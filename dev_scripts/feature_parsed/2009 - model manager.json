{  
    "project_name": "Model Manager",
    "features": [
        {
            "feature_title": "Set up and submit a model job",
            "feature_description": "This feature allows the user to set up and schedule a model job using the MM's Job-Setup module. It offers two main options: \"Weather FDDA\" and \"Climo\". For \"Weather FDDA\", the objective is to automate the setup of new real-time and off-line FDDA jobs, including GMOD jobs, re-runs, and case studies. Users can choose a cluster, select the model (MM5 or WRF), define a JOBID, determine domains (create own, choose pre-defined, or submit TERRAIN files), specify job run times and cycles (case study or re-run), supply other job-specific information (cycle interval, forecast length), specify whether to write restart files and their frequency, choose sigma-level configurations, optionally specify the number of nodes, receive email notifications, choose between standard or custom IC/BC data sources, provide custom IC/BC pre-processors or standard processing, determine MM5 executables or WRF model options, choose whether to run Final Analysis and Prelim. Analysis, and decide whether to run additional processing on model output (e.g., Bias Correction) and save output to MetVault. For \"Climo\", the objective is to integrate GCAT functionalities within the MM for setting up and running ClimoFDDA jobs. Users define a JOBID, supply job parameters (referencing GCAT tool for details), determine domain location, specify locations for pseudo-obs and custom cross sections, pick a pre-configured MM5 setup, set the job timeline (start, end, years), set ensemble options (hourly, min/max/mean/standard deviation, diurnal cycle, typical moment), request the number of nodes, choose whether to run additional processing on model output, and decide whether to save model output to MetVault. After model execution, users can choose to run post-processing on the ensemble output with options like Plots (NCL or RIP), NAPS, MDV, Sites, MEDOC, Raster, PRF, and Wind Roses, specifying a destination host and location for output files for each product. The user can save the job configuration and submit the job. Any custom scripts, executables, etc., must reside on the cluster where the job will run.",
            "feature_type": "Job Configuration and Submission"
        },
        {
            "feature_title": "Set up and submit a \"post-processing\" job",
            "feature_description": "This feature allows the user to run \"post-processing\" exclusively on an existing model output file. It also provides the post-processing component of the \"WeatherFDDA\" use case. The user first selects \"Set up a new 'post-processing' job\" from the system's options. Then, the user is prompted to provide the location and name of the model output file. If the model output file is expected from a running or scheduled FDDA-job, the user supplies the JOBID and cycle time. If the model output file already exists, the user provides its specific location. The user then selects the desired type of post-processing from a list of options, which includes Plots (NCL or RIP), NAPS, MDV, Sites, MEDOC (1-4), Stereo, and Verification. For each chosen post-processing option, the user can either provide a custom configuration file or utilize the default configuration file. The user must specify a destination location for the output products generated by the post-processing. Additionally, the user can specify the number of nodes that this job should run on, though this is noted as a requirement to be confirmed. Finally, the user can save the job's settings as a configuration file and submit the job for execution.",
            "feature_type": "Job Configuration and Submission"
        },
        {
            "feature_title": "Submit a 'By-hand' job",
            "feature_description": "The objective of this feature is to accommodate the current GMOD-framework, providing the ability for users to run customized jobs not configured through the MM's Job-Setup module. To submit such a job, the user must first identify the specific cluster(s) where the job is to run. Following this, the user must log on to that machine, perform all necessary operations for setting up the job, and then register it with the Model Manager (MM). Since the MM is not involved in the initial setup, the user is required to provide certain mandatory information for the MM to accept the job. This mandatory information includes: a job ID (e.g., GMUAE, GWDPG), the location of the script (host:/full_path_to_script), the time when the script is to run, an estimated time for how long the script will run, the name(s) of the executable(s), the maximum runtime for the executable(s), the number of nodes to use, and the location of output products (e.g., host:/dir_path). Optional information can also be provided, such as the job type, the frequency of how often the script should run, and any other additional relevant details. After providing this information, the user can save the job's settings into a configuration file. The user then submits the job, which can then be viewed in the job queue. Users will have the option to receive email notifications when the job starts, finishes, or is killed. A 'custom' job will need to notify the MM upon completion.",
            "feature_type": "Job Configuration and Submission"
        },
        {
            "feature_title": "Load a job configuration from a file and submit the job",
            "feature_description": "The objective of this feature is to provide the ability to load an existing job configuration into the Model Manager (MM) from a specified file. Upon logging into the system and choosing to \"Submit a new job\", the user selects the option \"Submit a job configuration file\". The user then supplies the file name of the configuration to be loaded. Once loaded, the user has the option to make changes to the configuration as needed. After making any modifications, the user can save the updated configuration. Finally, the user submits the job based on the loaded (and potentially modified) configuration.",
            "feature_type": "Job Configuration and Submission"
        },
        {
            "feature_title": "Retrieve and run a previously saved job configuration",
            "feature_description": "The objective of this feature is to provide the ability to retrieve a job configuration that was previously saved, allowing the user to re-run the job as is or modify its settings before re-running it. The user first logs on to the system using their user ID and password. The user then chooses to view their previously saved job configurations, which are presented in a table. This table may include attributes such as the Job id, Job type, the Cycle time that the job was run last (if applicable), and the time this job was run last. From this list, the user selects a specific job configuration. Once selected, the user has the option to change or delete this job configuration. If changes are made, the user can save the modified job configuration. Finally, the user submits the job, which will then run with the retrieved (and potentially updated) settings.",
            "feature_type": "Job Management"
        },
        {
            "feature_title": "View scheduled, running and old jobs",
            "feature_description": "The objective of this feature is to facilitate comprehensive monitoring of jobs within the Model Manager (MM) system. This includes viewing jobs currently running, inspecting jobs scheduled in the queue, and reviewing jobs that have completed in the past. The user begins by logging on with their user ID and password. They then choose from four options to filter the job display: all running jobs, all scheduled jobs (representing the job queue), past jobs, or all jobs (which encompasses running, scheduled, and old jobs). Based on the user's selection, a job table is presented. This table can display several attributes for each job, including: user id (the owner of the job), job type (e.g., GMOD, climoFDDA, FDDA-re-run, case study, custom), job priority, start time, remaining time (estimated) or the time it took to run the job, cycle (if applicable), the current stage (e.g., Pre-processing, F-analysis, Prelim. Analysis), status (SCHEDULED, RUNNING, status in percentage, DONE), the cluster and nodes used (for a running job), the number of processors, and other relevant details. The user can select a specific job to receive more detailed information. Additionally, the user can access and view a job's log files. The system allows users to delete their own jobs from the job queue, and a \"super user\" has the privilege to delete any job from the queue. Users can stop their running jobs, with \"super users\" having the ability to stop any running job. Similarly, users can re-start their jobs, and \"super users\" can re-start any job. Finally, users can resume their stopped jobs, and a \"super user\" can resume any stopped job.",
            "feature_type": "Job Monitoring and Management"
        }
    ],
    "data_dictionary": [
        {
            "variable_name": "MM",
            "variable_description": "Model Manager"
        },
        {
            "variable_name": "4DWX OTM",
            "variable_description": "\"4DWX On the Move\""
        },
        {
            "variable_name": "OTM",
            "variable_description": "short for 4DWX On the Move"
        },
        {
            "variable_name": "model back end system",
            "variable_description": "a term describing configuration files, data input, scripts and executables that are needed to run model jobs"
        },
        {
            "variable_name": "model job",
            "variable_description": "a collection of processes computing a weather or climate model over a given domain and for a given time period"
        },
        {
            "variable_name": "climo job",
            "variable_description": "either a \"ClimoFDDA\"-job (GCAT) or a CAM job"
        },
        {
            "variable_name": "GMOD job",
            "variable_description": "the current operational RTFDDA job using MM5 or WRF"
        },
        {
            "variable_name": "RTFDDA job",
            "variable_description": "a GMOD job or a RTFDDA ensemble"
        },
        {
            "variable_name": "off-line FDDA job",
            "variable_description": "a re-run of a previous RTFDDA cycle or a case study"
        },
        {
            "variable_name": "Post-processing' job",
            "variable_description": "a set of processes that take model output files as input, perform calculations or data conversions on the input and possibly produce output files in a different data format"
        },
        {
            "variable_name": "by-hand' job",
            "variable_description": "an existing set of scripts and executables that were set up by the user on a cluster in advance. A 'by hand' job can run any executable."
        }
    ],
    "compliance_terms": [],
    "reference_file": "feature_dataset/2009 - model manager.pdf"
}