{"provision_title": "DUTY TO REPORT.", "provision_body": "(a) DUTY TO Report.\u2014(1) IN GENERAL.\u2014(A) Duty. In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider\u2014(i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(A), take the actions described in subparagraph (B); and(ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B).(B) Actions described.\u2014The actions described in this subparagraph are\u2014(i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and(ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC.(2) FACTS OR CIRCUMSTANCES.\u2014(A) Apparent violations.\u2014The facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b).(B) Imminent violations.\u2014The facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent.", "provision_code": "(a)", "country": "United States", "region": "n/a", "relevant_labels": "Reporting requirements, providers, child sexual exploitation, child pornography, NCMEC, law enforcement, privacy, data preservation", "law_code": "18 U.S. Code \u00a7 2258A", "reference_file": "./law_dataset\\18 U.S. Code \u00a7 2258A - Reporting requirements of providers _ U.S. Code _ US Law _ LII _ Legal Information Institute.pdf"}
{"provision_title": "CONTENTS OF Report.", "provision_body": "(b) CONTENTS OF Report. In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include the following information:(1) INFORMATION ABOUT THE INVOLVED INDIVIDUAL.\u2014Information relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information.(2) HISTORICAL REFERENCE.\u2014Information relating to when and how a customer or subscriber of a provider uploaded, transmitted, or received content relating to the report or when and how content relating to the report was reported to, or discovered by the provider, including a date and time stamp and time zone.(3) GEOGRAPHIC LOCATION INFORMATION.\u2014Information relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider.(4) VISUAL DEPICTIONS OF APPARENT CHILD PORNOGRAPHY.\u2014Any visual depiction of apparent child pornography or other content relating to the incident such report is regarding.(5) COMPLETE COMMUNICATION.\u2014The complete communication containing any visual depiction of apparent child pornography or other content, including\u2014(A) any data or information regarding the transmission of the communication; and(B) any visual depictions, data, or other digital files contained in, or attached to, the communication.", "provision_code": "(b)", "country": "United States", "region": "n/a", "relevant_labels": "Reporting requirements, providers, child sexual exploitation, child pornography, NCMEC, law enforcement, privacy, data preservation", "law_code": "18 U.S. Code \u00a7 2258A", "reference_file": "./law_dataset\\18 U.S. Code \u00a7 2258A - Reporting requirements of providers _ U.S. Code _ US Law _ LII _ Legal Information Institute.pdf"}
{"provision_title": "FORWARDING of Report to Law EnfoRCEMENT.", "provision_body": "(c) FORWARDING of Report to Law EnfoRCEMENT.\u2014Pursuant to its clearinghouse role as a private, nonprofit organization, and at the conclusion of its review in furtherance of its nonprofit mission, NCMEC shall make available each report made under subsection (a)(1) to one or more of the following law enforcement agencies:(1) Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes.(2) Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation.(3) A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes.", "provision_code": "(c)", "country": "United States", "region": "n/a", "relevant_labels": "Reporting requirements, providers, child sexual exploitation, child pornography, NCMEC, law enforcement, privacy, data preservation", "law_code": "18 U.S. Code \u00a7 2258A", "reference_file": "./law_dataset\\18 U.S. Code \u00a7 2258A - Reporting requirements of providers _ U.S. Code _ US Law _ LII _ Legal Information Institute.pdf"}
{"provision_title": "ATTORNEY GENERAL RESPONSIBILITIES.", "provision_body": "(d) ATTORNEY GENERAL RESPONSIBILITIES.\u2014(1) IN GENERAL.\u2014The Attorney General shall enforce this section.(2) DESIGNATION OF FEDERAL AGENCIES.\u2014The Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1).(3) DESIGNATION OF FOREIGN AGENCIES.\u2014The Attorney General may\u2014(A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3);(B) establish the conditions under which such a report may be forwarded to such agencies; and(C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3).(4) REPORTING DESIGNATED FOREIGN AGENCIES.\u2014The Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3).(5) NOTIFICATION TO PROVIDERS.\u2014(A) In general.\u2014NCMEC may notify a provider of the information described in subparagraph (B), if\u2014(i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and(ii) NCMEC forwards the report described in clause (i) to\u2014(I) the requesting foreign law enforcement agency; or(II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes.(B) Information described.\u2014The information described in this subparagraph is\u2014(i) the identity of the foreign law enforcement agency to which the report was forwarded; and(ii) the date on which the report was forwarded.(C) Notification of inability to forward report.\u2014If a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report.", "provision_code": "(d)", "country": "United States", "region": "n/a", "relevant_labels": "Reporting requirements, providers, child sexual exploitation, child pornography, NCMEC, law enforcement, privacy, data preservation", "law_code": "18 U.S. Code \u00a7 2258A", "reference_file": "./law_dataset\\18 U.S. Code \u00a7 2258A - Reporting requirements of providers _ U.S. Code _ US Law _ LII _ Legal Information Institute.pdf"}
{"provision_title": "FAILURE TO REPORT.", "provision_body": "(e) FAILURE TO REPORT.\u2014A provider that knowingly and willfully fails to make a report required under subsection (a)(1) shall be fined\u2014(1) in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and(2) in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users.", "provision_code": "(e)", "country": "United States", "region": "n/a", "relevant_labels": "Reporting requirements, providers, child sexual exploitation, child pornography, NCMEC, law enforcement, privacy, data preservation", "law_code": "18 U.S. Code \u00a7 2258A", "reference_file": "./law_dataset\\18 U.S. Code \u00a7 2258A - Reporting requirements of providers _ U.S. Code _ US Law _ LII _ Legal Information Institute.pdf"}
{"provision_title": "PROTECTION of Privacy.", "provision_body": "(f) PROTECTION of Privacy.\u2014Nothing in this section shall be construed to require a provider to\u2014(1) monitor any user, subscriber, or customer of that provider;(2) monitor the content of any communication of any person described in paragraph (1); or(3) affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b).", "provision_code": "(f)", "country": "United States", "region": "n/a", "relevant_labels": "Reporting requirements, providers, child sexual exploitation, child pornography, NCMEC, law enforcement, privacy, data preservation", "law_code": "18 U.S. Code \u00a7 2258A", "reference_file": "./law_dataset\\18 U.S. Code \u00a7 2258A - Reporting requirements of providers _ U.S. Code _ US Law _ LII _ Legal Information Institute.pdf"}
{"provision_title": "CONDITIONS OF DISCLOSure Information Contained Within Report.", "provision_body": "(g) CONDITIONS OF DISCLOSure Information Contained Within Report.\u2014(1) IN GENERAL.\u2014Except as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report.(2) PERMITTED DISCLOSURES BY LAW ENFORCEMENT.\u2014(A) In general.\u2014A law enforcement agency may disclose information in a report received under subsection (c)\u2014(i) to an attorney for the government for use in the performance of the official duties of that attorney;(ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions;(iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law;(iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law;(v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant;(vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and(vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose.(B) Limitation.\u2014Nothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider.(3) PERMITTED DISCLOSURES BY NCMEC.\u2014NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to\u2014(A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;(B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;(C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;(D) a provider as described in section 2258C; and(E) respond to legal process, as necessary.(4) PERMITTED DISCLOSURE BY A PROVIDER.\u2014A provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process.", "provision_code": "(g)", "country": "United States", "region": "n/a", "relevant_labels": "Reporting requirements, providers, child sexual exploitation, child pornography, NCMEC, law enforcement, privacy, data preservation", "law_code": "18 U.S. Code \u00a7 2258A", "reference_file": "./law_dataset\\18 U.S. Code \u00a7 2258A - Reporting requirements of providers _ U.S. Code _ US Law _ LII _ Legal Information Institute.pdf"}
{"provision_title": "PRESERVATION.", "provision_body": "(h) PRESERVATION.\u2014(1) IN GENERAL.\u2014For the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline.(2) PRESERVATION OF COMMINGLED CONTENT.\u2014Pursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person.(3) PROTECTION OF PRESERVED MATERIALS.\u2014A provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection.(4) AUTHORITIES AND DUTIES NOT AFFECTED.\u2014Nothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703.(5) EXTENSION OF PRESERVATION.\u2014A provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children.(6) METHOD OF PRESERVATION.\u2014Not later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto.", "provision_code": "(h)", "country": "United States", "region": "n/a", "relevant_labels": "Reporting requirements, providers, child sexual exploitation, child pornography, NCMEC, law enforcement, privacy, data preservation", "law_code": "18 U.S. Code \u00a7 2258A", "reference_file": "./law_dataset\\18 U.S. Code \u00a7 2258A - Reporting requirements of providers _ U.S. Code _ US Law _ LII _ Legal Information Institute.pdf"}
{"provision_title": "Short Title", "provision_body": "This chapter shall be known, and may be cited, as the Protecting Our Kids from Social Media Addiction Act.", "provision_code": "27000", "country": "United States of America", "region": "California", "relevant_labels": "Social Media, Child Protection, Addiction, Minors, Parental Consent, Digital Well-being", "law_code": "Health and Safety Code, Division 20, Chapter 24", "reference_file": "./law_dataset\\20230SB976_91-1.pdf"}
{"provision_title": "Definitions", "provision_body": "For purposes of this chapter, the following terms have the following meanings: (a) \"Addictive feed\" means an internet website, online service, online application, or mobile application, or a portion thereof, in which multiple pieces of media generated or shared by users are, either concurrently or sequentially, recommended, selected, or prioritized for display to a user based, in whole or in part, on information provided by the user, or otherwise associated with the user or the user's device, unless any of the following conditions are met, alone or in combination with one another: (1) The information is not persistently associated with the user or user's device, and does not concern the user's previous interactions with media generated or shared by others. (2) The information consists of search terms that are not persistently associated with the user or user's device. (3) The information consists of user-selected privacy or accessibility settings, technical information concerning the user's device, or device communications or signals concerning whether the user is a minor. (4) The user expressly and unambiguously requested the specific media or media by the author, creator, or poster of the media, or the blocking, prioritization, or deprioritization of such media, provided that the media is not recommended, selected, or prioritized for display based, in whole or in part, on other information associated with the user or the user's device, except as otherwise permitted by this chapter and, in the case of audio or video content, is not automatically played. (5) The media consists of direct, private communications between users. (6) The media recommended, selected, or prioritized for display is exclusively the next media in a preexisting sequence from the same author, creator, poster, or source and, in the case of audio or video content, is not automatically played. (7) The recommendation, selection, or prioritization of the media is necessary to comply with this chapter or any regulations promulgated pursuant to this chapter. (b) (1) \u201cAddictive internet-based service or application\u201d means an internet website, online service, online application, or mobile application, including, but not limited to, a \u201csocial media platform\u201d as defined in Section 22675 of the Business and Professions Code, that offers users or provides users with an addictive feed as a significant part of the service provided by that internet website, online service, online application, or mobile application. (2) \"Addictive internet-based service or application\" does not apply to either of the following: (A) An internet website, online service, online application, or mobile application for which interactions between users are limited to commercial transactions or to consumer reviews of products, sellers, services, events, or places, or any combination thereof. (B) An internet website, online service, online application, or mobile application that operates a feed for the primary purpose of cloud storage. (c) \"Media\" means text, audio, an image, or a video. (d) \"Minor\" means an individual under 18 years of age who is located in the State of California. (e) \u201cOperator\u201d means a person who operates or provides an internet website, an online service, an online application, or a mobile application. (f) \"Parent\" means a parent or guardian, including as defined in regulations promulgated pursuant to this chapter. (g) \"User\" means a person who uses an internet website, online service, online application, or mobile application. \u201cUser\u201d does not include the operator or a person acting as an agent of the operator.", "provision_code": "27000.5", "country": "United States of America", "region": "California", "relevant_labels": "Social Media, Child Protection, Addiction, Minors, Parental Consent, Digital Well-being", "law_code": "Health and Safety Code, Division 20, Chapter 24", "reference_file": "./law_dataset\\20230SB976_91-1.pdf"}
{"provision_title": "Unlawful Provision of Addictive Feed", "provision_body": "(a) It shall be unlawful for the operator of an addictive internet-based service or application to provide an addictive feed to a user unless either of the following is met: (1) (A) Except as provided in subparagraph (B), the operator does not have actual knowledge that the user is a minor. (B) Commencing January 1, 2027, the operator has reasonably determined that the user is not a minor, including pursuant to regulations promulgated by the Attorney General. (2) The operator has obtained verifiable parental consent to provide an addictive feed to the user who is a minor. (b) Information collected for the purpose of determining a user's age or verifying parental consent pursuant to this chapter shall not be used for any purpose other than compliance with this chapter or with another applicable law. The information collected shall be deleted immediately after it is used to determine a user's age or to verify parental consent, except as necessary to comply with state or federal law.", "provision_code": "27001", "country": "United States of America", "region": "California", "relevant_labels": "Social Media, Child Protection, Addiction, Minors, Parental Consent, Digital Well-being", "law_code": "Health and Safety Code, Division 20, Chapter 24", "reference_file": "./law_dataset\\20230SB976_91-1.pdf"}
{"provision_title": "Notifications and Parental Controls", "provision_body": "(a) (1) Except as provided in paragraph (2), it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user's local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user's local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor unless the operator has obtained verifiable parental consent to send those notifications. (2) Commencing January 1, 2027, it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user's local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user's local time zone, to send notifications to a user whom the operator has not reasonably determined is not a minor, including pursuant to regulations promulgated by the Attorney General, unless the operator has obtained verifiable parental consent to send those notifications. (b) The operator of an addictive internet-based service or application shall provide a mechanism through which the verified parent of a user who is a minor may do any of the following: (1) Prevent their child from accessing or receiving notifications from the addictive internet-based service or application between specific hours chosen by the parent. This setting shall be set by the operator as on by default, in a manner in which the child's access is limited between the hours of 12 a.m. and 6 a.m., in the user's local time zone. (2) Limit their child's access to any addictive feed from the addictive internet-based service or application to a length of time per day specified by the verified parent. This setting shall be set by the operator as on by default, in a manner in which the child's access is limited to one hour per day unless modified by the verified parent. (3) Limit their child's ability to view the number of likes or other forms of feedback to pieces of media within an addictive feed. This setting shall be set by the operator as on by default. (4) Require that the default feed provided to the child when entering the internet-based service or application be one in which pieces of media are not recommended, selected, or prioritized for display based on information provided by the user, or otherwise associated with the user or the user's device, other than the user's age or status as a minor. (5) Set their child's account to private mode, in a manner in which only users to whom the child is connected on the addictive internet-based service or application may view or respond to content posted by the child. This setting shall be set by the operator as on by default.", "provision_code": "27002", "country": "United States of America", "region": "California", "relevant_labels": "Social Media, Child Protection, Addiction, Minors, Parental Consent, Digital Well-being", "law_code": "Health and Safety Code, Division 20, Chapter 24", "reference_file": "./law_dataset\\20230SB976_91-1.pdf"}
{"provision_title": "Construction of Chapter", "provision_body": "(a) This chapter shall not be construed as requiring the operator of an addictive internet-based service or application to give a parent any additional or special access to, or control over, the data or accounts of their child. (b) This chapter shall not be construed as preventing any action taken in good faith to restrict access to, or availability of, media.", "provision_code": "27003", "country": "United States of America", "region": "California", "relevant_labels": "Social Media, Child Protection, Addiction, Minors, Parental Consent, Digital Well-being", "law_code": "Health and Safety Code, Division 20, Chapter 24", "reference_file": "./law_dataset\\20230SB976_91-1.pdf"}
{"provision_title": "Operator Choices and Protections", "provision_body": "(a) An operator may choose not to provide services to minors. However, the operator of an addictive internet-based service or application shall not withhold, degrade, lower the quality of, or increase the price of, any product, service, or feature, other than as required by this chapter, due to a user or parent availing themselves of the rights provided by this chapter, or due to the protections required by this chapter. (b) A parent's provision of consent as described in Section 27001 or 27002, or the use by a parent of a mechanism as described in Section 27002, does not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator of an addictive internet-based service or application regarding any harm to the mental health or well-being of the user. (c) The protections provided by this chapter are in addition to those provided by any other applicable law, including, but not limited to, the California Age-Appropriate Design Code Act (Title 1.81.47 (commencing with Section 1798.99.28) of Part 4 of Division 3 of the Civil Code).", "provision_code": "27004", "country": "United States of America", "region": "California", "relevant_labels": "Social Media, Child Protection, Addiction, Minors, Parental Consent, Digital Well-being", "law_code": "Health and Safety Code, Division 20, Chapter 24", "reference_file": "./law_dataset\\20230SB976_91-1.pdf"}
{"provision_title": "Annual Public Disclosure", "provision_body": "An operator of an addictive internet-based service or application shall publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the controls set forth in Section 27002 are or are not enabled.", "provision_code": "27005", "country": "United States of America", "region": "California", "relevant_labels": "Social Media, Child Protection, Addiction, Minors, Parental Consent, Digital Well-being", "law_code": "Health and Safety Code, Division 20, Chapter 24", "reference_file": "./law_dataset\\20230SB976_91-1.pdf"}
{"provision_title": "Enforcement and Regulations", "provision_body": "(a) This chapter may only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General. (b) The Attorney General shall adopt regulations to further the purposes of this chapter, including regulations regarding age assurance and parental consent by January 1, 2027. The Attorney General may adopt regulations that provide for exceptions to this chapter, but only if those exceptions further the purpose of protecting minors. (c) In promulgating the regulations described in subdivision (b), the Attorney General shall solicit public comment regarding the impact that any regulation might have based on the nondiscrimination characteristics set forth in Section 51 of the Civil Code or in any other applicable law.", "provision_code": "27006", "country": "United States of America", "region": "California", "relevant_labels": "Social Media, Child Protection, Addiction, Minors, Parental Consent, Digital Well-being", "law_code": "Health and Safety Code, Division 20, Chapter 24", "reference_file": "./law_dataset\\20230SB976_91-1.pdf"}
{"provision_title": "Severability", "provision_body": "If any provision of this chapter, or application thereof, to any person or circumstance is held invalid, that invalidity shall not affect other provisions or applications of this chapter that can be given effect without the invalid provision or application, and to this end the provisions of this chapter are declared to be severable.", "provision_code": "27007", "country": "United States of America", "region": "California", "relevant_labels": "Social Media, Child Protection, Addiction, Minors, Parental Consent, Digital Well-being", "law_code": "Health and Safety Code, Division 20, Chapter 24", "reference_file": "./law_dataset\\20230SB976_91-1.pdf"}
{"provision_title": "Social media use for minors.", "provision_body": "(1) As used in this section, the term: (a) \"Account holder\" means a resident who opens an account or creates a profile or is identified by the social media platform by a unique identifier while using or accessing a social media platform when the social media platform knows or has reason to believe the resident is located in this state. (b) \"Daily active users\" means the number of unique users in the United States who used the online forum, website, or application at least 80 percent of the days during the previous 12 months, or, if the online forum, website, or application did not exist during the previous 12 months, the number of unique users in the United States who used the online forum, website, or application at least 80 percent of the days during the previous month. (c) \"Department\" means the Department of Legal Affairs. (d) \"Resident\" means a person who lives in this state for more than 6 months of the year. (e) \"Social media platform\" means an online forum, website, or application that satisfies each of the following criteria: 1. Allows users to upload content or view the content or activity of other users; 2. Ten percent or more of the daily active users who are younger than 16 years of age spend on average 2 hours per day or longer on the online forum, website, or application on the days when using the online forum, website, or application during the previous 12 months or, if the online forum, website, or application did not exist during the previous 12 months, during the previous month; 3. Employs algorithms that analyze user data or information on users to select content for users; and 4. Has any of the following addictive features: a. Infinite scrolling, which means either: (I) Continuously loading content, or content that loads as the user scrolls down the page without the need to open a separate page; or (II) Seamless content, or the use of pages with no visible or apparent end or page breaks. b. Push notifications or alerts sent by the online forum, website, or application to inform a user about specific activities or events related to the user's account. c. Displays personal interactive metrics that indicate the number of times other users have clicked a button to indicate their reaction to content or have shared or reposted the content. d. Auto-play video or video that begins to play without the user first clicking on the video or on a play button for that video. e. Live-streaming or a function that allows a user or advertiser to broadcast live video content in real-time. The term does not include an online service, website, or application where the exclusive function is e-mail or direct messaging consisting of text, photographs, pictures, images, or videos shared only between the sender and the recipients, without displaying or posting publicly or to other users not specifically identified as the recipients by the sender. (2)(a) A social media platform shall prohibit a minor who is younger than 14 years of age from entering into a contract with a social media platform to become an account holder. (b) A social media platform shall: 1. Terminate any account held by an account holder younger than 14 years of age, including accounts that the social media platform treats or categorizes as belonging to an account holder who is likely younger than 14 years of age for purposes of targeting content or advertising, and provide 90 days for an account holder to dispute such termination. Termination must be effective upon the expiration of the 90 days if the account holder fails to effectively dispute the termination. 2. Allow an account holder younger than 14 years of age to request to terminate the account. Termination must be effective within 5 business days after such request. 3. Allow the confirmed parent or guardian of an account holder younger than 14 years of age to request that the minor's account be terminated. Termination must be effective within 10 business days after such request. 4. Permanently delete all personal information held by the social media platform relating to the terminated account, unless there are legal requirements to maintain such information. (3)(a) A social media platform shall prohibit a minor who is 14 or 15 years of age from entering into a contract with a social media platform to become an account holder, unless the minor's parent or guardian provides consent for the minor to become an account holder. (b) A social media platform shall: 1. Terminate any account held by an account holder who is 14 or 15 years of age, including accounts that the social media platform treats or categorizes as belonging to an account holder who is likely 14 or 15 years of age for purposes of targeting content or advertising, if the account holder's parent or guardian has not provided consent for the minor to create or maintain the account. The social media platform shall provide 90 days for an account holder to dispute such termination. Termination must be effective upon the expiration of the 90 days if the account holder fails to effectively dispute the termination. 2. Allow an account holder who is 14 or 15 years of age to request to terminate the account. Termination must be effective within 5 business days after such request. 3. Allow the confirmed parent or guardian of an account holder who is 14 or 15 years of age to request that the minor's account be terminated. Termination must be effective within 10 business days after such request. 4. Permanently delete all personal information held by the social media platform relating to the terminated account, unless there are legal requirements to maintain such information. (4) If a court enjoins the enforcement of subsection (3) or would otherwise enjoin enforcement of any other provision of this section due to subsection (3), then subsection (3) shall be severed, and the following shall come into effect: (a) A social media platform shall prohibit a minor who is 14 or 15 years of age from entering into a contract with a social media platform to become an account holder. (b) A social media platform shall: 1. Terminate any account held by an account holder who is 14 or 15 years of age, including accounts that the social media platform treats or categorizes as belonging to an account holder who is likely 14 or 15 years of age for purposes of targeting content or advertising, and provide 90 days for an account holder to dispute such termination. Termination must be effective upon the expiration of 90 days if the account holder fails to effectively dispute the termination. 2. Allow an account holder who is 14 or 15 years of age to request to terminate the account. Termination must be effective within 5 business days after such request. 3. Allow the confirmed parent or guardian of an account holder who is 14 or 15 years of age to request that the minor's account be terminated. Termination must be effective within 10 business days after such request. 4. Permanently delete all personal information held by the social media platform relating to the terminated account, unless there are legal requirements to maintain such information. (5) Any knowing or reckless violation of subsection (2), subsection (3), or, if in effect, subsection (4) is deemed an unfair and deceptive trade practice actionable under part II of this chapter solely by the department against a social media platform. If the department has reason to believe that a social media platform is in violation of subsection (2), subsection (3), or, if in effect, subsection (4), the department, as the enforcing authority, may bring an action against such platform for an unfair or deceptive act or practice. For the purpose of bringing an action pursuant to this section, ss. 501.211 and 501.212 do not apply. In addition to other remedies under part II of this chapter, the department may collect a civil penalty of up to $50,000 per violation and reasonable attorney fees and court costs. When the social media platform's failure to comply with subsection (2), subsection (3), or, if in effect, subsection (4) is a consistent pattern of knowing or reckless conduct, punitive damages may be assessed against the social media platform. (6)(a) A social media platform that knowingly or recklessly violates subsection (2), subsection (3), or, if in effect, subsection (4) is liable to the minor account holder, including court costs and reasonable attorney fees as ordered by the court. Claimants may be awarded up to $10,000 in damages. (b) A civil action for a claim under this subsection must be brought within 1 year from the date the complainant knew, or reasonably should have known, of the alleged violation. (c) Any action brought under this subsection may only be brought on behalf of a minor account holder. (7) For purposes of bringing an action under this section, a social media platform that allows a minor account holder younger than 14 years of age or a minor account holder who is 14 or 15 years of age to create an account on such platform is considered to be both engaged in substantial and not isolated activities within this state and operating, conducting, engaging in, or carrying on a business and doing business in this state, and is therefore subject to the jurisdiction of the courts of this state. (8) If a social media platform allows an account holder to use the social media platform, the parties have entered into a contract. (9) This section does not preclude any other available remedy at law or equity. (10)(a) If, by its own inquiry or as a result of complaints, the department has reason to believe that an entity or person has engaged in, or is engaging in, an act or practice that violates this section, the department may administer oaths and affirmations, subpoena witnesses or matter, and collect evidence. Within 5 days, excluding weekends and legal holidays, after the service of a subpoena or at any time before the return date specified therein, whichever is longer, the party served may file in the circuit court in the county in which it resides or in which it transacts business and serve upon the enforcing authority a petition for an order modifying or setting aside the subpoena. The petitioner may raise any objection or privilege which would be available upon service of such subpoena in a civil action. The subpoena shall inform the party served of its rights under this subsection. (b) If the matter that the department seeks to obtain by subpoena is located outside the state, the entity or person subpoenaed may make it available to the department or its representative to examine the matter at the place where it is located. The department may designate representatives, including officials of the state in which the matter is located, to inspect the matter on its behalf, and may respond to similar requests from officials of other states. (c) Upon failure of an entity or person without lawful excuse to obey a subpoena and upon reasonable notice to all persons affected, the department may apply to the circuit court for an order compelling compliance. (d) The department may request that an entity or person that refuses to comply with a subpoena on the ground that testimony or matter may incriminate the entity or person be ordered by the court to provide the testimony or matter. Except in a prosecution for perjury, an entity or individual that complies with a court order to provide testimony or matter after asserting a valid privilege against self-incrimination shall not have the testimony or matter so provided, or evidence derived therefrom, received against the entity or person in any criminal investigation or proceeding. (e) Any entity or person upon whom a subpoena is served pursuant to this section shall comply with the terms thereof unless otherwise provided by order of the court. Any entity or person that fails to appear with the intent to avoid, evade, or prevent compliance in whole or in part with any investigation under this part or who removes from any place, conceals, withholds, mutilates, alters, or destroys, or by any other means falsifies any documentary material in the possession, custody, or control of any entity or person subject to any such subpoena, or knowingly conceals any relevant information with the intent to avoid, evade, or prevent compliance shall be liable for a civil penalty of not more than $5,000 per week in violation, reasonable attorney's fees, and costs. (11) The department may adopt rules to implement this section.", "provision_code": "501.1736", "country": "United States", "region": "Florida", "relevant_labels": "online protections for minors, social media platforms, account termination, age verification, material harmful to minors, civil penalties, private causes of action, Department of Legal Affairs, investigative demands, punitive damages, jurisdiction of state courts, contract, rules, third party conducting age verification, severability, effective date", "law_code": "CS/CS/HB 3, Engrossed 1", "reference_file": "./law_dataset\\CSCSHB_3_Online_Protections_for_Minors.pdf"}
{"provision_title": "Age verification for online access to materials harmful to minors.", "provision_body": "(1) As used in this section, the term: (a) \"Anonymous age verification\" has the same meaning as in s. 501.1738. (b) \"Commercial entity\" includes a corporation, a limited liability company, a partnership, a limited partnership, a sole proprietorship, and any other legally recognized entity. (c) \"Department\" means the Department of Legal Affairs. (d) \"Distribute\" means to issue, sell, give, provide, deliver, transfer, transmit, circulate, or disseminate by any means. (e) \"Material harmful to minors\" means any material that: 1. The average person applying contemporary community standards would find, taken as a whole, appeals to the prurient interest; 2. Depicts or describes, in a patently offensive way, sexual conduct as specifically defined in s. 847.001(19); and 3. When taken as a whole, lacks serious literary, artistic, political, or scientific value for minors. (f) \"News-gathering organization\" means any of the following: 1. A newspaper, news publication, or news source, printed or published online or on a mobile platform, engaged in reporting current news and matters of public interest, and an employee thereof who can provide documentation of such employment. 2. A radio broadcast station, television broadcast station, cable television operator, or wire service, and an employee thereof who can provide documentation of such employment. (g) \"Publish\" means to communicate or make information available to another person or entity on a publicly available website or application. (h) \"Resident\" means a person who lives in this state for more than 6 months of the year. (i) \"Standard age verification\" means any commercially reasonable method of age verification approved by the commercial entity. (j) \"Substantial portion\" means more than 33.3 percent of total material on a website or application. (2) A commercial entity that knowingly and intentionally publishes or distributes material harmful to minors on a website or application, if the website or application contains a substantial portion of material harmful to minors, must use either anonymous age verification or standard age verification to verify that the age of a person attempting to access the material is 18 years of age or older and prevent access to the material by a person younger than 18 years of age. The commercial entity must offer anonymous age verification and standard age verification, and a person attempting to access the material may select which method will be used to verify his or her age. (3) A commercial entity must ensure that the requirements of s. 501.1738 are met. (4)(a) This section does not apply to any bona fide news or public interest broadcast, website video, report, or event and does not affect the rights of a news-gathering organization. (b) An Internet service provider or its affiliates or subsidiaries, a search engine, or a cloud service provider does not violate this section solely for providing access or connection to or from a website or other information or content on the Internet or a facility, system, or network not under the provider's control, including transmission, downloading, intermediate storage, or access software, to the extent the provider is not responsible for the creation of the content of the communication which constitutes material harmful to minors. (5)(a) Any violation of subsection (2) or subsection (3) is deemed an unfair and deceptive trade practice actionable under part II of this chapter solely by the department on behalf of a resident minor against a commercial entity. If the department has reason to believe that a commercial entity is in violation of subsection (2) or subsection (3), the department, as the enforcing authority, may bring an action against the commercial entity for an unfair or deceptive act or practice. For the purpose of bringing an action pursuant to this section, ss. 501.211 and 501.212 do not apply. In addition to other remedies under part II of this chapter, the department may collect a civil penalty of up to $50,000 per violation and reasonable attorney fees and court costs. When the commercial entity's failure to comply with subsection (2) or subsection (3) is a consistent pattern of conduct of the commercial entity, punitive damages may be assessed against the commercial entity. (b) A third party that performs age verification for a commercial entity in violation of s. 501.1738 is deemed to have committed an unfair and deceptive trade practice actionable under part II of this chapter solely by the department against such third party. If the department has reason to believe that the third party is in violation of s. 501.1738, the department, as the enforcing authority, may bring an action against such third party for an unfair or deceptive act or practice. For the purpose of bringing an action pursuant to this section, ss. 501.211 and 501.212 do not apply. In addition to other remedies under part II of this chapter, the department may collect a civil penalty of up to $50,000 per violation and reasonable attorney fees and court costs. (c) A commercial entity that violates subsection (2) for failing to prohibit access or prohibit a minor from future access to material harmful to minors after a report of unauthorized or unlawful access is liable to the minor for such access, including court costs and reasonable attorney fees as ordered by the court. Claimants may be awarded up to $10,000 in damages. (d) Any action under this subsection may only be brought on behalf of or by a resident minor. (6) For purposes of bringing an action under subsection (5), a commercial entity that publishes or distributes material harmful to minors on a website or application, if the website or application contains a substantial portion of material harmful to minors and such website or application is available to be accessed in this state, is considered to be both engaged in substantial and not isolated activities within this state and operating, conducting, engaging in, or carrying on a business and doing business in this state, and is therefore subject to the jurisdiction of the courts of this state. (7) This section does not preclude any other available remedy at law or equity. (8)(a) If, by its own inquiry or as a result of complaints, the department has reason to believe that an entity or person has engaged in, or is engaging in, an act or practice that violates this section, the department may administer oaths and affirmations, subpoena witnesses or matter, and collect evidence. Within 5 days, excluding weekends and legal holidays, after the service of a subpoena or at any time before the return date specified therein, whichever is longer, the party served may file in the circuit court in the county in which it resides or in which it transacts business and serve upon the enforcing authority a petition for an order modifying or setting aside the subpoena. The petitioner may raise any objection or privilege which would be available upon service of such subpoena in a civil action. The subpoena shall inform the party served of its rights under this subsection. (b) If the matter that the department seeks to obtain by subpoena is located outside the state, the entity or person subpoenaed may make it available to the department or its representative to examine the matter at the place where it is located. The department may designate representatives, including officials of the state in which the matter is located, to inspect the matter on its behalf, and may respond to similar requests from officials of other states. (c) Upon failure of an entity or person without lawful excuse to obey a subpoena and upon reasonable notice to all persons affected, the department may apply to the circuit court for an order compelling compliance. (d) The department may request that an entity or person that refuses to comply with a subpoena on the ground that testimony or matter may incriminate the entity or person be ordered by the court to provide the testimony or matter. Except in a prosecution for perjury, an entity or individual that complies with a court order to provide testimony or matter after asserting a valid privilege against self-incrimination shall not have the testimony or matter so provided, or evidence derived therefrom, received against the entity or person in any criminal investigation or proceeding. (e) Any entity or person upon whom a subpoena is served pursuant to this section shall comply with the terms thereof unless otherwise provided by order of the court. Any entity or person that fails to appear with the intent to avoid, evade, or prevent compliance in whole or in part with any investigation under this part or who removes from any place, conceals, withholds, mutilates, alters, or destroys, or by any other means falsifies any documentary material in the possession, custody, or control of any entity or person subject to any such subpoena, or knowingly conceals any relevant information with the intent to avoid, evade, or prevent compliance, shall be liable for a civil penalty of not more than $5,000 per week in violation, reasonable attorney's fees, and costs. (9) The department may adopt rules to implement this section.", "provision_code": "501.1737", "country": "United States", "region": "Florida", "relevant_labels": "online protections for minors, social media platforms, account termination, age verification, material harmful to minors, civil penalties, private causes of action, Department of Legal Affairs, investigative demands, punitive damages, jurisdiction of state courts, contract, rules, third party conducting age verification, severability, effective date", "law_code": "CS/CS/HB 3, Engrossed 1", "reference_file": "./law_dataset\\CSCSHB_3_Online_Protections_for_Minors.pdf"}
{"provision_title": "Anonymous age verification.", "provision_body": "(1) As used in this section, the term \"anonymous age verification\" means a commercially reasonable method used by a government agency or a business for the purpose of age verification which is conducted by a nongovernmental, independent third party organized under the laws of a state of the United States which: (a) Has its principal place of business in a state of the United States; and (b) Is not owned or controlled by a company formed in a foreign country, a government of a foreign country, or any other entity formed in a foreign country. (2) A third party conducting anonymous age verification pursuant to this section: (a) May not retain personal identifying information used to verify age once the age of an account holder or a person seeking an account has been verified. (b) May not use personal identifying information used to verify age for any other purpose. (c) Must keep anonymous any personal identifying information used to verify age. Such information may not be shared or otherwise communicated to any person. (d) Must protect personal identifying information used to verify age from unauthorized or illegal access, destruction, use, modification, or disclosure through reasonable security procedures and practices appropriate to the nature of the personal information.", "provision_code": "501.1738", "country": "United States", "region": "Florida", "relevant_labels": "online protections for minors, social media platforms, account termination, age verification, material harmful to minors, civil penalties, private causes of action, Department of Legal Affairs, investigative demands, punitive damages, jurisdiction of state courts, contract, rules, third party conducting age verification, severability, effective date", "law_code": "CS/CS/HB 3, Engrossed 1", "reference_file": "./law_dataset\\CSCSHB_3_Online_Protections_for_Minors.pdf"}
{"provision_title": "n/a", "provision_body": "If any provision of this act or its application to any person or circumstances is held invalid, the invalidity does not affect other provisions or applications of this act which can be given effect without the invalid provision or application, and to this end the provisions of this act are severable.", "provision_code": "Section 4", "country": "United States", "region": "Florida", "relevant_labels": "online protections for minors, social media platforms, account termination, age verification, material harmful to minors, civil penalties, private causes of action, Department of Legal Affairs, investigative demands, punitive damages, jurisdiction of state courts, contract, rules, third party conducting age verification, severability, effective date", "law_code": "CS/CS/HB 3, Engrossed 1", "reference_file": "./law_dataset\\CSCSHB_3_Online_Protections_for_Minors.pdf"}
{"provision_title": "n/a", "provision_body": "This act shall take effect January 1, 2025.", "provision_code": "Section 5", "country": "United States", "region": "Florida", "relevant_labels": "online protections for minors, social media platforms, account termination, age verification, material harmful to minors, civil penalties, private causes of action, Department of Legal Affairs, investigative demands, punitive damages, jurisdiction of state courts, contract, rules, third party conducting age verification, severability, effective date", "law_code": "CS/CS/HB 3, Engrossed 1", "reference_file": "./law_dataset\\CSCSHB_3_Online_Protections_for_Minors.pdf"}
{"provision_title": "Definitions.", "provision_body": "As used in this chapter: (1) \"Account holder\" means a person who has, or opens, an account or profile to use a social media company's platform. (2) \"Addiction\" means use of a social media platform that: (a) indicates the user's substantial preoccupation or obsession with, or the user's substantial difficulty to cease or reduce use of, the social media platform; and (b) causes physical, mental, emotional, developmental, or material harms to the user. (3) \"Director\" means the director of the Division of Consumer Protection created in Section 13-2-1. (4) \"Division\" means the Division of Consumer Protection created in Section 13-2-1. (5) \"Educational entity\" means a public school, an LEA, a charter school, the Utah Schools for the Deaf and Blind, a private school, a denominational school, a parochial school, a community college, a state college, a state university, or a nonprofit private postsecondary educational institution. (6) (a) \"Interactive computer service\" means an information service, information system, or information access software provider that: (i) provides or enables computer access by multiple users to a computer server; and (ii) provides access to the Internet. (b) \"Interactive computer service\" includes: (i) a web service; (ii) a web system; (iii) a website; (iv) a web application; or (v) a web portal. (7) \"Minor\" means an individual who is under the age of 18 and: (a) has not been emancipated as that term is defined in Section 80-7-102; or (b) has not been married. (8) \"Post\" means content that an account holder makes available on a social media platform for other account holders or users to view. (9) \"Social media company\" means a person or entity that: (a) provides a social media platform that has at least 5,000,000 account holders worldwide; and (b) is an interactive computer service. (10) (a) \"Social media platform\" means an online forum that a social media company makes available for an account holder to: (i) create a profile; (ii) upload posts; (iii) view the posts of other account holders; and (iv) interact with other account holders or users. (b) \"Social media platform\" does not include an online service, website, or application: (i) where the predominant or exclusive function is: (A) electronic mail; (B) direct messaging consisting of text, photos, or videos that are sent between devices by electronic means, where messages are: (I) shared between the sender and the recipient; (II) only visible to the sender and the recipient; and (III) are not posted publicly; (C) a streaming service that: (I) provides only licensed media in a continuous flow from the service, website, or application to the end user; and (II) does not obtain a license to the media from a user or account holder by agreement to its terms of service; (D) news, sports, entertainment, or other content that is preselected by the provider and not user generated, and any chat, comment, or interactive functionality that is provided incidental to, directly related to, or dependent upon provision of the content; (E) online shopping or e-commerce, if the interaction with other users or account holders is generally limited to: (I) the ability to upload a post and comment on reviews; (II) the ability to display lists or collections of goods for sale or wish lists; and (III) other functions that are focused on online shopping or e-commerce rather than interaction between users or account holders; (F) interactive gaming, virtual gaming, or an online service, that allows the creation and uploading of content for the purpose of interactive gaming, edutainment, or associated entertainment, and the communication related to that content; (G) photo editing that has an associated photo hosting service, if the interaction with other users or account holders is generally limited to liking or commenting; (H) a professional creative network for showcasing and discovering artistic content, if the content is required to be non-pornographic; (I) single-purpose community groups for public safety if: (I) the interaction with other users or account holders is generally limited to that single purpose; and (II) the community group has guidelines or policies against illegal content; (J) providing career development opportunities, including professional networking, job skills, learning certifications, and job posting and application services; (K) business to business software; (L) a teleconferencing or videoconferencing service that allows reception and transmission of audio and video signals for real time communication; (M) cloud storage; (N) shared document collaboration; (O) cloud computing services, which may include cloud storage and shared document collaboration; (P) providing access to or interacting with data visualization platforms, libraries, or hubs; (Q) to permit comments on a digital news website, if the news content is posted only by the provider of the digital news website; (R) providing or obtaining technical support for a platform, product, or service; (S) academic or scholarly research; or (T) genealogical research; or (ii) where: (A) the majority of the content that is posted or created is posted or created by the provider of the online service, website, or application; and (B) the ability to chat, comment, or interact with other users is directly related to the provider's content; (iii) that is a classified ad service that only permits the sale of goods and prohibits the solicitation of personal services; or (iv) that is used by and under the direction of an educational entity, including: (A) a learning management system; (B) a student engagement program; and (C) a subject or skill-specific program. (11) \"User\" means a person who has access to view all, or some of, the posts on a social media platform, but is not an account holder. (12) (a) \"Utah account holder\" means a person who is a Utah resident and an account holder. (b) \"Utah account holder\" includes a Utah minor account holder. (13) \"Utah minor account holder\" means a Utah account holder who is a minor. (14) \"Utah resident\" means an individual who currently resides in Utah. Enacted by Chapter 477, 2023 General Session Enacted by Chapter 498, 2023 General Session", "provision_code": "13-63-101", "country": "United States", "region": "Utah", "relevant_labels": "Social Media, Minors, Parental Consent, Age Verification, Data Collection, Advertising, Addiction, Enforcement, Private Right of Action, Consumer Protection", "law_code": "Utah Code Title 13, Chapter 63", "reference_file": "./law_dataset\\Utah Social Media Regulation Act.pdf"}
{"provision_title": "Age requirements for use of social media platform -- Parental consent -- Rulemaking authority of division.", "provision_body": "(1) Beginning March 1, 2024, a social media company may not permit a Utah resident who is a minor to be an account holder on the social media company's social media platform unless the Utah resident has the express consent of a parent or guardian. (2) Notwithstanding any provision of this chapter, a social media company may not permit a Utah resident who is a minor to hold or open an account on a social media platform if the minor is ineligible to hold or open an account under any other provision of state or federal law. (3) (a) Beginning March 1, 2024, a social media company shall verify the age of an existing or new Utah account holder and, if the existing or new account holder is a minor, confirm that a minor has consent as required under Subsection (1): (i) for a new account, at the time the Utah resident opens the account; or (ii) for a Utah account holder who has not provided age verification as required under this section, within 14 calendar days of the Utah account holder's attempt to access the account. (b) If a Utah account holder fails to meet the verification requirements of this section within the required time period, the social media company shall deny access to the account: (i) upon the expiration of the time period; and (ii) until all verification requirements are met. (4) In accordance with Title 63G, Chapter 3, Utah Administrative Rulemaking Act, the division, with consideration of stakeholder input, shall make rules to: (a) establish processes or means by which a social media company may meet the age verification requirements of this chapter; (b) establish acceptable forms or methods of identification, which may not be limited to a valid identification card issued by a government entity; (c) establish requirements for providing confirmation of the receipt of any information provided by a person seeking to verify age under this chapter; (d) establish processes or means to confirm that a parent or guardian has provided consent for the minor to open or use an account as required under this section; (e) establish requirements for retaining, protecting, and securely disposing of any information obtained by a social media company or its agent as a result of compliance with the requirements of this chapter; (f) require that information obtained by a social media company or its agent in order to comply with the requirements of this chapter are only retained for the purpose of compliance and may not be used for any other purpose; (g) if the division permits an agent to process verification requirements required by this section, require that the agent have its principal place of business in the United States of America; (h) require other applicable state agencies to comply with any rules promulgated under the authority of this section; and (i) ensure that the rules are consistent with state and federal law, including Title 13, Chapter 61, Utah Consumer Privacy Act. Enacted by Chapter 498, 2023 General Session", "provision_code": "13-63-102", "country": "United States", "region": "Utah", "relevant_labels": "Social Media, Minors, Parental Consent, Age Verification, Data Collection, Advertising, Addiction, Enforcement, Private Right of Action, Consumer Protection", "law_code": "Utah Code Title 13, Chapter 63", "reference_file": "./law_dataset\\Utah Social Media Regulation Act.pdf"}
{"provision_title": "Prohibition on data collection for certain accounts -- Prohibition on advertising -- Use of information -- Search results -- Directed content.", "provision_body": "Beginning March 1, 2024, a social media company, for a social media platform account held by a Utah minor account holder: (1) shall prohibit direct messaging between the account and any other user that is not linked to the account through friending; (2) may not show the account in search results for any user that is not linked to the account through friending; (3) shall prohibit the display of any advertising in the account; (4) shall not collect or use any personal information from the posts, content, messages, text, or usage activities of the account other than information that is necessary to comply with, and to verify compliance with, state or federal law, which information includes a parent or guardian's name, a birth date, and any other information required to be submitted under this section; and (5) shall prohibit the use of targeted or suggested groups, services, products, posts, accounts, or users in the account. Enacted by Chapter 498, 2023 General Session", "provision_code": "13-63-103", "country": "United States", "region": "Utah", "relevant_labels": "Social Media, Minors, Parental Consent, Age Verification, Data Collection, Advertising, Addiction, Enforcement, Private Right of Action, Consumer Protection", "law_code": "Utah Code Title 13, Chapter 63", "reference_file": "./law_dataset\\Utah Social Media Regulation Act.pdf"}
{"provision_title": "Parental access to social media account.", "provision_body": "Beginning March 1, 2024, a social media company shall provide a parent or guardian who has given parental consent for a Utah minor account holder under Section 13-63-102 with a password or other means for the parent or guardian to access the account, which shall allow the parent or guardian to view: (1) all posts the Utah minor account holder makes under the social media platform account; and (2) all responses and messages sent to or by the Utah minor account holder in the social media platform account. Enacted by Chapter 498, 2023 General Session", "provision_code": "13-63-104", "country": "United States", "region": "Utah", "relevant_labels": "Social Media, Minors, Parental Consent, Age Verification, Data Collection, Advertising, Addiction, Enforcement, Private Right of Action, Consumer Protection", "law_code": "Utah Code Title 13, Chapter 63", "reference_file": "./law_dataset\\Utah Social Media Regulation Act.pdf"}
{"provision_title": "Limited hours of access for minors -- Parental access and options.", "provision_body": "(1) Beginning March 1, 2024, a social media company shall prohibit a Utah minor account holder from having access to the Utah minor account holder's account during the hours of 10:30 p.m. to 6:30 a.m., unless the access is modified according to another requirement of this section. (2) Time of day under this section shall be calculated based on the Internet protocol address being used by the Utah minor account holder at the time of attempting access. (3) A social media company shall provide options for a parent or guardian with access to an account under Section 13-63-104 to: (a) change or eliminate the time-of-day restriction described in Subsection (1); and (b) set a limit on the number of hours per day that a Utah minor account holder may use the account. (4) A social media company shall not permit a Utah minor account holder to change or bypass restrictions on access as required by this section. (5) Notwithstanding any provision of this section, a social media company shall permit a parent or guardian with access to an account under Section 13-63-104 to access the account without time restrictions. Enacted by Chapter 498, 2023 General Session", "provision_code": "13-63-105", "country": "United States", "region": "Utah", "relevant_labels": "Social Media, Minors, Parental Consent, Age Verification, Data Collection, Advertising, Addiction, Enforcement, Private Right of Action, Consumer Protection", "law_code": "Utah Code Title 13, Chapter 63", "reference_file": "./law_dataset\\Utah Social Media Regulation Act.pdf"}
{"provision_title": "Investigative powers of the division.", "provision_body": "(1) The division shall receive consumer complaints alleging a violation of Part 1, General Requirements. (2) A person may file a consumer complaint that alleges a violation under Part 1, General Requirements, with the division. (3) The division shall investigate a consumer complaint to determine whether a violation of Part 1, General Requirements, occurred. Enacted by Chapter 498, 2023 General Session", "provision_code": "13-63-201", "country": "United States", "region": "Utah", "relevant_labels": "Social Media, Minors, Parental Consent, Age Verification, Data Collection, Advertising, Addiction, Enforcement, Private Right of Action, Consumer Protection", "law_code": "Utah Code Title 13, Chapter 63", "reference_file": "./law_dataset\\Utah Social Media Regulation Act.pdf"}
{"provision_title": "Enforcement powers of the division.", "provision_body": "(1) Except for a private right of action under Section 13-63-301, the division has the exclusive authority to administer and enforce the requirements of Part 1, General Requirements. (2) The attorney general, upon request, shall give legal advice to, and act as counsel for, the division in the exercise of the division's responsibilities under this part. (3) (a) Subject to the ability to cure an alleged violation under Subsection (4): (i) the division director may impose an administrative fine of up to $2,500 for each violation of Part 1, General Requirements; and (ii) the division may bring an action in a court of competent jurisdiction to enforce a provision of Part 1, General Requirements. (b) In a court action by the division to enforce a provision of Part 1, General Requirements, the court may: (i) declare that the act or practice violates a provision of Part 1, General Requirements; (ii) issue an injunction for a violation of Part 1, General Requirements; (iii) order disgorgement of any money received in violation of Part 1, General Requirements; (iv) order payment of disgorged money to an injured purchaser or consumer; (v) impose a civil penalty of up to $2,500 for each violation of Part 1, General Requirements; (vi) award actual damages to an injured purchaser or consumer; and (vii) award any other relief that the court deems reasonable and necessary. (4) (a) At least 30 days before the day on which the division initiates an enforcement action against a person that is subject to the requirements of Part 1, General Requirements, the division shall provide the person with: (i) written notice that identifies each alleged violation; and (ii) an explanation of the basis for each allegation. (b) Except as provided under Subsection (4)(c), the division may not initiate an action if the person: (i) cures the noticed violation within 30 days after the day on which the person receives the notice described in Subsection (4)(a); and (ii) provides the division with a written statement that: (A) the person has cured the violation; and (B) no further violation will occur. (c) The division may initiate a civil action against a person that: (i) fails to cure a violation after receiving the notice described in Subsection (4)(a); or (ii) after curing a noticed violation and providing a written statement in accordance with Subsection (4)(b), commits another violation of the same provision. (5) If a court of competent jurisdiction grants judgment or injunctive relief to the division, the court shall award the division: (a) reasonable attorney fees; (b) court costs; and (c) investigative fees. (6) (a) A person who violates an administrative or court order issued for a violation of Part 1, General Requirements, is subject to a civil penalty of no more than $5,000 for each violation. (b) A civil penalty authorized under this section may be imposed in any civil action brought by the division, or by the attorney general on behalf of the division. (7) All money received for the payment of a fine or civil penalty imposed under this section shall be deposited into the Consumer Protection Education and Training Fund established in Section 13-2-8. Enacted by Chapter 498, 2023 General Session", "provision_code": "13-63-202", "country": "United States", "region": "Utah", "relevant_labels": "Social Media, Minors, Parental Consent, Age Verification, Data Collection, Advertising, Addiction, Enforcement, Private Right of Action, Consumer Protection", "law_code": "Utah Code Title 13, Chapter 63", "reference_file": "./law_dataset\\Utah Social Media Regulation Act.pdf"}
{"provision_title": "Division report.", "provision_body": "(1) The division shall compile an annual report: (a) evaluating the liability and enforcement provisions of this chapter, including: (i) the effectiveness of the division's efforts to enforce this chapter; and (ii) any recommendations for changes to this chapter; (b) summarizing the consumer interactions that are protected and not protected by this chapter, including a list of alleged violations the division has received; and (c) an accounting of: (i) all administrative fines and civil penalties assessed during the year; (ii) all administrative fines and civil penalties collected during the year; and (iii) the use of funds from the Consumer Protection Education and Training Fund. (2) The division may update or correct the report as new information becomes available. (3) The division shall submit the report to the Business and Labor Interim Committee on or before the August meeting of each interim period. Enacted by Chapter 498, 2023 General Session", "provision_code": "13-63-203", "country": "United States", "region": "Utah", "relevant_labels": "Social Media, Minors, Parental Consent, Age Verification, Data Collection, Advertising, Addiction, Enforcement, Private Right of Action, Consumer Protection", "law_code": "Utah Code Title 13, Chapter 63", "reference_file": "./law_dataset\\Utah Social Media Regulation Act.pdf"}
{"provision_title": "Private right of action.", "provision_body": "(1) Beginning March 1, 2024, a person may bring an action against a person that does not comply with a requirement of Part 1, General Requirements. (2) A suit filed under the authority of this section shall be filed in the district court for the district in which a person bringing the action resides. (3) If a court finds that a person has violated a provision of Part 1, General Requirements, the person who brings an action under this section is entitled to: (a) an award of reasonable attorney fees and court costs; and (b) an amount equal to the greater of: (i) $2,500 per each incident of violation; or (ii) actual damages for financial, physical, and emotional harm incurred by the person bringing the action, if the court determines that the harm is a direct consequence of the violation or violations. Enacted by Chapter 498, 2023 General Session", "provision_code": "13-63-301", "country": "United States", "region": "Utah", "relevant_labels": "Social Media, Minors, Parental Consent, Age Verification, Data Collection, Advertising, Addiction, Enforcement, Private Right of Action, Consumer Protection", "law_code": "Utah Code Title 13, Chapter 63", "reference_file": "./law_dataset\\Utah Social Media Regulation Act.pdf"}
{"provision_title": "Social media platform design regulations -- Enforcement and auditing authority -- Penalties.", "provision_body": "(1) Beginning March 1, 2024: (a) the division shall administer and enforce the provisions of this section; and (b) the division may audit the records of a social media company in order to determine compliance with the requirements of this section or to investigate a complaint, including a random sample of a social media company's records and other audit methods. (2) Beginning March 1, 2024, a social media company shall not use a practice, design, or feature on the company's social media platform that the social media company knows, or which by the exercise of reasonable care should know, causes a Utah minor account holder to have an addiction to the social media platform. (3) Beginning March 1, 2024: (a) Subject to Subsection (3)(b), a social media company is subject to: (i) a civil penalty of $250,000 for each practice, design, or feature shown to have caused addiction; and (ii) a civil penalty of up to $2,500 for each Utah minor account holder who is shown to have been exposed to the practice, design, or feature found to have caused addiction under Subsection (3)(a)(i). (b) A social media company shall not be subject to a civil penalty for violating this section if the social media company, as an affirmative defense, demonstrates that the social media company: (i) instituted and maintained a program of at least quarterly audits of the social media company's practices, designs, and features to detect practices, designs, or features that have the potential to cause or contribute to the addiction of a minor user; and (ii) corrected, within 30 days of the completion of an audit described in Subsection (3)(b)(i), any practice, design, or feature discovered by the audit to present more than a de minimus risk of violating this section. (c) In a court action by the division to enforce this section, the court may, in addition to a civil penalty: (i) declare that the act or practice violates a provision of this section; (ii) issue an injunction for a violation of this section; (iii) award actual damages to an injured purchaser or consumer; and (iv) award any other relief that the court deems reasonable and necessary. (4) Nothing in this section may be construed to impose liability for a social media company for any of the following: (a) content that is generated by an account holder, or uploaded to or shared on the platform by an account holder, that may be encountered by another account holder; (b) passively displaying content that is created entirely by a third party; (c) information or content for which the social media company was not, in whole or in part, responsible for creating or developing; or (d) any conduct by a social media company involving a Utah minor account holder who would otherwise be protected by federal or Utah law. (5) If a court of competent jurisdiction grants judgment or injunctive relief to the division, the court shall award the division: (a) reasonable attorney fees; (b) court costs; and (c) investigative fees. (6) Nothing in this section may be construed to negate or limit a cause of action that may have existed or exists against a social media company under the law as it existed before the effective date of this section. (7) All money received for the payment of a fine or civil penalty imposed under this section shall be deposited into the Consumer Protection Education and Training Fund established in Section 13-2-8. Enacted by Chapter 477, 2023 General Session", "provision_code": "13-63-401", "country": "United States", "region": "Utah", "relevant_labels": "Social Media, Minors, Parental Consent, Age Verification, Data Collection, Advertising, Addiction, Enforcement, Private Right of Action, Consumer Protection", "law_code": "Utah Code Title 13, Chapter 63", "reference_file": "./law_dataset\\Utah Social Media Regulation Act.pdf"}
{"provision_title": "Private right of action for harm to a minor -- Rebuttable presumption of harm and causation.", "provision_body": "(1) Beginning March 1, 2024, a person may bring an action under this section against a social media company to recover damages incurred after March 1, 2024 by a Utah minor account holder for any addiction, financial, physical, or emotional harm suffered as a consequence of using or having an account on the social media company's social media platform. (2) A suit filed under the authority of this section shall be filed in the district court for the district in which the Utah minor account holder resides. (3) Notwithstanding Subsection (4), if a court finds that a Utah minor account holder has been harmed as a consequence of using or having an account on the social media company's social media platform, the minor seeking relief under this section is entitled to: (a) an award of reasonable attorney fees and court costs; and (b) an amount equal to the greater of: (i) $2,500 per each incident of harm; or (ii) actual damages for addiction, financial, physical, and emotional harm incurred by the person bringing the action, if the court determines that the harm is a direct consequence of the violation or violations. (4) If a Utah minor account holder seeking recovery of damages under this section is under the age of 16, there shall be a rebuttable presumption that the harm actually occurred and that the harm was a caused as a consequence of using or having an account on the social media company's social media platform. Enacted by Chapter 477, 2023 General Session", "provision_code": "13-63-501", "country": "United States", "region": "Utah", "relevant_labels": "Social Media, Minors, Parental Consent, Age Verification, Data Collection, Advertising, Addiction, Enforcement, Private Right of Action, Consumer Protection", "law_code": "Utah Code Title 13, Chapter 63", "reference_file": "./law_dataset\\Utah Social Media Regulation Act.pdf"}
{"provision_title": "Waiver prohibited.", "provision_body": "A waiver or limitation, or a purported waiver or limitation, of any of the following is void as unlawful, is against public policy, and a court or arbitrator may not enforce or give effect to the waiver, notwithstanding any contract or choice-of-law provision in a contract: (1) a protection or requirement provided under this chapter; (2) the right to cooperate with the division or to file a complaint with the division; (3) the right to a private right of action as provided under this chapter; or (4) the right to recover actual damages, statutory damages, civil penalties, costs, or fees as allowed by this chapter. Enacted by Chapter 477, 2023 General Session Enacted by Chapter 498, 2023 General Session", "provision_code": "13-63-601", "country": "United States", "region": "Utah", "relevant_labels": "Social Media, Minors, Parental Consent, Age Verification, Data Collection, Advertising, Addiction, Enforcement, Private Right of Action, Consumer Protection", "law_code": "Utah Code Title 13, Chapter 63", "reference_file": "./law_dataset\\Utah Social Media Regulation Act.pdf"}
{"provision_title": "Severability.", "provision_body": "If any provision of this chapter or the application of any provision to any person or circumstance is held invalid by a final decision of a court of competent jurisdiction, the remainder of this chapter shall be given effect without the invalid provision or application. The provisions of this chapter are severable. Enacted by Chapter 477, 2023 General Session Enacted by Chapter 498, 2023 General Session", "provision_code": "13-63-701", "country": "United States", "region": "Utah", "relevant_labels": "Social Media, Minors, Parental Consent, Age Verification, Data Collection, Advertising, Addiction, Enforcement, Private Right of Action, Consumer Protection", "law_code": "Utah Code Title 13, Chapter 63", "reference_file": "./law_dataset\\Utah Social Media Regulation Act.pdf"}
{"provision_title": "Subject matter", "provision_body": "1. The aim of this Regulation is to contribute to the proper functioning of the internal market for intermediary services by setting out harmonised rules for a safe, predictable and trusted online environment that facilitates innovation and in which fundamental rights enshrined in the Charter, including the principle of consumer protection, are effectively protected. 2. This Regulation lays down harmonised rules on the provision of intermediary services in the internal market. In particular, it establishes: (a) a framework for the conditional exemption from liability of providers of intermediary services; (b) rules on specific due diligence obligations tailored to certain specific categories of providers of intermediary services; (c) rules on the implementation and enforcement of this Regulation, including as regards the cooperation of and coordination between the competent authorities.", "provision_code": "Article 1", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Scope", "provision_body": "1. This Regulation shall apply to intermediary services offered to recipients of the service that have their place of establishment or are located in the Union, irrespective of where the providers of those intermediary services have their place of establishment. 2. This Regulation shall not apply to any service that is not an intermediary service or to any requirements imposed in respect of such a service, irrespective of whether the service is provided through the use of an intermediary service. 3. This Regulation shall not affect the application of Directive 2000/31/EC. 4. This Regulation is without prejudice to the rules laid down by other Union legal acts regulating other aspects of the provision of intermediary services in the internal market or specifying and complementing this Regulation, in particular, the following: (a) Directive 2010/13/EU; (b) Union law on copyright and related rights; (c) Regulation (EU) 2021/784; (d) Regulation (EU) 2019/1148; (e) Regulation (EU) 2019/1150; (f) Union law on consumer protection and product safety, including Regulations (EU) 2017/2394 and (EU) 2019/1020 and Directives 2001/95/EC and 2013/11/EU; (g) Union law on the protection of personal data, in particular Regulation (EU) 2016/679 and Directive 2002/58/EC; (h) Union law in the field of judicial cooperation in civil matters, in particular Regulation (EU) No 1215/2012 or any Union legal act laying down the rules on law applicable to contractual and non-contractual obligations; (i) Union law in the field of judicial cooperation in criminal matters, in particular a Regulation on European Production and Preservation Orders for electronic evidence in criminal matters; (j) a Directive laying down harmonised rules on the appointment of legal representatives for the purpose of gathering evidence in criminal proceedings.", "provision_code": "Article 2", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Definitions", "provision_body": "For the purpose of this Regulation, the following definitions shall apply: (a) \u2018information society service\u2019 means a \u2018service\u2019 as defined in Article 1(1), point (b), of Directive (EU) 2015/1535; (b) \u2018recipient of the service\u2019 means any natural or legal person who uses an intermediary service, in particular for the purposes of seeking information or making it accessible; (c) \u2018consumer\u2019 means any natural person who is acting for purposes which are outside his or her trade, business, craft, or profession; (d) \u2018to offer services in the Union\u2019 means enabling natural or legal persons in one or more Member States to use the services of a provider of intermediary services that has a substantial connection to the Union; (e) \u2018substantial connection to the Union\u2019 means a connection of a provider of intermediary services with the Union resulting either from its establishment in the Union or from specific factual criteria, such as: \u2014 a significant number of recipients of the service in one or more Member States in relation to its or their population; or \u2014 the targeting of activities towards one or more Member States; (f) \u2018trader\u2019 means any natural person, or any legal person irrespective of whether it is privately or publicly owned, who is acting, including through any person acting in his or her name or on his or her behalf, for purposes relating to his or her trade, business, craft or profession; (g) \u2018intermediary service\u2019 means one of the following information society services: (i) a \u2018mere conduit\u2019 service, consisting of the transmission in a communication network of information provided by a recipient of the service, or the provision of access to a communication network; (ii) a \u2018caching\u2019 service, consisting of the transmission in a communication network of information provided by a recipient of the service, involving the automatic, intermediate and temporary storage of that information, performed for the sole purpose of making more efficient the information's onward transmission to other recipients upon their request; (iii) a \u2018hosting\u2019 service, consisting of the storage of information provided by, and at the request of, a recipient of the service; (h) \u2018illegal content\u2019 means any information that, in itself or in relation to an activity, including the sale of products or the provision of services, is not in compliance with Union law or the law of any Member State which is in compliance with Union law, irrespective of the precise subject matter or nature of that law; (i) \u2018online platform\u2019 means a hosting service that, at the request of a recipient of the service, stores and disseminates information to the public, unless that activity is a minor and purely ancillary feature of another service or a minor functionality of the principal service and, for objective and technical reasons, cannot be used without that other service, and the integration of the feature or functionality into the other service is not a means to circumvent the applicability of this Regulation; (j) \u2018online search engine\u2019 means an intermediary service that allows users to input queries in order to perform searches of, in principle, all websites, or all websites in a particular language, on the basis of a query on any subject in the form of a keyword, voice request, phrase or other input, and returns results in any format in which information related to the requested content can be found; (k) \u2018dissemination to the public\u2019 means making information available, at the request of the recipient of the service who provided the information, to a potentially unlimited number of third parties; (l) \u2018distance contract\u2019 means \u2018distance contract\u2019 as defined in Article 2, point (7), of Directive 2011/83/EU; (m) \u2018online interface\u2019 means any software, including a website or a part thereof, and applications, including mobile applications; (n) \u2018Digital Services Coordinator of establishment\u2019 means the Digital Services Coordinator of the Member State where the main establishment of a provider of an intermediary service is located or its legal representative resides or is established; (o) \u2018Digital Services Coordinator of destination\u2019 means the Digital Services Coordinator of a Member State where the intermediary service is provided; (p) \u2018active recipient of an online platform\u2019 means a recipient of the service that has engaged with an online platform by either requesting the online platform to host information or being exposed to information hosted by the online platform and disseminated through its online interface; (q) \u2018active recipient of an online search engine\u2019 means a recipient of the service that has submitted a query to an online search engine and been exposed to information indexed and presented on its online interface; (r) \u2018advertisement\u2019 means information designed to promote the message of a legal or natural person, irrespective of whether to achieve commercial or non-commercial purposes, and presented by an online platform on its online interface against remuneration specifically for promoting that information; (s) \u2018recommender system\u2019 means a fully or partially automated system used by an online platform to suggest in its online interface specific information to recipients of the service or prioritise that information, including as a result of a search initiated by the recipient of the service or otherwise determining the relative order or prominence of information displayed; (t) \u2018content moderation\u2019 means the activities, whether automated or not, undertaken by providers of intermediary services, that are aimed, in particular, at detecting, identifying and addressing illegal content or information incompatible with their terms and conditions, provided by recipients of the service, including measures taken that affect the availability, visibility, and accessibility of that illegal content or that information, such as demotion, demonetisation, disabling of access to, or removal thereof, or that affect the ability of the recipients of the service to provide that information, such as the termination or suspension of a recipient\u2019s account; (u) \u2018terms and conditions\u2019 means all clauses, irrespective of their name or form, which govern the contractual relationship between the provider of intermediary services and the recipients of the service; (v) \u2018persons with disabilities\u2019 means \u2018persons with disabilities\u2019 as referred to in Article 3, point (1), of Directive (EU) 2019/882 of the European Parliament and of the Council (38); (w) \u2018commercial communication\u2019 means \u2018commercial communication\u2019 as defined in Article 2, point (f), of Directive 2000/ 31/EC; (x) \u2018turnover\u2019 means the amount derived by an undertaking within the meaning of Article 5(1) of Council Regulation (EC) No 139/2004 (39).", "provision_code": "Article 3", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "\u2018Mere conduit\u2019", "provision_body": "1. Where an information society service is provided that consists of the transmission in a communication network of information provided by a recipient of the service, or the provision of access to a communication network, the service provider shall not be liable for the information transmitted or accessed, on condition that the provider: (a) does not initiate the transmission; (b) does not select the receiver of the transmission; and (c) does not select or modify the information contained in the transmission. 2. The acts of transmission and of provision of access referred to in paragraph 1 shall include the automatic, intermediate and transient storage of the information transmitted in so far as this takes place for the sole purpose of carrying out the transmission in the communication network, and provided that the information is not stored for any period longer than is reasonably necessary for the transmission. 3. This Article shall not affect the possibility for a judicial or administrative authority, in accordance with a Member State\u2019s legal system, to require the service provider to terminate or prevent an infringement.", "provision_code": "Article 4", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "\u2018Caching\u2019", "provision_body": "1. Where an information society service is provided that consists of the transmission in a communication network of information provided by a recipient of the service, the service provider shall not be liable for the automatic, intermediate and temporary storage of that information, performed for the sole purpose of making more efficient or more secure the information's onward transmission to other recipients of the service upon their request, on condition that the provider: (a) does not modify the information; (b) complies with conditions on access to the information; (c) complies with rules regarding the updating of the information, specified in a manner widely recognised and used by industry; (d) does not interfere with the lawful use of technology, widely recognised and used by industry, to obtain data on the use of the information; and (e) acts expeditiously to remove or to disable access to the information it has stored upon obtaining actual knowledge of the fact that the information at the initial source of the transmission has been removed from the network, or access to it has been disabled, or that a judicial or an administrative authority has ordered such removal or disablement. 2. This Article shall not affect the possibility for a judicial or administrative authority, in accordance with a Member State\u2019s legal system, to require the service provider to terminate or prevent an infringement.", "provision_code": "Article 5", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Hosting", "provision_body": "1. Where an information society service is provided that consists of the storage of information provided by a recipient of the service, the service provider shall not be liable for the information stored at the request of a recipient of the service, on condition that the provider: (a) does not have actual knowledge of illegal activity or illegal content and, as regards claims for damages, is not aware of facts or circumstances from which the illegal activity or illegal content is apparent; or (b) upon obtaining such knowledge or awareness, acts expeditiously to remove or to disable access to the illegal content. 2. Paragraph 1 shall not apply where the recipient of the service is acting under the authority or the control of the provider. 3. Paragraph 1 shall not apply with respect to the liability under consumer protection law of online platforms that allow consumers to conclude distance contracts with traders, where such an online platform presents the specific item of information or otherwise enables the specific transaction at issue in a way that would lead an average consumer to believe that the information, or the product or service that is the object of the transaction, is provided either by the online platform itself or by a recipient of the service who is acting under its authority or control. 4. This Article shall not affect the possibility for a judicial or administrative authority, in accordance with a Member State's legal system, to require the service provider to terminate or prevent an infringement.", "provision_code": "Article 6", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Voluntary own-initiative investigations and legal compliance", "provision_body": "Providers of intermediary services shall not be deemed ineligible for the exemptions from liability referred to in Articles 4, 5 and 6 solely because they, in good faith and in a diligent manner, carry out voluntary own-initiative investigations into, or take other measures aimed at detecting, identifying and removing, or disabling access to, illegal content, or take the necessary measures to comply with the requirements of Union law and national law in compliance with Union law, including the requirements set out in this Regulation.", "provision_code": "Article 7", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "No general monitoring or active fact-finding obligations", "provision_body": "No general obligation to monitor the information which providers of intermediary services transmit or store, nor actively to seek facts or circumstances indicating illegal activity shall be imposed on those providers.", "provision_code": "Article 8", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Orders to act against illegal content", "provision_body": "1. Upon the receipt of an order to act against one or more specific items of illegal content, issued by the relevant national judicial or administrative authorities, on the basis of the applicable Union law or national law in compliance with Union law, providers of intermediary services shall inform the authority issuing the order, or any other authority specified in the order, of any effect given to the order without undue delay, specifying if and when effect was given to the order. 2. Member States shall ensure that when an order referred to in paragraph 1 is transmitted to the provider, it meets at least the following conditions: (a) that order contains the following elements: (i) a reference to the legal basis under Union or national law for the order; (ii) a statement of reasons explaining why the information is illegal content, by reference to one or more specific provisions of Union law or national law in compliance with Union law; (iii) information identifying the issuing authority; (iv) clear information enabling the provider of intermediary services to identify and locate the illegal content concerned, such as one or more exact URL and, where necessary, additional information; (v) information about redress mechanisms available to the provider of intermediary services and to the recipient of the service who provided the content; (vi) where applicable, information about which authority is to receive the information about the effect given to the orders; (b) the territorial scope of that order, on the basis of the applicable rules of Union and national law, including the Charter, and, where relevant, general principles of international law, is limited to what is strictly necessary to achieve its objective; (c) that order is transmitted in one of the languages declared by the provider of intermediary services pursuant to Article 11(3) or in another official language of the Member States, agreed between the authority issuing the order and that provider, and is sent to the electronic point of contact designated by that provider, in accordance with Article 11; where the order is not drafted in the language declared by the provider of intermediary services or in another bilaterally agreed language, the order may be transmitted in the language of the authority issuing the order, provided that it is accompanied by a translation into such declared or bilaterally agreed language of at least the elements set out in points (a) and (b) of this paragraph. 3. The authority issuing the order or, where applicable, the authority specified therein, shall transmit it, along with any information received from the provider of intermediary services concerning the effect given to that order to the Digital Services Coordinator from the Member State of the issuing authority. 4. After receiving the order from the judicial or administrative authority, the Digital Services Coordinator of the Member State concerned shall, without undue delay, transmit a copy of the order referred to in paragraph 1 of this Article to all other Digital Services Coordinators through the system established in accordance with Article 85. 5. At the latest when effect is given to the order or, where applicable, at the time provided by the issuing authority in its order, providers of intermediary services shall inform the recipient of the service concerned of the order received and to the effect given to it. Such information provided to the recipient of the service shall include a statement of reasons, the possibilities for redress that exist, and a description of the territorial scope of the order, in accordance with paragraph 2. 6. The conditions and requirements laid down in this Article shall be without prejudice to national civil and criminal procedural law.", "provision_code": "Article 9", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Orders to provide information", "provision_body": "1. Upon receipt of an order to provide specific information about one or more specific individual recipients of the service, issued by the relevant national judicial or administrative authorities on the basis of the applicable Union law or national law in compliance with Union law, providers of intermediary services shall, without undue delay inform the authority issuing the order, or any other authority specified in the order, of its receipt and of the effect given to the order, specifying if and when effect was given to the order. 2. Member States shall ensure that when an order referred to in paragraph 1 is transmitted to the provider, it meets at least the following conditions: (a) that order contains the following elements: (i) a reference to the legal basis under Union or national law for the order; (ii) information identifying the issuing authority; (iii) clear information enabling the provider of intermediary services to identify the specific recipient or recipients on whom information is sought, such as one or more account names or unique identifiers; (iv) a statement of reasons explaining the objective for which the information is required and why the requirement to provide the information is necessary and proportionate to determine compliance by the recipients of the intermediary services with applicable Union law or national law in compliance with Union law, unless such a statement cannot be provided for reasons related to the prevention, investigation, detection and prosecution of criminal offences; (v) information about redress mechanisms available to the provider and to the recipients of the service concerned; (vi) where applicable, information about which authority is to receive the information about the effect given to the orders; (b) that order only requires the provider to provide information already collected for the purposes of providing the service and which lies within its control; (c) that order is transmitted in one of the languages declared by the provider of intermediary services pursuant to Article 11(3) or in another official language of the Member States, agreed between the authority issuing the order and the provider, and is sent to the electronic point of contact designated by that provider, in accordance with Article 11; where the order is not drafted in the language declared by the provider of intermediary services or in another bilaterally agreed language, the order may be transmitted in the language of the authority issuing the order, provided that it is accompanied by a translation into such declared or bilaterally agreed language of at least the elements set out in points (a) and (b) of this paragraph. 3. The authority issuing the order or, where applicable, the authority specified therein, shall transmit it, along with any information received from the provider of intermediary services concerning the effect given to that order to the Digital Services Coordinator from the Member State of the issuing authority. 4. After receiving the order from the judicial or administrative authority, the Digital Services Coordinator of the Member State concerned shall, without undue delay, transmit a copy of the order referred to in paragraph 1 of this Article to all Digital Services Coordinators through the system established in accordance with Article 85. 5. At the latest when effect is given to the order, or, where applicable, at the time provided by the issuing authority in its order, providers of intermediary services shall inform the recipient of the service concerned of the order received and the effect given to it. Such information provided to the recipient of the service shall include a statement of reasons and the possibilities for redress that exist, in accordance with paragraph 2. 6. The conditions and requirements laid down in this Article shall be without prejudice to national civil and criminal procedural law.", "provision_code": "Article 10", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Points of contact for Member States\u2019 authorities, the Commission and the Board", "provision_body": "1. Providers of intermediary services shall designate a single point of contact to enable them to communicate directly, by electronic means, with Member States\u2019 authorities, the Commission and the Board referred to in Article 61 for the application of this Regulation. 2. Providers of intermediary services shall make public the information necessary to easily identify and communicate with their single points of contact. That information shall be easily accessible, and shall be kept up to date. 3. Providers of intermediary services shall specify in the information referred to in paragraph 2 the official language or languages of the Member States which, in addition to a language broadly understood by the largest possible number of Union citizens, can be used to communicate with their points of contact, and which shall include at least one of the official languages of the Member State in which the provider of intermediary services has its main establishment or where its legal representative resides or is established.", "provision_code": "Article 11", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Points of contact for recipients of the service", "provision_body": "1. Providers of intermediary services shall designate a single point of contact to enable recipients of the service to communicate directly and rapidly with them, by electronic means and in a user-friendly manner, including by allowing recipients of the service to choose the means of communication, which shall not solely rely on automated tools. 2. In addition to the obligations provided under Directive 2000/31/EC, providers of intermediary services shall make public the information necessary for the recipients of the service in order to easily identify and communicate with their single points of contact. That information shall be easily accessible, and shall be kept up to date.", "provision_code": "Article 12", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Legal representatives", "provision_body": "1. Providers of intermediary services which do not have an establishment in the Union but which offer services in the Union shall designate, in writing, a legal or natural person to act as their legal representative in one of the Member States where the provider offers its services. 2. Providers of intermediary services shall mandate their legal representatives for the purpose of being addressed in addition to or instead of such providers, by the Member States\u2019 competent authorities, the Commission and the Board, on all issues necessary for the receipt of, compliance with and enforcement of decisions issued in relation to this Regulation. Providers of intermediary services shall provide their legal representative with necessary powers and sufficient resources to guarantee their efficient and timely cooperation with the Member States\u2019 competent authorities, the Commission and the Board, and to comply with such decisions. 3. It shall be possible for the designated legal representative to be held liable for non-compliance with obligations under this Regulation, without prejudice to the liability and legal actions that could be initiated against the provider of intermediary services. 4. Providers of intermediary services shall notify the name, postal address, email address and telephone number of their legal representative to the Digital Services Coordinator in the Member State where that legal representative resides or is established. They shall ensure that that information is publicly available, easily accessible, accurate and kept up to date. 5. The designation of a legal representative within the Union pursuant to paragraph 1 shall not constitute an establishment in the Union.", "provision_code": "Article 13", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Terms and conditions", "provision_body": "1. Providers of intermediary services shall include information on any restrictions that they impose in relation to the use of their service in respect of information provided by the recipients of the service, in their terms and conditions. That information shall include information on any policies, procedures, measures and tools used for the purpose of content moderation, including algorithmic decision-making and human review, as well as the rules of procedure of their internal complaint handling system. It shall be set out in clear, plain, intelligible, user-friendly and unambiguous language, and shall be publicly available in an easily accessible and machine-readable format. 2. Providers of intermediary services shall inform the recipients of the service of any significant change to the terms and conditions. 3. Where an intermediary service is primarily directed at minors or is predominantly used by them, the provider of that intermediary service shall explain the conditions for, and any restrictions on, the use of the service in a way that minors can understand. 4. Providers of intermediary services shall act in a diligent, objective and proportionate manner in applying and enforcing the restrictions referred to in paragraph 1, with due regard to the rights and legitimate interests of all parties involved, including the fundamental rights of the recipients of the service, such as the freedom of expression, freedom and pluralism of the media, and other fundamental rights and freedoms as enshrined in the Charter. 5. Providers of very large online platforms and of very large online search engines shall provide recipients of services with a concise, easily-accessible and machine-readable summary of the terms and conditions, including the available remedies and redress mechanisms, in clear and unambiguous language. 6. Very large online platforms and very large online search engines within the meaning of Article 33 shall publish their terms and conditions in the official languages of all the Member States in which they offer their services.", "provision_code": "Article 14", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Transparency reporting obligations for providers of intermediary services", "provision_body": "1. Providers of intermediary services shall make publicly available, in a machine-readable format and in an easily accessible manner, at least once a year, clear, easily comprehensible reports on any content moderation that they engaged in during the relevant period. Those reports shall include, in particular, information on the following, as applicable: (a) for providers of intermediary services, the number of orders received from Member States\u2019 authorities including orders issued in accordance with Articles 9 and 10, categorised by the type of illegal content concerned, the Member State issuing the order, and the median time needed to inform the authority issuing the order, or any other authority specified in the order, of its receipt, and to give effect to the order; (b) for providers of hosting services, the number of notices submitted in accordance with Article 16, categorised by the type of alleged illegal content concerned, the number of notices submitted by trusted flaggers, any action taken pursuant to the notices by differentiating whether the action was taken on the basis of the law or the terms and conditions of the provider, the number of notices processed by using automated means and the median time needed for taking the action; (c) for providers of intermediary services, meaningful and comprehensible information about the content moderation engaged in at the providers\u2019 own initiative, including the use of automated tools, the measures taken to provide training and assistance to persons in charge of content moderation, the number and type of measures taken that affect the availability, visibility and accessibility of information provided by the recipients of the service and the recipients\u2019 ability to provide information through the service, and other related restrictions of the service; the information reported shall be categorised by the type of illegal content or violation of the terms and conditions of the service provider, by the detection method and by the type of restriction applied; (d) for providers of intermediary services, the number of complaints received through the internal complaint-handling systems in accordance with the provider\u2019s terms and conditions and additionally, for providers of online platforms, in accordance with Article 20, the basis for those complaints, decisions taken in respect of those complaints, the median time needed for taking those decisions and the number of instances where those decisions were reversed; (e) any use made of automated means for the purpose of content moderation, including a qualitative description, a specification of the precise purposes, indicators of the accuracy and the possible rate of error of the automated means used in fulfilling those purposes, and any safeguards applied. 2. Paragraph 1 of this Article shall not apply to providers of intermediary services that qualify as micro or small enterprises as defined in Recommendation 2003/361/EC and which are not very large online platforms within the meaning of Article 33 of this Regulation. 3. The Commission may adopt implementing acts to lay down templates concerning the form, content and other details of reports pursuant to paragraph 1 of this Article, including harmonised reporting periods. Those implementing acts shall be adopted in accordance with the advisory procedure referred to in Article 88.", "provision_code": "Article 15", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Notice and action mechanisms", "provision_body": "1. Providers of hosting services shall put mechanisms in place to allow any individual or entity to notify them of the presence on their service of specific items of information that the individual or entity considers to be illegal content. Those mechanisms shall be easy to access and user-friendly, and shall allow for the submission of notices exclusively by electronic means. 2. The mechanisms referred to in paragraph 1 shall be such as to facilitate the submission of sufficiently precise and adequately substantiated notices. To that end, the providers of hosting services shall take the necessary measures to enable and to facilitate the submission of notices containing all of the following elements: (a) a sufficiently substantiated explanation of the reasons why the individual or entity alleges the information in question to be illegal content; (b) a clear indication of the exact electronic location of that information, such as the exact URL or URLs, and, where necessary, additional information enabling the identification of the illegal content adapted to the type of content and to the specific type of hosting service; (c) the name and email address of the individual or entity submitting the notice, except in the case of information considered to involve one of the offences referred to in Articles 3 to 7 of Directive 2011/93/EU; (d) a statement confirming the bona fide belief of the individual or entity submitting the notice that the information and allegations contained therein are accurate and complete. 3. Notices referred to in this Article shall be considered to give rise to actual knowledge or awareness for the purposes of Article 6 in respect of the specific item of information concerned where they allow a diligent provider of hosting services to identify the illegality of the relevant activity or information without a detailed legal examination. 4. Where the notice contains the electronic contact information of the individual or entity that submitted it, the provider of hosting services shall, without undue delay, send a confirmation of receipt of the notice to that individual or entity. 5. The provider shall also, without undue delay, notify that individual or entity of its decision in respect of the information to which the notice relates, providing information on the possibilities for redress in respect of that decision. 6. Providers of hosting services shall process any notices that they receive under the mechanisms referred to in paragraph 1 and take their decisions in respect of the information to which the notices relate, in a timely, diligent, non arbitrary and objective manner. Where they use automated means for that processing or decision-making, they shall include information on such use in the notification referred to in paragraph 5.", "provision_code": "Article 16", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Statement of reasons", "provision_body": "1. Providers of hosting services shall provide a clear and specific statement of reasons to any affected recipients of the service for any of the following restrictions imposed on the ground that the information provided by the recipient of the service is illegal content or incompatible with their terms and conditions: (a) any restrictions of the visibility of specific items of information provided by the recipient of the service, including removal of content, disabling access to content, or demoting content; (b) suspension, termination or other restriction of monetary payments; (c) suspension or termination of the provision of the service in whole or in part; (d) suspension or termination of the recipient of the service's account. 2. Paragraph 1 shall only apply where the relevant electronic contact details are known to the provider. It shall apply at the latest from the date that the restriction is imposed, regardless of why or how it was imposed. Paragraph 1 shall not apply where the information is deceptive high-volume commercial content. 3. The statement of reasons referred to in paragraph 1 shall at least contain the following information: (a) information on whether the decision entails either the removal of, the disabling of access to, the demotion of or the restriction of the visibility of the information, or the suspension or termination of monetary payments related to that information, or imposes other measures referred to in paragraph 1 with regard to the information, and, where relevant, the territorial scope of the decision and its duration; (b) the facts and circumstances relied on in taking the decision, including, where relevant, information on whether the decision was taken pursuant to a notice submitted in accordance with Article 16 or based on voluntary own-initiative investigations and, where strictly necessary, the identity of the notifier; (c) where applicable, information on the use made of automated means in taking the decision, including information on whether the decision was taken in respect of content detected or identified using automated means; (d) where the decision concerns allegedly illegal content, a reference to the legal ground relied on and explanations as to why the information is considered to be illegal content on that ground; (e) where the decision is based on the alleged incompatibility of the information with the terms and conditions of the provider of hosting services, a reference to the contractual ground relied on and explanations as to why the information is considered to be incompatible with that ground; (f) clear and user-friendly information on the possibilities for redress available to the recipient of the service in respect of the decision, in particular, where applicable through internal complaint-handling mechanisms, out-of-court dispute settlement and judicial redress. 4. The information provided by the providers of hosting services in accordance with this Article shall be clear and easily comprehensible and as precise and specific as reasonably possible under the given circumstances. The information shall, in particular, be such as to reasonably allow the recipient of the service concerned to effectively exercise the possibilities for redress referred to in of paragraph 3, point (f). 5. This Article shall not apply to any orders referred to in Article 9.", "provision_code": "Article 17", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Notification of suspicions of criminal offences", "provision_body": "1. Where a provider of hosting services becomes aware of any information giving rise to a suspicion that a criminal offence involving a threat to the life or safety of a person or persons has taken place, is taking place or is likely to take place, it shall promptly inform the law enforcement or judicial authorities of the Member State or Member States concerned of its suspicion and provide all relevant information available. 2. Where the provider of hosting services cannot identify with reasonable certainty the Member State concerned, it shall inform the law enforcement authorities of the Member State in which it is established or where its legal representative resides or is established or inform Europol, or both. For the purpose of this Article, the Member State concerned shall be the Member State in which the offence is suspected to have taken place, to be taking place or to be likely to take place, or the Member State where the suspected offender resides or is located, or the Member State where the victim of the suspected offence resides or is located.", "provision_code": "Article 18", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Exclusion for micro and small enterprises", "provision_body": "1. This Section, with the exception of Article 24(3) thereof, shall not apply to providers of online platforms that qualify as micro or small enterprises as defined in Recommendation 2003/361/EC. This Section, with the exception of Article 24(3) thereof, shall not apply to providers of online platforms that previously qualified for the status of a micro or small enterprise as defined in Recommendation 2003/361/EC during the 12 months following their loss of that status pursuant to Article 4(2) thereof, except when they are very large online platforms in accordance with Article 33. 2. By derogation from paragraph 1 of this Article, this Section shall apply to providers of online platforms that have been designated as very large online platforms in accordance with Article 33, irrespective of whether they qualify as micro or small enterprises.", "provision_code": "Article 19", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Internal complaint-handling system", "provision_body": "1. Providers of online platforms shall provide recipients of the service, including individuals or entities that have submitted a notice, for a period of at least six months following the decision referred to in this paragraph, with access to an effective internal complaint-handling system that enables them to lodge complaints, electronically and free of charge, against the decision taken by the provider of the online platform upon the receipt of a notice or against the following decisions taken by the provider of the online platform on the grounds that the information provided by the recipients constitutes illegal content or is incompatible with its terms and conditions: (a) decisions whether or not to remove or disable access to or restrict visibility of the information; (b) decisions whether or not to suspend or terminate the provision of the service, in whole or in part, to the recipients; (c) decisions whether or not to suspend or terminate the recipients\u2019 account; (d) decisions whether or not to suspend, terminate or otherwise restrict the ability to monetise information provided by the recipients. 2. The period of at least six months referred to in paragraph 1 of this Article shall start on the day on which the recipient of the service is informed about the decision in accordance with Article 16(5) or Article 17. 3. Providers of online platforms shall ensure that their internal complaint-handling systems are easy to access, user friendly and enable and facilitate the submission of sufficiently precise and adequately substantiated complaints. 4. Providers of online platforms shall handle complaints submitted through their internal complaint-handling system in a timely, non-discriminatory, diligent and non-arbitrary manner. Where a complaint contains sufficient grounds for the provider of the online platform to consider that its decision not to act upon the notice is unfounded or that the information to which the complaint relates is not illegal and is not incompatible with its terms and conditions, or contains information indicating that the complainant\u2019s conduct does not warrant the measure taken, it shall reverse its decision referred to in paragraph 1 without undue delay. 5. Providers of online platforms shall inform complainants without undue delay of their reasoned decision in respect of the information to which the complaint relates and of the possibility of out-of-court dispute settlement provided for in Article 21 and other available possibilities for redress. 6. Providers of online platforms shall ensure that the decisions, referred to in paragraph 5, are taken under the supervision of appropriately qualified staff, and not solely on the basis of automated means.", "provision_code": "Article 20", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Out-of-court dispute settlement", "provision_body": "1. Recipients of the service, including individuals or entities that have submitted notices, addressed by the decisions referred to in Article 20(1) shall be entitled to select any out-of-court dispute settlement body that has been certified in accordance with paragraph 3 of this Article in order to resolve disputes relating to those decisions, including complaints that have not been resolved by means of the internal complaint-handling system referred to in that Article. Providers of online platforms shall ensure that information about the possibility for recipients of the service to have access to an out-of-court dispute settlement, as referred to in the first subparagraph, is easily accessible on their online interface, clear and user-friendly. The first subparagraph is without prejudice to the right of the recipient of the service concerned to initiate, at any stage, proceedings to contest those decisions by the providers of online platforms before a court in accordance with the applicable law. 2. Both parties shall engage, in good faith, with the selected certified out-of-court dispute settlement body with a view to resolving the dispute. Providers of online platforms may refuse to engage with such out-of-court dispute settlement body if a dispute has already been resolved concerning the same information and the same grounds of alleged illegality or incompatibility of content. The certified out-of-court dispute settlement body shall not have the power to impose a binding settlement of the dispute on the parties. 3. The Digital Services Coordinator of the Member State where the out-of-court dispute settlement body is established shall, for a maximum period of five years, which may be renewed, certify the body, at its request, where the body has demonstrated that it meets all of the following conditions: (a) it is impartial and independent, including financially independent, of providers of online platforms and of recipients of the service provided by providers of online platforms, including of individuals or entities that have submitted notices; (b) it has the necessary expertise in relation to the issues arising in one or more particular areas of illegal content, or in relation to the application and enforcement of terms and conditions of one or more types of online platform, allowing the body to contribute effectively to the settlement of a dispute; (c) its members are remunerated in a way that is not linked to the outcome of the procedure; (d) the out-of-court dispute settlement that it offers is easily accessible, through electronic communications technology and provides for the possibility to initiate the dispute settlement and to submit the requisite supporting documents online; (e) it is capable of settling disputes in a swift, efficient and cost-effective manner and in at least one of the official languages of the institutions of the Union; (f) the out-of-court dispute settlement that it offers takes place in accordance with clear and fair rules of procedure that are easily and publicly accessible, and that comply with applicable law, including this Article. The Digital Services Coordinator shall, where applicable, specify in the certificate: (a) the particular issues to which the body\u2019s expertise relates, as referred to in point (b) of the first subparagraph; and (b) the official language or languages of the institutions of the Union in which the body is capable of settling disputes, as referred to in point (e) of the first subparagraph. 4. Certified out-of-court dispute settlement bodies shall report to the Digital Services Coordinator that certified them, on an annual basis, on their functioning, specifying at least the number of disputes they received, the information about the outcomes of those disputes, the average time taken to resolve them and any shortcomings or difficulties encountered. They shall provide additional information at the request of that Digital Services Coordinator. Digital Services Coordinators shall, every two years, draw up a report on the functioning of the out-of-court dispute settlement bodies that they certified. That report shall in particular: (a) list the number of disputes that each certified out-of-court dispute settlement body has received annually; (b) indicate the outcomes of the procedures brought before those bodies and the average time taken to resolve the disputes; (c) identify and explain any systematic or sectoral shortcomings or difficulties encountered in relation to the functioning of those bodies; (d) identify best practices concerning that functioning; (e) make recommendations as to how to improve that functioning, where appropriate. Certified out-of-court dispute settlement bodies shall make their decisions available to the parties within a reasonable period of time and no later than 90 calendar days after the receipt of the complaint. In the case of highly complex disputes, the certified out-of-court dispute settlement body may, at its own discretion, extend the 90 calendar day period for an additional period that shall not exceed 90 days, resulting in a maximum total duration of 180 days. 5. If the out-of-court dispute settlement body decides the dispute in favour of the recipient of the service, including the individual or entity that has submitted a notice, the provider of the online platform shall bear all the fees charged by the out-of-court dispute settlement body, and shall reimburse that recipient, including the individual or entity, for any other reasonable expenses that it has paid in relation to the dispute settlement. If the out-of-court dispute settlement body decides the dispute in favour of the provider of the online platform, the recipient of the service, including the individual or entity, shall not be required to reimburse any fees or other expenses that the provider of the online platform paid or is to pay in relation to the dispute settlement, unless the out-of-court dispute settlement body finds that that recipient manifestly acted in bad faith. The fees charged by the out-of-court dispute settlement body to the providers of online platforms for the dispute settlement shall be reasonable and shall in any event not exceed the costs incurred by the body. For recipients of the service, the dispute settlement shall be available free of charge or at a nominal fee. Certified out-of-court dispute settlement bodies shall make the fees, or the mechanisms used to determine the fees, known to the recipient of the service, including to the individuals or entities that have submitted a notice, and to the provider of the online platform concerned, before engaging in the dispute settlement. 6. Member States may establish out-of-court dispute settlement bodies for the purposes of paragraph 1 or support the activities of some or all out-of-court dispute settlement bodies that they have certified in accordance with paragraph 3. Member States shall ensure that any of their activities undertaken under the first subparagraph do not affect the ability of their Digital Services Coordinators to certify the bodies concerned in accordance with paragraph 3. 7. A Digital Services Coordinator that has certified an out-of-court dispute settlement body shall revoke that certification if it determines, following an investigation either on its own initiative or on the basis of the information received by third parties, that the out-of-court dispute settlement body no longer meets the conditions set out in paragraph 3. Before revoking that certification, the Digital Services Coordinator shall afford that body an opportunity to react to the findings of its investigation and its intention to revoke the out-of-court dispute settlement body\u2019s certification. 8. Digital Services Coordinators shall notify to the Commission the out-of-court dispute settlement bodies that they have certified in accordance with paragraph 3, including where applicable the specifications referred to in the second subparagraph of that paragraph, as well as the out-of-court dispute settlement bodies the certification of which they have revoked. The Commission shall publish a list of those bodies, including those specifications, on a dedicated website that is easily accessible, and keep it up to date. 9. This Article is without prejudice to Directive 2013/11/EU and alternative dispute resolution procedures and entities for consumers established under that Directive.", "provision_code": "Article 21", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Trusted flaggers", "provision_body": "1. Providers of online platforms shall take the necessary technical and organisational measures to ensure that notices submitted by trusted flaggers, acting within their designated area of expertise, through the mechanisms referred to in Article 16, are given priority and are processed and decided upon without undue delay. 2. The status of \u2018trusted flagger\u2019 under this Regulation shall be awarded, upon application by any entity, by the Digital Services Coordinator of the Member State in which the applicant is established, to an applicant that has demonstrated that it meets all of the following conditions: (a) it has particular expertise and competence for the purposes of detecting, identifying and notifying illegal content; (b) it is independent from any provider of online platforms; (c) it carries out its activities for the purposes of submitting notices diligently, accurately and objectively. 3. Trusted flaggers shall publish, at least once a year easily comprehensible and detailed reports on notices submitted in accordance with Article 16 during the relevant period. The report shall list at least the number of notices categorised by: (a) the identity of the provider of hosting services, (b) the type of allegedly illegal content notified, (c) the action taken by the provider. Those reports shall include an explanation of the procedures in place to ensure that the trusted flagger retains its independence. Trusted flaggers shall send those reports to the awarding Digital Services Coordinator, and shall make them publicly available. The information in those reports shall not contain personal data. 4. Digital Services Coordinators shall communicate to the Commission and the Board the names, addresses and email addresses of the entities to which they have awarded the status of the trusted flagger in accordance with paragraph 2 or whose trusted flagger status they have suspended in accordance with paragraph 6 or revoked in accordance with paragraph 7. 5. The Commission shall publish the information referred to in paragraph 4 in a publicly available database, in an easily accessible and machine-readable format, and shall keep the database up to date. 6. Where a provider of online platforms has information indicating that a trusted flagger has submitted a significant number of insufficiently precise, inaccurate or inadequately substantiated notices through the mechanisms referred to in Article 16, including information gathered in connection to the processing of complaints through the internal complaint-handling systems referred to in Article 20(4), it shall communicate that information to the Digital Services Coordinator that awarded the status of trusted flagger to the entity concerned, providing the necessary explanations and supporting documents. Upon receiving the information from the provider of online platforms, and if the Digital Services Coordinator considers that there are legitimate reasons to open an investigation, the status of trusted flagger shall be suspended during the period of the investigation. That investigation shall be carried out without undue delay. 7. The Digital Services Coordinator that awarded the status of trusted flagger to an entity shall revoke that status if it determines, following an investigation either on its own initiative or on the basis information received from third parties, including the information provided by a provider of online platforms pursuant to paragraph 6, that the entity no longer meets the conditions set out in paragraph 2. Before revoking that status, the Digital Services Coordinator shall afford the entity an opportunity to react to the findings of its investigation and to its intention to revoke the entity\u2019s status as trusted flagger. 8. The Commission, after consulting the Board, shall, where necessary, issue guidelines to assist providers of online platforms and Digital Services Coordinators in the application of paragraphs 2, 6 and 7.", "provision_code": "Article 22", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Measures and protection against misuse", "provision_body": "1. Providers of online platforms shall suspend, for a reasonable period of time and after having issued a prior warning, the provision of their services to recipients of the service that frequently provide manifestly illegal content. 2. Providers of online platforms shall suspend, for a reasonable period of time and after having issued a prior warning, the processing of notices and complaints submitted through the notice and action mechanisms and internal complaints handling systems referred to in Articles 16 and 20, respectively, by individuals or entities or by complainants that frequently submit notices or complaints that are manifestly unfounded. 3. When deciding on suspension, providers of online platforms shall assess, on a case-by-case basis and in a timely, diligent and objective manner, whether the recipient of the service, the individual, the entity or the complainant engages in the misuse referred to in paragraphs 1 and 2, taking into account all relevant facts and circumstances apparent from the information available to the provider of online platforms. Those circumstances shall include at least the following: (a) the absolute numbers of items of manifestly illegal content or manifestly unfounded notices or complaints, submitted within a given time frame; (b) the relative proportion thereof in relation to the total number of items of information provided or notices submitted within a given time frame; (c) the gravity of the misuses, including the nature of illegal content, and of its consequences; (d) where it is possible to identify it, the intention of the recipient of the service, the individual, the entity or the complainant. 4. Providers of online platforms shall set out, in a clear and detailed manner, in their terms and conditions their policy in respect of the misuse referred to in paragraphs 1 and 2, and shall give examples of the facts and circumstances that they take into account when assessing whether certain behaviour constitutes misuse and the duration of the suspension.", "provision_code": "Article 23", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Transparency reporting obligations for providers of online platforms", "provision_body": "1. In addition to the information referred to in Article 15, providers of online platforms shall include in the reports referred to in that Article information on the following: (a) the number of disputes submitted to the out-of-court dispute settlement bodies referred to in Article 21, the outcomes of the dispute settlement, and the median time needed for completing the dispute settlement procedures, as well as the share of disputes where the provider of the online platform implemented the decisions of the body; (b) the number of suspensions imposed pursuant to Article 23, distinguishing between suspensions enacted for the provision of manifestly illegal content, the submission of manifestly unfounded notices and the submission of manifestly unfounded complaints. 2. By 17 February 2023 and at least once every six months thereafter, providers shall publish for each online platform or online search engine, in a publicly available section of their online interface, information on the average monthly active recipients of the service in the Union, calculated as an average over the period of the past six months and in accordance with the methodology laid down in the delegated acts referred to in Article 33(3), where those delegated acts have been adopted. 3. Providers of online platforms or of online search engines shall communicate to the Digital Services Coordinator of establishment and the Commission, upon their request and without undue delay, the information referred to in paragraph 2, updated to the moment of such request. That Digital Services Coordinator or the Commission may require the provider of the online platform or of the online search engine to provide additional information as regards the calculation referred to in that paragraph, including explanations and substantiation in respect of the data used. That information shall not include personal data. 4. When the Digital Services Coordinator of establishment has reasons to consider, based the information received pursuant to paragraphs 2 and 3 of this Article, that a provider of online platforms or of an online search engine meets the threshold of average monthly active recipients of the service in the Union laid down in Article 33(1), it shall inform the Commission thereof. 5. Providers of online platforms shall, without undue delay, submit to the Commission the decisions and the statements of reasons referred to in Article 17(1) for the inclusion in a publicly accessible machine-readable database managed by the Commission. Providers of online platforms shall ensure that the information submitted does not contain personal data. 6. The Commission may adopt implementing acts to lay down templates concerning the form, content and other details of reports pursuant to paragraph 1 of this Article. Those implementing acts shall be adopted in accordance with the advisory procedure referred to in Article 88.", "provision_code": "Article 24", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Online interface design and organisation", "provision_body": "1. Providers of online platforms shall not design, organise or operate their online interfaces in a way that deceives or manipulates the recipients of their service or in a way that otherwise materially distorts or impairs the ability of the recipients of their service to make free and informed decisions. 2. The prohibition in paragraph 1 shall not apply to practices covered by Directive 2005/29/EC or Regulation (EU) 2016/679. 3. The Commission may issue guidelines on how paragraph 1 applies to specific practices, notably: (a) giving more prominence to certain choices when asking the recipient of the service for a decision; (b) repeatedly requesting that the recipient of the service make a choice where that choice has already been made, especially by presenting pop-ups that interfere with the user experience; (c) making the procedure for terminating a service more difficult than subscribing to it.", "provision_code": "Article 25", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Advertising on online platforms", "provision_body": "1. Providers of online platforms that present advertisements on their online interfaces shall ensure that, for each specific advertisement presented to each individual recipient, the recipients of the service are able to identify, in a clear, concise and unambiguous manner and in real time, the following: (a) that the information is an advertisement, including through prominent markings, which might follow standards pursuant to Article 44; (b) the natural or legal person on whose behalf the advertisement is presented; (c) the natural or legal person who paid for the advertisement if that person is different from the natural or legal person referred to in point (b); (d) meaningful information directly and easily accessible from the advertisement about the main parameters used to determine the recipient to whom the advertisement is presented and, where applicable, about how to change those parameters. 2. Providers of online platforms shall provide recipients of the service with a functionality to declare whether the content they provide is or contains commercial communications. When the recipient of the service submits a declaration pursuant to this paragraph, the provider of online platforms shall ensure that other recipients of the service can identify in a clear and unambiguous manner and in real time, including through prominent markings, which might follow standards pursuant to Article 44, that the content provided by the recipient of the service is or contains commercial communications, as described in that declaration. 3. Providers of online platforms shall not present advertisements to recipients of the service based on profiling as defined in Article 4, point (4), of Regulation (EU) 2016/679 using special categories of personal data referred to in Article 9(1) of Regulation (EU) 2016/679.", "provision_code": "Article 26", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Recommender system transparency", "provision_body": "1. Providers of online platforms that use recommender systems shall set out in their terms and conditions, in plain and intelligible language, the main parameters used in their recommender systems, as well as any options for the recipients of the service to modify or influence those main parameters. 2. The main parameters referred to in paragraph 1 shall explain why certain information is suggested to the recipient of the service. They shall include, at least: (a) the criteria which are most significant in determining the information suggested to the recipient of the service; (b) the reasons for the relative importance of those parameters. 3. Where several options are available pursuant to paragraph 1 for recommender systems that determine the relative order of information presented to recipients of the service, providers of online platforms shall also make available a functionality that allows the recipient of the service to select and to modify at any time their preferred option. That functionality shall be directly and easily accessible from the specific section of the online platform\u2019s online interface where the information is being prioritised.", "provision_code": "Article 27", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Online protection of minors", "provision_body": "1. Providers of online platforms accessible to minors shall put in place appropriate and proportionate measures to ensure a high level of privacy, safety, and security of minors, on their service. 2. Providers of online platform shall not present advertisements on their interface based on profiling as defined in Article 4, point (4), of Regulation (EU) 2016/679 using personal data of the recipient of the service when they are aware with reasonable certainty that the recipient of the service is a minor. 3. Compliance with the obligations set out in this Article shall not oblige providers of online platforms to process additional personal data in order to assess whether the recipient of the service is a minor. 4. The Commission, after consulting the Board, may issue guidelines to assist providers of online platforms in the application of paragraph 1.", "provision_code": "Article 28", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Exclusion for micro and small enterprises", "provision_body": "1. This Section shall not apply to providers of online platforms allowing consumers to conclude distance contracts with traders that qualify as micro or small enterprises as defined in Recommendation 2003/361/EC. This Section shall not apply to providers of online platforms allowing consumers to conclude distance contracts with traders that previously qualified for the status of a micro or small enterprise as defined in Recommendation 2003/361/EC during the 12 months following their loss of that status pursuant to Article 4(2) thereof, except when they are very large online platforms in accordance with Article 33. 2. By derogation from paragraph 1 of this Article, this Section shall apply to providers of online platforms allowing consumers to conclude distance contracts with traders that have been designated as very large online platforms in accordance with Article 33, irrespective of whether they qualify as micro or small enterprises.", "provision_code": "Article 29", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Traceability of traders", "provision_body": "1. Providers of online platforms allowing consumers to conclude distance contracts with traders shall ensure that traders can only use those online platforms to promote messages on or to offer products or services to consumers located in the Union if, prior to the use of their services for those purposes, they have obtained the following information, where applicable to the trader: (a) the name, address, telephone number and email address of the trader; (b) a copy of the identification document of the trader or any other electronic identification as defined by Article 3 of Regulation (EU) No 910/2014 of the European Parliament and of the Council (40); (c) the payment account details of the trader; (d) where the trader is registered in a trade register or similar public register, the trade register in which the trader is registered and its registration number or equivalent means of identification in that register; (e) a self-certification by the trader committing to only offer products or services that comply with the applicable rules of Union law. 2. Upon receiving the information referred to in paragraph 1 and prior to allowing the trader concerned to use its services, the provider of the online platform allowing consumers to conclude distance contracts with traders shall, through the use of any freely accessible official online database or online interface made available by a Member State or the Union or through requests to the trader to provide supporting documents from reliable sources, make best efforts to assess whether the information referred to in paragraph 1, points (a) to (e), is reliable and complete. For the purpose of this Regulation, traders shall be liable for the accuracy of the information provided. As regards traders that are already using the services of providers of online platforms allowing consumers to conclude distance contracts with traders for the purposes referred to in paragraph 1 on 17 February 2024, the providers shall make best efforts to obtain the information listed from the traders concerned within 12 months. Where the traders concerned fail to provide the information within that period, the providers shall suspend the provision of their services to those traders until they have provided all information. 3. Where the provider of the online platform allowing consumers to conclude distance contracts with traders obtains sufficient indications or has reason to believe that any item of information referred to in paragraph 1 obtained from the trader concerned is inaccurate, incomplete or not up-to-date, that provider shall request that the trader remedy that situation without delay or within the period set by Union and national law. Where the trader fails to correct or complete that information, the provider of the online platform allowing consumers to conclude distance contracts with traders shall swiftly suspend the provision of its service to that trader in relation to the offering of products or services to consumers located in the Union until the request has been fully complied with. 4. Without prejudice to Article 4 of Regulation (EU) 2019/1150, if a provider of an online platform allowing consumers to conclude distance contracts with traders refuses to allow a trader to use its service pursuant to paragraph 1, or suspends the provision of its service pursuant to paragraph 3 of this Article, the trader concerned shall have the right to lodge a complaint as provided for in Articles 20 and 21 of this Regulation. 5. Providers of online platforms allowing consumers to conclude distance contracts with traders shall store the information obtained pursuant to paragraphs 1 and 2 in a secure manner for a period of six months after the end of the contractual relationship with the trader concerned. They shall subsequently delete the information. 6. Without prejudice to paragraph 2 of this Article, the provider of the online platform allowing consumers to conclude distance contracts with traders shall only disclose the information to third parties where so required in accordance with the applicable law, including the orders referred to in Article 10 and any orders issued by Member States\u2019 competent authorities or the Commission for the performance of their tasks under this Regulation. 7. The provider of the online platform allowing consumers to conclude distance contracts with traders shall make the information referred to in paragraph 1, points (a), (d) and (e) available on its online platform to the recipients of the service in a clear, easily accessible and comprehensible manner. That information shall be available at least on the online platform\u2019s online interface where the information on the product or service is presented.", "provision_code": "Article 30", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Compliance by design", "provision_body": "1. Providers of online platforms allowing consumers to conclude distance contracts with traders shall ensure that its online interface is designed and organised in a way that enables traders to comply with their obligations regarding pre contractual information, compliance and product safety information under applicable Union law. In particular, the provider concerned shall ensure that its online interface enables traders to provide information on the name, address, telephone number and email address of the economic operator, as defined in Article 3, point (13), of Regulation (EU) 2019/1020 and other Union law. 2. Providers of online platforms allowing consumers to conclude distance contracts with traders shall ensure that its online interface is designed and organised in a way that it allows traders to provide at least the following: (a) the information necessary for the clear and unambiguous identification of the products or the services promoted or offered to consumers located in the Union through the services of the providers; (b) any sign identifying the trader such as the trademark, symbol or logo; and, (c) where applicable, the information concerning the labelling and marking in compliance with rules of applicable Union law on product safety and product compliance. 3. Providers of online platforms allowing consumers to conclude distance contracts with traders shall make best efforts to assess whether such traders have provided the information referred to in paragraphs 1 and 2 prior to allowing them to offer their products or services on those platforms. After allowing the trader to offer products or services on its online platform that allows consumers to conclude distance contracts with traders, the provider shall make reasonable efforts to randomly check in any official, freely accessible and machine-readable online database or online interface whether the products or services offered have been identified as illegal.", "provision_code": "Article 31", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Right to information", "provision_body": "1. Where a provider of an online platform allowing consumers to conclude distance contracts with traders becomes aware, irrespective of the means used, that an illegal product or service has been offered by a trader to consumers located in the Union through its services, that provider shall inform, insofar as it has their contact details, consumers who purchased the illegal product or service through its services of the following: (a) the fact that the product or service is illegal; (b) the identity of the trader; and (c) any relevant means of redress. The obligation laid down in the first subparagraph shall be limited to purchases of illegal products or services made within the six months preceding the moment that the provider became aware of the illegality. 2. Where, in the situation referred to in paragraph 1, the provider of the online platform allowing consumers to conclude distance contracts with traders does not have the contact details of all consumers concerned, that provider shall make publicly available and easily accessible on its online interface the information concerning the illegal product or service, the identity of the trader and any relevant means of redress.", "provision_code": "Article 32", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Very large online platforms and very large online search engines", "provision_body": "1. This Section shall apply to online platforms and online search engines which have a number of average monthly active recipients of the service in the Union equal to or higher than 45 million, and which are designated as very large online platforms or very large online search engines pursuant to paragraph 4. 2. The Commission shall adopt delegated acts in accordance with Article 87 to adjust the number of average monthly active recipients of the service in the Union referred to in paragraph 1, where the Union\u2019s population increases or decreases at least by 5 % in relation to its population in 2020 or its population after adjustment by means of a delegated act in the year in which the latest delegated act was adopted. In such a case, it shall adjust the number so that it corresponds to 10 % of the Union\u2019s population in the year in which it adopts the delegated act, rounded up or down to allow the number to be expressed in millions. 3. The Commission may adopt delegated acts in accordance with Article 87, after consulting the Board, to supplement the provisions of this Regulation by laying down the methodology for calculating the number of average monthly active recipients of the service in the Union, for the purposes of paragraph 1 of this Article and Article 24(2), ensuring that the methodology takes account of market and technological developments. 4. The Commission shall, after having consulted the Member State of establishment or after taking into account the information provided by the Digital Services Coordinator of establishment pursuant to Article 24(4), adopt a decision designating as a very large online platform or a very large online search engine for the purposes of this Regulation the online platform or the online search engine which has a number of average monthly active recipients of the service equal to or higher than the number referred to in paragraph 1 of this Article. The Commission shall take its decision on the basis of data reported by the provider of the online platform or of the online search engine pursuant to Article 24(2), or information requested pursuant to Article 24(3) or any other information available to the Commission. The failure by the provider of the online platform or of the online search engine to comply with Article 24(2) or to comply with the request by the Digital Services Coordinator of establishment or by the Commission pursuant to Article 24(3) shall not prevent the Commission from designating that provider as a provider of a very large online platform or of a very large online search engine pursuant to this paragraph. Where the Commission bases its decision on other information available to the Commission pursuant to the first subparagraph of this paragraph or on the basis of additional information requested pursuant to Article 24(3), the Commission shall give the provider of the online platform or of the online search engine concerned 10 working days in which to submit its views on the Commission\u2019s preliminary findings and on its intention to designate the online platform or the online search engine as a very large online platform or as a very large online search engine, respectively. The Commission shall take due account of the views submitted by the provider concerned. The failure of the provider of the online platform or of the online search engine concerned to submit its views pursuant to the third subparagraph shall not prevent the Commission from designating that online platform or that online search engine as a very large online platform or as a very large online search engine, respectively, based on other information available to it. 5. The Commission shall terminate the designation if, during an uninterrupted period of one year, the online platform or the online search engine does not have a number of average monthly active recipients of the service equal to or higher than the number referred to in paragraph 1. 6. The Commission shall notify its decisions pursuant to paragraphs 4 and 5, without undue delay, to the provider of the online platform or of the online search engine concerned, to the Board and to the Digital Services Coordinator of establishment. The Commission shall ensure that the list of designated very large online platforms and very large online search engines is published in the Official Journal of the European Union, and shall keep that list up to date. The obligations set out in this Section shall apply, or cease to apply, to the very large online platforms and very large online search engines concerned from four months after the notification to the provider concerned referred to in the first subparagraph.", "provision_code": "Article 33", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Risk assessment", "provision_body": "1. Providers of very large online platforms and of very large online search engines shall diligently identify, analyse and assess any systemic risks in the Union stemming from the design or functioning of their service and its related systems, including algorithmic systems, or from the use made of their services. They shall carry out the risk assessments by the date of application referred to in Article 33(6), second subparagraph, and at least once every year thereafter, and in any event prior to deploying functionalities that are likely to have a critical impact on the risks identified pursuant to this Article. This risk assessment shall be specific to their services and proportionate to the systemic risks, taking into consideration their severity and probability, and shall include the following systemic risks: (a) the dissemination of illegal content through their services; (b) any actual or foreseeable negative effects for the exercise of fundamental rights, in particular the fundamental rights to human dignity enshrined in Article 1 of the Charter, to respect for private and family life enshrined in Article 7 of the Charter, to the protection of personal data enshrined in Article 8 of the Charter, to freedom of expression and information, including the freedom and pluralism of the media, enshrined in Article 11 of the Charter, to non discrimination enshrined in Article 21 of the Charter, to respect for the rights of the child enshrined in Article 24 of the Charter and to a high-level of consumer protection enshrined in Article 38 of the Charter; (c) any actual or foreseeable negative effects on civic discourse and electoral processes, and public security; (d) any actual or foreseeable negative effects in relation to gender-based violence, the protection of public health and minors and serious negative consequences to the person\u2019s physical and mental well-being. 2. When conducting risk assessments, providers of very large online platforms and of very large online search engines shall take into account, in particular, whether and how the following factors influence any of the systemic risks referred to in paragraph 1: (a) the design of their recommender systems and any other relevant algorithmic system; (b) their content moderation systems; (c) the applicable terms and conditions and their enforcement; (d) systems for selecting and presenting advertisements; (e) data related practices of the provider. The assessments shall also analyse whether and how the risks pursuant to paragraph 1 are influenced by intentional manipulation of their service, including by inauthentic use or automated exploitation of the service, as well as the amplification and potentially rapid and wide dissemination of illegal content and of information that is incompatible with their terms and conditions. The assessment shall take into account specific regional or linguistic aspects, including when specific to a Member State. 3. Providers of very large online platforms and of very large online search engines shall preserve the supporting documents of the risk assessments for at least three years after the performance of risk assessments, and shall, upon request, communicate them to the Commission and to the Digital Services Coordinator of establishment.", "provision_code": "Article 34", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Mitigation of risks", "provision_body": "1. Providers of very large online platforms and of very large online search engines shall put in place reasonable, proportionate and effective mitigation measures, tailored to the specific systemic risks identified pursuant to Article 34, with particular consideration to the impacts of such measures on fundamental rights. Such measures may include, where applicable: (a) adapting the design, features or functioning of their services, including their online interfaces; (b) adapting their terms and conditions and their enforcement; (c) adapting content moderation processes, including the speed and quality of processing notices related to specific types of illegal content and, where appropriate, the expeditious removal of, or the disabling of access to, the content notified, in particular in respect of illegal hate speech or cyber violence, as well as adapting any relevant decision making processes and dedicated resources for content moderation; (d) testing and adapting their algorithmic systems, including their recommender systems; (e) adapting their advertising systems and adopting targeted measures aimed at limiting or adjusting the presentation of advertisements in association with the service they provide; (f) reinforcing the internal processes, resources, testing, documentation, or supervision of any of their activities in particular as regards detection of systemic risk; (g) initiating or adjusting cooperation with trusted flaggers in accordance with Article 22 and the implementation of the decisions of out-of-court dispute settlement bodies pursuant to Article 21; (h) initiating or adjusting cooperation with other providers of online platforms or of online search engines through the codes of conduct and the crisis protocols referred to in Articles 45 and 48 respectively; (i) taking awareness-raising measures and adapting their online interface in order to give recipients of the service more information; (j) taking targeted measures to protect the rights of the child, including age verification and parental control tools, tools aimed at helping minors signal abuse or obtain support, as appropriate; (k) ensuring that an item of information, whether it constitutes a generated or manipulated image, audio or video that appreciably resembles existing persons, objects, places or other entities or events and falsely appears to a person to be authentic or truthful is distinguishable through prominent markings when presented on their online interfaces, and, in addition, providing an easy to use functionality which enables recipients of the service to indicate such information. 2. The Board, in cooperation with the Commission, shall publish comprehensive reports, once a year. The reports shall include the following: (a) identification and assessment of the most prominent and recurrent systemic risks reported by providers of very large online platforms and of very large online search engines or identified through other information sources, in particular those provided in compliance with Articles 39, 40 and 42; (b) best practices for providers of very large online platforms and of very large online search engines to mitigate the systemic risks identified. Those reports shall present systemic risks broken down by the Member States in which they occurred and in the Union as a whole, as applicable. 3. The Commission, in cooperation with the Digital Services Coordinators, may issue guidelines on the application of paragraph 1 in relation to specific risks, in particular to present best practices and recommend possible measures, having due regard to the possible consequences of the measures on fundamental rights enshrined in the Charter of all parties involved. When preparing those guidelines the Commission shall organise public consultations.", "provision_code": "Article 35", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Crisis response mechanism", "provision_body": "1. Where a crisis occurs, the Commission, acting upon a recommendation of the Board may adopt a decision, requiring one or more providers of very large online platforms or of very large online search engines to take one or more of the following actions: (a) assess whether, and if so to what extent and how, the functioning and use of their services significantly contribute to a serious threat as referred to in paragraph 2, or are likely to do so; (b) identify and apply specific, effective and proportionate measures, such as any of those provided for in Article 35(1) or Article 48(2), to prevent, eliminate or limit any such contribution to the serious threat identified pursuant to point (a) of this paragraph; (c) report to the Commission by a certain date or at regular intervals specified in the decision, on the assessments referred to in point (a), on the precise content, implementation and qualitative and quantitative impact of the specific measures taken pursuant to point (b) and on any other issue related to those assessments or those measures, as specified in the decision. When identifying and applying measures pursuant to point (b) of this paragraph, the service provider or providers shall take due account of the gravity of the serious threat referred to in paragraph 2, of the urgency of the measures and of the actual or potential implications for the rights and legitimate interests of all parties concerned, including the possible failure of the measures to respect the fundamental rights enshrined in the Charter. 2. For the purpose of this Article, a crisis shall be deemed to have occurred where extraordinary circumstances lead to a serious threat to public security or public health in the Union or in significant parts of it. 3. When taking the decision referred to in paragraph 1, the Commission shall ensure that all of the following requirements are met: (a) the actions required by the decision are strictly necessary, justified and proportionate, having regard in particular to the gravity of the serious threat referred to in paragraph 2, the urgency of the measures and the actual or potential implications for the rights and legitimate interests of all parties concerned, including the possible failure of the measures to respect the fundamental rights enshrined in the Charter; (b) the decision specifies a reasonable period within which specific measures referred to in paragraph 1, point (b), are to be taken, having regard, in particular, to the urgency of those measures and the time needed to prepare and implement them; (c) the actions required by the decision are limited to a period not exceeding three months. 4. After adopting the decision referred to in paragraph 1, the Commission shall, without undue delay, take the following steps: (a) notify the decision to the provider or providers to which the decision is addressed; (b) make the decision publicly available; and (c) inform the Board of the decision, invite it to submit its views thereon, and keep it informed of any subsequent developments relating to the decision. 5. The choice of specific measures to be taken pursuant to paragraph 1, point (b), and to paragraph 7, second subparagraph, shall remain with the provider or providers addressed by the Commission\u2019s decision. 6. The Commission may on its own initiative or at the request of the provider, engage in a dialogue with the provider to determine whether, in light of the provider\u2019s specific circumstances, the intended or implemented measures referred to in paragraph 1, point (b), are effective and proportionate in achieving the objectives pursued. In particular, the Commission shall ensure that the measures taken by the service provider under paragraph 1, point (b), meet the requirements referred to in paragraph 3, points (a) and (c). 7. The Commission shall monitor the application of the specific measures taken pursuant to the decision referred to in paragraph 1 of this Article on the basis of the reports referred to in point (c) of that paragraph and any other relevant information, including information it may request pursuant to Article 40 or 67, taking into account the evolution of the crisis. The Commission shall report regularly to the Board on that monitoring, at least on a monthly basis. Where the Commission considers that the intended or implemented specific measures pursuant to paragraph 1, point (b), are not effective or proportionate it may, after consulting the Board, adopt a decision requiring the provider to review the identification or application of those specific measures. 8. Where appropriate in view of the evolution of the crisis, the Commission, acting on the Board\u2019s recommendation, may amend the decision referred to in paragraph 1 or in paragraph 7, second subparagraph, by: (a) revoking the decision and, where appropriate, requiring the very large online platform or very large online search engine to cease to apply the measures identified and implemented pursuant to paragraph 1, point (b), or paragraph 7, second subparagraph, in particular where the grounds for such measures do not exist anymore; (b) extending the period referred to paragraph 3, point (c), by a period of no more than three months; (c) taking account of experience gained in applying the measures, in particular the possible failure of the measures to respect the fundamental rights enshrined in the Charter. 9. The requirements of paragraphs 1 to 6 shall apply to the decision and to the amendment thereof referred to in this Article. 10. The Commission shall take utmost account of the recommendation of the Board issued pursuant to this Article. 11. The Commission shall report to the European Parliament and to the Council on a yearly basis following the adoption of decisions in accordance with this Article, and, in any event, three months after the end of the crisis, on the application of the specific measures taken pursuant to those decisions.", "provision_code": "Article 36", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Independent audit", "provision_body": "1. Providers of very large online platforms and of very large online search engines shall be subject, at their own expense and at least once a year, to independent audits to assess compliance with the following: (a) the obligations set out in Chapter III; (b) any commitments undertaken pursuant to the codes of conduct referred to in Articles 45 and 46 and the crisis protocols referred to in Article 48. 2. Providers of very large online platforms and of very large online search engines shall afford the organisations carrying out the audits pursuant to this Article the cooperation and assistance necessary to enable them to conduct those audits in an effective, efficient and timely manner, including by giving them access to all relevant data and premises and by answering oral or written questions. They shall refrain from hampering, unduly influencing or undermining the performance of the audit. Such audits shall ensure an adequate level of confidentiality and professional secrecy in respect of the information obtained from the providers of very large online platforms and of very large online search engines and third parties in the context of the audits, including after the termination of the audits. However, complying with that requirement shall not adversely affect the performance of the audits and other provisions of this Regulation, in particular those on transparency, supervision and enforcement. Where necessary for the purpose of the transparency reporting pursuant to Article 42(4), the audit report and the audit implementation report referred to in paragraphs 4 and 6 of this Article shall be accompanied with versions that do not contain any information that could reasonably be considered to be confidential. 3. Audits performed pursuant to paragraph 1 shall be performed by organisations which: (a) are independent from, and do not have any conflicts of interest with, the provider of very large online platforms or of very large online search engines concerned and any legal person connected to that provider; in particular: (i) have not provided non-audit services related to the matters audited to the provider of very large online platform or of very large online search engine concerned and to any legal person connected to that provider in the 12 months\u2019 period before the beginning of the audit and have committed to not providing them with such services in the 12 months\u2019 period after the completion of the audit; (ii) have not provided auditing services pursuant to this Article to the provider of very large online platform or of very large online search engine concerned and any legal person connected to that provider during a period longer than 10 consecutive years; (iii) are not performing the audit in return for fees which are contingent on the result of the audit; (b) have proven expertise in the area of risk management, technical competence and capabilities; (c) have proven objectivity and professional ethics, based in particular on adherence to codes of practice or appropriate standards. 4. Providers of very large online platforms and of very large online search engines shall ensure that the organisations that perform the audits establish an audit report for each audit. That report shall be substantiated, in writing, and shall include at least the following: (a) the name, address and the point of contact of the provider of the very large online platform or of the very large online search engine subject to the audit and the period covered; (b) the name and address of the organisation or organisations performing the audit; (c) a declaration of interests; (d) a description of the specific elements audited, and the methodology applied; (e) a description and a summary of the main findings drawn from the audit; (f) a list of the third parties consulted as part of the audit; (g) an audit opinion on whether the provider of the very large online platform or of the very large online search engine subject to the audit complied with the obligations and with the commitments referred to in paragraph 1, namely \u2018positive\u2019, \u2018positive with comments\u2019 or \u2018negative\u2019; (h) where the audit opinion is not \u2018positive\u2019, operational recommendations on specific measures to achieve compliance and the recommended timeframe to achieve compliance. 5. Where the organisation performing the audit was unable to audit certain specific elements or to express an audit opinion based on its investigations, the audit report shall include an explanation of the circumstances and the reasons why those elements could not be audited. 6. Providers of very large online platforms or of very large online search engines receiving an audit report that is not \u2018positive\u2019 shall take due account of the operational recommendations addressed to them with a view to take the necessary measures to implement them. They shall, within one month from receiving those recommendations, adopt an audit implementation report setting out those measures. Where they do not implement the operational recommendations, they shall justify in the audit implementation report the reasons for not doing so and set out any alternative measures that they have taken to address any instances of non-compliance identified. 7. The Commission is empowered to adopt delegated acts in accordance with Article 87 to supplement this Regulation by laying down the necessary rules for the performance of the audits pursuant to this Article, in particular as regards the necessary rules on the procedural steps, auditing methodologies and reporting templates for the audits performed pursuant to this Article. Those delegated acts shall take into account any voluntary auditing standards referred to in Article 44(1), point (e).", "provision_code": "Article 37", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Recommender systems", "provision_body": "In addition to the requirements set out in Article 27, providers of very large online platforms and of very large online search engines that use recommender systems shall provide at least one option for each of their recommender systems which is not based on profiling as defined in Article 4, point (4), of Regulation (EU) 2016/679.", "provision_code": "Article 38", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Additional online advertising transparency", "provision_body": "1. Providers of very large online platforms or of very large online search engines that present advertisements on their online interfaces shall compile and make publicly available in a specific section of their online interface, through a searchable and reliable tool that allows multicriteria queries and through application programming interfaces, a repository containing the information referred to in paragraph 2, for the entire period during which they present an advertisement and until one year after the advertisement was presented for the last time on their online interfaces. They shall ensure that the repository does not contain any personal data of the recipients of the service to whom the advertisement was or could have been presented, and shall make reasonable efforts to ensure that the information is accurate and complete. 2. The repository shall include at least all of the following information: (a) the content of the advertisement, including the name of the product, service or brand and the subject matter of the advertisement; (b) the natural or legal person on whose behalf the advertisement is presented; (c) the natural or legal person who paid for the advertisement, if that person is different from the person referred to in point (b); (d) the period during which the advertisement was presented; (e) whether the advertisement was intended to be presented specifically to one or more particular groups of recipients of the service and if so, the main parameters used for that purpose including where applicable the main parameters used to exclude one or more of such particular groups; (f) the commercial communications published on the very large online platforms and identified pursuant to Article 26(2); (g) the total number of recipients of the service reached and, where applicable, aggregate numbers broken down by Member State for the group or groups of recipients that the advertisement specifically targeted. 3. As regards paragraph 2, points (a), (b) and (c), where a provider of very large online platform or of very large online search engine has removed or disabled access to a specific advertisement based on alleged illegality or incompatibility with its terms and conditions, the repository shall not include the information referred to in those points. In such case, the repository shall include, for the specific advertisement concerned, the information referred to in Article 17(3), points (a) to (e), or Article 9(2), point (a)(i), as applicable. The Commission may, after consultation of the Board, the relevant vetted researchers referred to in Article 40 and the public, issue guidelines on the structure, organisation and functionalities of the repositories referred to in this Article.", "provision_code": "Article 39", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Data access and scrutiny", "provision_body": "1. Providers of very large online platforms or of very large online search engines shall provide the Digital Services Coordinator of establishment or the Commission, at their reasoned request and within a reasonable period specified in that request, access to data that are necessary to monitor and assess compliance with this Regulation. 2. Digital Services Coordinators and the Commission shall use the data accessed pursuant to paragraph 1 only for the purpose of monitoring and assessing compliance with this Regulation and shall take due account of the rights and interests of the providers of very large online platforms or of very large online search engines and the recipients of the service concerned, including the protection of personal data, the protection of confidential information, in particular trade secrets, and maintaining the security of their service. 3. For the purposes of paragraph 1, providers of very large online platforms or of very large online search engines shall, at the request of either the Digital Service Coordinator of establishment or of the Commission, explain the design, the logic, the functioning and the testing of their algorithmic systems, including their recommender systems. 4. Upon a reasoned request from the Digital Services Coordinator of establishment, providers of very large online platforms or of very large online search engines shall, within a reasonable period, as specified in the request, provide access to data to vetted researchers who meet the requirements in paragraph 8 of this Article, for the sole purpose of conducting research that contributes to the detection, identification and understanding of systemic risks in the Union, as set out pursuant to Article 34(1), and to the assessment of the adequacy, efficiency and impacts of the risk mitigation measures pursuant to Article 35. 5. Within 15 days following receipt of a request as referred to in paragraph 4, providers of very large online platforms or of very large online search engines may request the Digital Services Coordinator of establishment, to amend the request, where they consider that they are unable to give access to the data requested because one of following two reasons: (a) they do not have access to the data; (b) giving access to the data will lead to significant vulnerabilities in the security of their service or the protection of confidential information, in particular trade secrets. 6. Requests for amendment pursuant to paragraph 5 shall contain proposals for one or more alternative means through which access may be provided to the requested data or other data which are appropriate and sufficient for the purpose of the request. The Digital Services Coordinator of establishment shall decide on the request for amendment within 15 days and communicate to the provider of the very large online platform or of the very large online search engine its decision and, where relevant, the amended request and the new period to comply with the request. 7. Providers of very large online platforms or of very large online search engines shall facilitate and provide access to data pursuant to paragraphs 1 and 4 through appropriate interfaces specified in the request, including online databases or application programming interfaces. 8. Upon a duly substantiated application from researchers, the Digital Services Coordinator of establishment shall grant such researchers the status of \u2018vetted researchers\u2019 for the specific research referred to in the application and issue a reasoned request for data access to a provider of very large online platform or of very large online search engine a pursuant to paragraph 4, where the researchers demonstrate that they meet all of the following conditions: (a) they are affiliated to a research organisation as defined in Article 2, point (1), of Directive (EU) 2019/790; (b) they are independent from commercial interests; (c) their application discloses the funding of the research; (d) they are capable of fulfilling the specific data security and confidentiality requirements corresponding to each request and to protect personal data, and they describe in their request the appropriate technical and organisational measures that they have put in place to this end; (e) their application demonstrates that their access to the data and the time frames requested are necessary for, and proportionate to, the purposes of their research, and that the expected results of that research will contribute to the purposes laid down in paragraph 4; (f) the planned research activities will be carried out for the purposes laid down in paragraph 4; (g) they have committed themselves to making their research results publicly available free of charge, within a reasonable period after the completion of the research, subject to the rights and interests of the recipients of the service concerned, in accordance with Regulation (EU) 2016/679. Upon receipt of the application pursuant to this paragraph, the Digital Services Coordinator of establishment shall inform the Commission and the Board. 9. Researchers may also submit their application to the Digital Services Coordinator of the Member State of the research organisation to which they are affiliated. Upon receipt of the application pursuant to this paragraph the Digital Services Coordinator shall conduct an initial assessment as to whether the respective researchers meet all of the conditions set out in paragraph 8. The respective Digital Services Coordinator shall subsequently send the application, together with the supporting documents submitted by the respective researchers and the initial assessment, to the Digital Services Coordinator of establishment. The Digital Services Coordinator of establishment shall take a decision whether to award a researcher the status of \u2018vetted researcher\u2019 without undue delay. While taking due account of the initial assessment provided, the final decision to award a researcher the status of \u2018vetted researcher\u2019 lies within the competence of Digital Services Coordinator of establishment, pursuant to paragraph 8. 10. The Digital Services Coordinator that awarded the status of vetted researcher and issued the reasoned request for data access to the providers of very large online platforms or of very large online search engines in favour of a vetted researcher shall issue a decision terminating the access if it determines, following an investigation either on its own initiative or on the basis of information received from third parties, that the vetted researcher no longer meets the conditions set out in paragraph 8, and shall inform the provider of the very large online platform or of the very large online search engine concerned of the decision. Before terminating the access, the Digital Services Coordinator shall allow the vetted researcher to react to the findings of its investigation and to its intention to terminate the access. 11. Digital Services Coordinators of establishment shall communicate to the Board the names and contact information of the natural persons or entities to which they have awarded the status of \u2018vetted researcher\u2019 in accordance with paragraph 8, as well as the purpose of the research in respect of which the application was made or, where they have terminated the access to the data in accordance with paragraph 10, communicate that information to the Board. 12. Providers of very large online platforms or of very large online search engines shall give access without undue delay to data, including, where technically possible, to real-time data, provided that the data is publicly accessible in their online interface by researchers, including those affiliated to not for profit bodies, organisations and associations, who comply with the conditions set out in paragraph 8, points (b), (c), (d) and (e), and who use the data solely for performing research that contributes to the detection, identification and understanding of systemic risks in the Union pursuant to Article 34(1). 13. The Commission shall, after consulting the Board, adopt delegated acts supplementing this Regulation by laying down the technical conditions under which providers of very large online platforms or of very large online search engines are to share data pursuant to paragraphs 1 and 4 and the purposes for which the data may be used. Those delegated acts shall lay down the specific conditions under which such sharing of data with researchers can take place in compliance with Regulation (EU) 2016/679, as well as relevant objective indicators, procedures and, where necessary, independent advisory mechanisms in support of sharing of data, taking into account the rights and interests of the providers of very large online platforms or of very large online search engines and the recipients of the service concerned, including the protection of confidential information, in particular trade secrets, and maintaining the security of their service.", "provision_code": "Article 40", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Compliance function", "provision_body": "1. Providers of very large online platforms or of very large online search engines shall establish a compliance function, which is independent from their operational functions and composed of one or more compliance officers, including the head of the compliance function. That compliance function shall have sufficient authority, stature and resources, as well as access to the management body of the provider of the very large online platform or of the very large online search engine to monitor the compliance of that provider with this Regulation. 2. The management body of the provider of the very large online platform or of the very large online search engine shall ensure that compliance officers have the professional qualifications, knowledge, experience and ability necessary to fulfil the tasks referred to in paragraph 3. The management body of the provider of the very large online platform or of the very large online search engine shall ensure that the head of the compliance function is an independent senior manager with distinct responsibility for the compliance function. The head of the compliance function shall report directly to the management body of the provider of the very large online platform or of the very large online search engine, and may raise concerns and warn that body where risks referred to in Article 34 or non-compliance with this Regulation affect or may affect the provider of the very large online platform or of the very large online search engine concerned, without prejudice to the responsibilities of the management body in its supervisory and managerial functions. The head of the compliance function shall not be removed without prior approval of the management body of the provider of the very large online platform or of the very large online search engine. 3. Compliance officers shall have the following tasks: (a) cooperating with the Digital Services Coordinator of establishment and the Commission for the purpose of this Regulation; (b) ensuring that all risks referred to in Article 34 are identified and properly reported on and that reasonable, proportionate and effective risk-mitigation measures are taken pursuant to Article 35; (c) organising and supervising the activities of the provider of the very large online platform or of the very large online search engine relating to the independent audit pursuant to Article 37; (d) informing and advising the management and employees of the provider of the very large online platform or of the very large online search engine about relevant obligations under this Regulation; (e) monitoring the compliance of the provider of the very large online platform or of the very large online search engine with its obligations under this Regulation; (f) where applicable, monitoring the compliance of the provider of the very large online platform or of the very large online search engine with commitments made under the codes of conduct pursuant to Articles 45 and 46 or the crisis protocols pursuant to Article 48. 4. Providers of very large online platforms or of very large online search engines shall communicate the name and contact details of the head of the compliance function to the Digital Services Coordinator of establishment and to the Commission. 5. The management body of the provider of the very large online platform or of the very large online search engine shall define, oversee and be accountable for the implementation of the provider's governance arrangements that ensure the independence of the compliance function, including the division of responsibilities within the organisation of the provider of very large online platform or of very large online search engine, the prevention of conflicts of interest, and sound management of systemic risks identified pursuant to Article 34. 6. The management body shall approve and review periodically, at least once a year, the strategies and policies for taking up, managing, monitoring and mitigating the risks identified pursuant to Article 34 to which the very large online platform or the very large online search engine is or might be exposed to. 7. The management body shall devote sufficient time to the consideration of the measures related to risk management. It shall be actively involved in the decisions related to risk management, and shall ensure that adequate resources are allocated to the management of the risks identified in accordance with Article 34.", "provision_code": "Article 41", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Transparency reporting obligations", "provision_body": "1. Providers of very large online platforms or of very large online search engines shall publish the reports referred to in Article 15 at the latest by two months from the date of application referred to in Article 33(6), second subparagraph, and thereafter at least every six months. 2. The reports referred to in paragraph 1 of this Article published by providers of very large online platforms shall, in addition to the information referred to in Article 15 and Article 24(1), specify: (a) the human resources that the provider of very large online platforms dedicates to content moderation in respect of the service offered in the Union, broken down by each applicable official language of the Member States, including for compliance with the obligations set out in Articles 16 and 22, as well as for compliance with the obligations set out in Article 20; (b) the qualifications and linguistic expertise of the persons carrying out the activities referred to in point (a), as well as the training and support given to such staff; (c) the indicators of accuracy and related information referred to in Article 15(1), point (e), broken down by each official language of the Member States. The reports shall be published in at least one of the official languages of the Member States. 3. In addition to the information referred to in Articles 24(2), the providers of very large online platforms or of very large online search engines shall include in the reports referred to in paragraph 1 of this Article the information on the average monthly recipients of the service for each Member State. 4. Providers of very large online platforms or of very large online search engines shall transmit to the Digital Services Coordinator of establishment and the Commission, without undue delay upon completion, and make publicly available at the latest three months after the receipt of each audit report pursuant to Article 37(4): (a) a report setting out the results of the risk assessment pursuant to Article 34; (b) the specific mitigation measures put in place pursuant to Article 35(1); (c) the audit report provided for in Article 37(4); (d) the audit implementation report provided for in Article 37(6); (e) where applicable, information about the consultations conducted by the provider in support of the risk assessments and design of the risk mitigation measures. 5. Where a provider of very large online platform or of very large online search engine considers that the publication of information pursuant to paragraph 4 might result in the disclosure of confidential information of that provider or of the recipients of the service, cause significant vulnerabilities for the security of its service, undermine public security or harm recipients, the provider may remove such information from the publicly available reports. In that case, the provider shall transmit the complete reports to the Digital Services Coordinator of establishment and the Commission, accompanied by a statement of the reasons for removing the information from the publicly available reports.", "provision_code": "Article 42", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Supervisory fee", "provision_body": "1. The Commission shall charge providers of very large online platforms and of very large online search engines an annual supervisory fee upon their designation pursuant to Article 33. 2. The overall amount of the annual supervisory fees shall cover the estimated costs that the Commission incurs in relation to its supervisory tasks under this Regulation, in particular costs related to the designation pursuant to Article 33, to the set-up, maintenance and operation of the database pursuant to Article 24(5) and to the information sharing system pursuant to Article 85, to referrals pursuant to Article 59, to supporting the Board pursuant to Article 62 and to the supervisory tasks pursuant to Article 56 and Section 4 of Chapter IV. 3. The providers of very large online platforms and of very large online search engines shall be charged annually a supervisory fee for each service for which they have been designated pursuant to Article 33. The Commission shall adopt implementing acts establishing the amount of the annual supervisory fee in respect of each provider of very large online platform or of very large online search engine. When adopting those implementing acts, the Commission shall apply the methodology laid down in the delegated act referred to in paragraph 4 of this Article and shall respect the principles set out in paragraph 5 of this Article. Those implementing acts shall be adopted in accordance with the advisory procedure referred to in Article 88. 4. The Commission shall adopt delegated acts, in accordance with Article 87, laying down the detailed methodology and procedures for: (a) the determination of the estimated costs referred to in paragraph 2; (b) the determination of the individual annual supervisory fees referred to in paragraph 5, points (b) and (c); (c) the determination of the maximum overall limit defined in paragraph 5, point (c); and (d) the detailed arrangements necessary to make payments. When adopting those delegated acts, the Commission shall respect the principles set out in paragraph 5 of this Article. 5. The implementing act referred to in paragraph 3 and the delegated act referred to in paragraph 4 shall respect the following principles: (a) the estimation of the overall amount of the annual supervisory fee takes into account the costs incurred in the previous year; (b) the annual supervisory fee is proportionate to the number of average monthly active recipients in the Union of each very large online platform or each very large online search engine designated pursuant to Article 33; (c) the overall amount of the annual supervisory fee charged on a given provider of very large online platform or very large search engine does not, in any case, exceed 0,05 % of its worldwide annual net income in the preceding financial year. 6. The individual annual supervisory fees charged pursuant to paragraph 1 of this Article shall constitute external assigned revenue in accordance with Article 21(5) of Regulation (EU, Euratom) 2018/1046 of the European Parliament and of the Council (41). 7. The Commission shall report annually to the European Parliament and to the Council on the overall amount of the costs incurred for the fulfilment of the tasks under this Regulation and the total amount of the individual annual supervisory fees charged in the preceding year.", "provision_code": "Article 43", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Standards", "provision_body": "1. The Commission shall consult the Board, and shall support and promote the development and implementation of voluntary standards set by relevant European and international standardisation bodies, at least in respect of the following: (a) electronic submission of notices under Article 16; (b) templates, design and process standards for communicating with the recipients of the service in a user-friendly manner on restrictions resulting from terms and conditions and changes thereto; (c) electronic submission of notices by trusted flaggers under Article 22, including through application programming interfaces; (d) specific interfaces, including application programming interfaces, to facilitate compliance with the obligations set out in Articles 39 and 40; (e) auditing of very large online platforms and of very large online search engines pursuant to Article 37; (f) interoperability of the advertisement repositories referred to in Article 39(2); (g) transmission of data between advertising intermediaries in support of transparency obligations pursuant to Article 26(1), points (b), (c) and (d); (h) technical measures to enable compliance with obligations relating to advertising contained in this Regulation, including the obligations regarding prominent markings for advertisements and commercial communications referred to in Article 26; (i) choice interfaces and presentation of information on the main parameters of different types of recommender systems, in accordance with Articles 27 and 38; (j) standards for targeted measures to protect minors online. 2. The Commission shall support the update of the standards in the light of technological developments and the behaviour of the recipients of the services in question. The relevant information regarding the update of the standards shall be publicly available and easily accessible.", "provision_code": "Article 44", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Codes of conduct", "provision_body": "1. The Commission and the Board shall encourage and facilitate the drawing up of voluntary codes of conduct at Union level to contribute to the proper application of this Regulation, taking into account in particular the specific challenges of tackling different types of illegal content and systemic risks, in accordance with Union law in particular on competition and the protection of personal data. 2. Where significant systemic risk within the meaning of Article 34(1) emerge and concern several very large online platforms or very large online search engines, the Commission may invite the providers of very large online platforms concerned or the providers of very large online search engines concerned, and other providers of very large online platforms, of very large online search engines, of online platforms and of other intermediary services, as appropriate, as well as relevant competent authorities, civil society organisations and other relevant stakeholders, to participate in the drawing up of codes of conduct, including by setting out commitments to take specific risk mitigation measures, as well as a regular reporting framework on any measures taken and their outcomes. 3. When giving effect to paragraphs 1 and 2, the Commission and the Board, and where relevant other bodies, shall aim to ensure that the codes of conduct clearly set out their specific objectives, contain key performance indicators to measure the achievement of those objectives and take due account of the needs and interests of all interested parties, and in particular citizens, at Union level. The Commission and the Board shall also aim to ensure that participants report regularly to the Commission and their respective Digital Services Coordinators of establishment on any measures taken and their outcomes, as measured against the key performance indicators that they contain. Key performance indicators and reporting commitments shall take into account differences in size and capacity between different participants. 4. The Commission and the Board shall assess whether the codes of conduct meet the aims specified in paragraphs 1 and 3, and shall regularly monitor and evaluate the achievement of their objectives, having regard to the key performance indicators that they might contain. They shall publish their conclusions. The Commission and the Board shall also encourage and facilitate regular review and adaptation of the codes of conduct. In the case of systematic failure to comply with the codes of conduct, the Commission and the Board may invite the signatories to the codes of conduct to take the necessary action.", "provision_code": "Article 45", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Codes of conduct for online advertising", "provision_body": "1. The Commission shall encourage and facilitate the drawing up of voluntary codes of conduct at Union level by providers of online platforms and other relevant service providers, such as providers of online advertising intermediary services, other actors involved in the programmatic advertising value chain, or organisations representing recipients of the service and civil society organisations or relevant authorities to contribute to further transparency for actors in the online advertising value chain beyond the requirements of Articles 26 and 39. 2. The Commission shall aim to ensure that the codes of conduct pursue an effective transmission of information that fully respects the rights and interests of all parties involved, as well as a competitive, transparent and fair environment in online advertising, in accordance with Union and national law, in particular on competition and the protection of privacy and personal data. The Commission shall aim to ensure that the codes of conduct at least address the following: (a) the transmission of information held by providers of online advertising intermediaries to recipients of the service concerning the requirements set in Article 26(1), points (b), (c) and (d); (b) the transmission of information held by providers of online advertising intermediaries to the repositories pursuant to Article 39; (c) meaningful information on data monetisation. 3. The Commission shall encourage the development of the codes of conduct by 18 February 2025 and their application by 18 August 2025. 4. The Commission shall encourage all the actors in the online advertising value chain referred to in paragraph 1 to endorse the commitments stated in the codes of conduct, and to comply with them.", "provision_code": "Article 46", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Codes of conduct for accessibility", "provision_body": "1. The Commission shall encourage and facilitate the drawing up of codes of conduct at Union level with the involvement of providers of online platforms and other relevant service providers, organisations representing recipients of the service and civil society organisations or relevant authorities to promote full and effective, equal participation, by improving access to online services that, through their initial design or subsequent adaptation, address the particular needs of persons with disabilities. 2. The Commission shall aim to ensure that the codes of conduct pursue the objective of ensuring that those services are accessible in compliance with Union and national law, in order to maximise their foreseeable use by persons with disabilities. The Commission shall aim to ensure that the codes of conduct address at least the following objectives: (a) designing and adapting services to make them accessible to persons with disabilities by making them perceivable, operable, understandable and robust; (b) explaining how the services meet the applicable accessibility requirements and making this information available to the public in an accessible manner for persons with disabilities; (c) making information, forms and measures provided pursuant to this Regulation available in such a manner that they are easy to find, easy to understand, and accessible to persons with disabilities. 3. The Commission shall encourage the development of the codes of conduct by 18 February 2025 and their application by 18 August 2025.", "provision_code": "Article 47", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Crisis protocols", "provision_body": "1. The Board may recommend that the Commission initiate the drawing up, in accordance with paragraphs 2, 3 and 4, of voluntary crisis protocols for addressing crisis situations. Those situations shall be strictly limited to extraordinary circumstances affecting public security or public health. 2. The Commission shall encourage and facilitate the providers of very large online platforms, of very large online search engines and, where appropriate, the providers of other online platforms or of other online search engines, to participate in the drawing up, testing and application of those crisis protocols. The Commission shall aim to ensure that those crisis protocols include one or more of the following measures: (a) prominently displaying information on the crisis situation provided by Member States\u2019 authorities or at Union level, or, depending on the context of the crisis, by relevant reliable bodies; (b) ensuring that the provider of intermediary services designates a specific point of contact for crisis management; where relevant, this may be the electronic point of contact referred to in Article 11 or, in the case of providers of very large online platforms or of very large online search engines, the compliance officer referred to in Article 41; (c) where applicable, adapt the resources dedicated to compliance with the obligations set out in Articles 16, 20, 22, 23 and 35 to the needs arising from the crisis situation. 3. The Commission shall, as appropriate, involve Member States\u2019 authorities, and may also involve Union bodies, offices and agencies in drawing up, testing and supervising the application of the crisis protocols. The Commission may, where necessary and appropriate, also involve civil society organisations or other relevant organisations in drawing up the crisis protocols. 4. The Commission shall aim to ensure that the crisis protocols set out clearly all of the following: (a) the specific parameters to determine what constitutes the specific extraordinary circumstance the crisis protocol seeks to address and the objectives it pursues; (b) the role of each participant and the measures they are to put in place in preparation and once the crisis protocol has been activated; (c) a clear procedure for determining when the crisis protocol is to be activated; (d) a clear procedure for determining the period during which the measures to be taken once the crisis protocol has been activated are to be taken, which is strictly limited to what is necessary for addressing the specific extraordinary circumstances concerned; (e) safeguards to address any negative effects on the exercise of the fundamental rights enshrined in the Charter, in particular the freedom of expression and information and the right to non-discrimination; (f) a process to publicly report on any measures taken, their duration and their outcomes, upon the termination of the crisis situation. 5. If the Commission considers that a crisis protocol fails to effectively address the crisis situation, or to safeguard the exercise of fundamental rights as referred to in paragraph 4, point (e), it shall request the participants to revise the crisis protocol, including by taking additional measures.", "provision_code": "Article 48", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Competent authorities and Digital Services Coordinators", "provision_body": "1. Member States shall designate one or more competent authorities to be responsible for the supervision of providers of intermediary services and enforcement of this Regulation (\u2018competent authorities\u2019). 2. Member States shall designate one of the competent authorities as their Digital Services Coordinator. The Digital Services Coordinator shall be responsible for all matters relating to supervision and enforcement of this Regulation in that Member State, unless the Member State concerned has assigned certain specific tasks or sectors to other competent authorities. The Digital Services Coordinator shall in any event be responsible for ensuring coordination at national level in respect of those matters and for contributing to the effective and consistent supervision and enforcement of this Regulation throughout the Union. For that purpose, Digital Services Coordinators shall cooperate with each other, other national competent authorities, the Board and the Commission, without prejudice to the possibility for Member States to provide for cooperation mechanisms and regular exchanges of views between the Digital Services Coordinator and other national authorities where relevant for the performance of their respective tasks. Where a Member State designates one or more competent authorities in addition to the Digital Services Coordinator, it shall ensure that the respective tasks of those authorities and of the Digital Services Coordinator are clearly defined and that they cooperate closely and effectively when performing their tasks. 3. Member States shall designate the Digital Services Coordinators by 17 February 2024. Member States shall make publicly available, and communicate to the Commission and the Board, the name of their competent authority designated as Digital Services Coordinator and information on how it can be contacted. The Member State concerned shall communicate to the Commission and the Board the name of the other competent authorities referred to in paragraph 2, as well as their respective tasks. 4. The provisions applicable to Digital Services Coordinators set out in Articles 50, 51 and 56 shall also apply to any other competent authorities that the Member States designate pursuant to paragraph 1 of this Article.", "provision_code": "Article 49", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Requirements for Digital Services Coordinators", "provision_body": "1. Member States shall ensure that their Digital Services Coordinators perform their tasks under this Regulation in an impartial, transparent and timely manner. Member States shall ensure that their Digital Services Coordinators have all necessary resources to carry out their tasks, including sufficient technical, financial and human resources to adequately supervise all providers of intermediary services falling within their competence. Each Member State shall ensure that its Digital Services Coordinator has sufficient autonomy in managing its budget within the budget's overall limits, in order not to adversely affect the independence of the Digital Services Coordinator. 2. When carrying out their tasks and exercising their powers in accordance with this Regulation, the Digital Services Coordinators shall act with complete independence. They shall remain free from any external influence, whether direct or indirect, and shall neither seek nor take instructions from any other public authority or any private party. 3. Paragraph 2 of this Article is without prejudice to the tasks of Digital Services Coordinators within the system of supervision and enforcement provided for in this Regulation and the cooperation with other competent authorities in accordance with Article 49(2). Paragraph 2 of this Article shall not prevent the exercise of judicial review and shall also be without prejudice to proportionate accountability requirements regarding the general activities of the Digital Services Coordinators, such as financial expenditure or reporting to national parliaments, provided that those requirements do not undermine the achievement of the objectives of this Regulation.", "provision_code": "Article 50", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Powers of Digital Services Coordinators", "provision_body": "1. Where needed in order to carry out their tasks under this Regulation, Digital Services Coordinators shall have the following powers of investigation, in respect of conduct by providers of intermediary services falling within the competence of their Member State: (a) the power to require those providers, as well as any other persons acting for purposes related to their trade, business, craft or profession that may reasonably be aware of information relating to a suspected infringement of this Regulation, including organisations performing the audits referred to in Article 37 and Article 75(2), to provide such information without undue delay; (b) the power to carry out, or to request a judicial authority in their Member State to order, inspections of any premises that those providers or those persons use for purposes related to their trade, business, craft or profession, or to request other public authorities to do so, in order to examine, seize, take or obtain copies of information relating to a suspected infringement in any form, irrespective of the storage medium; (c) the power to ask any member of staff or representative of those providers or those persons to give explanations in respect of any information relating to a suspected infringement and to record the answers with their consent by any technical means. 2. Where needed for carrying out their tasks under this Regulation, Digital Services Coordinators shall have the following enforcement powers, in respect of providers of intermediary services falling within the competence of their Member State: (a) the power to accept the commitments offered by those providers in relation to their compliance with this Regulation and to make those commitments binding; (b) the power to order the cessation of infringements and, where appropriate, to impose remedies proportionate to the infringement and necessary to bring the infringement effectively to an end, or to request a judicial authority in their Member State to do so; (c) the power to impose fines, or to request a judicial authority in their Member State to do so, in accordance with Article 52 for failure to comply with this Regulation, including with any of the investigative orders issued pursuant to paragraph 1 of this Article; (d) the power to impose a periodic penalty payment, or to request a judicial authority in their Member State to do so, in accordance with Article 52 to ensure that an infringement is terminated in compliance with an order issued pursuant to point (b) of this subparagraph or for failure to comply with any of the investigative orders issued pursuant to paragraph 1 of this Article; (e) the power to adopt interim measures or to request the competent national judicial authority in their Member State to do so, to avoid the risk of serious harm. As regards the first subparagraph, points (c) and (d), Digital Services Coordinators shall also have the enforcement powers set out in those points in respect of the other persons referred to in paragraph 1 for failure to comply with any of the orders issued to them pursuant to that paragraph. They shall only exercise those enforcement powers after providing those other persons in good time with all relevant information relating to such orders, including the applicable period, the fines or periodic payments that may be imposed for failure to comply and the possibilities for redress. 3. Where needed for carrying out their tasks under this Regulation, Digital Services Coordinators shall, in respect of providers of intermediary services falling within the competence of their Member State, where all other powers pursuant to this Article to bring about the cessation of an infringement have been exhausted and the infringement has not been remedied or is continuing and is causing serious harm which cannot be avoided through the exercise of other powers available under Union or national law, also have the power to take the following measures: (a) to require the management body of those providers, without undue delay, to examine the situation, adopt and submit an action plan setting out the necessary measures to terminate the infringement, ensure that the provider takes those measures, and report on the measures taken; (b) where the Digital Services Coordinator considers that a provider of intermediary services has not sufficiently complied with the requirements referred to in point (a), that the infringement has not been remedied or is continuing and is causing serious harm, and that that infringement entails a criminal offence involving a threat to the life or safety of persons, to request that the competent judicial authority of its Member State order the temporary restriction of access of recipients to the service concerned by the infringement or, only where that is not technically feasible, to the online interface of the provider of intermediary services on which the infringement takes place. The Digital Services Coordinator shall, except where it acts upon the Commission\u2019s request referred to in Article 82, prior to submitting the request referred to in the first subparagraph, point (b), of this paragraph invite interested parties to submit written observations within a period that shall not be less than two weeks, describing the measures that it intends to request and identifying the intended addressee or addressees thereof. The provider of intermediary services, the intended addressee or addressees and any other third party demonstrating a legitimate interest shall be entitled to participate in the proceedings before the competent judicial authority. Any measure ordered shall be proportionate to the nature, gravity, recurrence and duration of the infringement, without unduly restricting access to lawful information by recipients of the service concerned. The restriction of access shall be for a period of four weeks, subject to the possibility for the competent judicial authority, in its order, to allow the Digital Services Coordinator to extend that period for further periods of the same lengths, subject to a maximum number of extensions set by that judicial authority. The Digital Services Coordinator shall only extend the period where, having regard to the rights and interests of all parties affected by that restriction and all relevant circumstances, including any information that the provider of intermediary services, the addressee or addressees and any other third party that demonstrated a legitimate interest may provide to it, it considers that both of the following conditions have been met: (a) the provider of intermediary services has failed to take the necessary measures to terminate the infringement; (b) the temporary restriction does not unduly restrict access to lawful information by recipients of the service, having regard to the number of recipients affected and whether any adequate and readily accessible alternatives exist. Where the Digital Services Coordinator considers that the conditions set out in the third subparagraph, points (a) and (b), have been met but it cannot further extend the period pursuant to the third subparagraph, it shall submit a new request to the competent judicial authority, as referred to in the first subparagraph, point (b). 4. The powers listed in paragraphs 1, 2 and 3 shall be without prejudice to Section 3. 5. The measures taken by the Digital Services Coordinators in the exercise of their powers listed in paragraphs 1, 2 and 3 shall be effective, dissuasive and proportionate, having regard, in particular, to the nature, gravity, recurrence and duration of the infringement or suspected infringement to which those measures relate, as well as the economic, technical and operational capacity of the provider of the intermediary services concerned where relevant. 6. Member States shall lay down specific rules and procedures for the exercise of the powers pursuant to paragraphs 1, 2 and 3 and shall ensure that any exercise of those powers is subject to adequate safeguards laid down in the applicable national law in compliance with the Charter and with the general principles of Union law. In particular, those measures shall only be taken in accordance with the right to respect for private life and the rights of defence, including the rights to be heard and of access to the file, and subject to the right to an effective judicial remedy of all affected parties.", "provision_code": "Article 51", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Penalties", "provision_body": "1. Member States shall lay down the rules on penalties applicable to infringements of this Regulation by providers of intermediary services within their competence and shall take all the necessary measures to ensure that they are implemented in accordance with Article 51. 2. Penalties shall be effective, proportionate and dissuasive. Member States shall notify the Commission of those rules and of those measures and shall notify it, without delay, of any subsequent amendments affecting them. 3. Member States shall ensure that the maximum amount of fines that may be imposed for a failure to comply with an obligation laid down in this Regulation shall be 6 % of the annual worldwide turnover of the provider of intermediary services concerned in the preceding financial year. Member States shall ensure that the maximum amount of the fine that may be imposed for the supply of incorrect, incomplete or misleading information, failure to reply or rectify incorrect, incomplete or misleading information and failure to submit to an inspection shall be 1 % of the annual income or worldwide turnover of the provider of intermediary services or person concerned in the preceding financial year. 4. Member States shall ensure that the maximum amount of a periodic penalty payment shall be 5 % of the average daily worldwide turnover or income of the provider of intermediary services concerned in the preceding financial year per day, calculated from the date specified in the decision concerned.", "provision_code": "Article 52", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Right to lodge a complaint", "provision_body": "Recipients of the service and any body, organisation or association mandated to exercise the rights conferred by this Regulation on their behalf shall have the right to lodge a complaint against providers of intermediary services alleging an infringement of this Regulation with the Digital Services Coordinator of the Member State where the recipient of the service is located or established. The Digital Services Coordinator shall assess the complaint and, where appropriate, transmit it to the Digital Services Coordinator of establishment, accompanied, where considered appropriate, by an opinion. Where the complaint falls under the responsibility of another competent authority in its Member State, the Digital Services Coordinator receiving the complaint shall transmit it to that authority. During these proceedings, both parties shall have the right to be heard and receive appropriate information about the status of the complaint, in accordance with national law.", "provision_code": "Article 53", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Compensation", "provision_body": "Recipients of the service shall have the right to seek, in accordance with Union and national law, compensation from providers of intermediary services, in respect of any damage or loss suffered due to an infringement by those providers of their obligations under this Regulation.", "provision_code": "Article 54", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Activity reports", "provision_body": "1. Digital Services Coordinators shall draw up annual reports on their activities under this Regulation, including the number of complaints received pursuant to Article 53 and an overview of their follow-up. The Digital Services Coordinators shall make the annual reports available to the public in a machine-readable format, subject to the applicable rules on the confidentiality of information pursuant to Article 84, and shall communicate them to the Commission and to the Board. 2. The annual report shall also include the following information: (a) the number and subject matter of orders to act against illegal content and orders to provide information issued in accordance with Articles 9 and 10 by any national judicial or administrative authority of the Member State of the Digital Services Coordinator concerned; (b) the effects given to those orders, as communicated to the Digital Services Coordinator pursuant to Articles 9 and 10. 3. Where a Member State has designated several competent authorities pursuant to Article 49, it shall ensure that the Digital Services Coordinator draws up a single report covering the activities of all competent authorities and that the Digital Services Coordinator receives all relevant information and support needed to that effect from the other competent authorities concerned.", "provision_code": "Article 55", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Competences", "provision_body": "1. The Member State in which the main establishment of the provider of intermediary services is located shall have exclusive powers to supervise and enforce this Regulation, except for the powers provided for in paragraphs 2, 3 and 4. 2. The Commission shall have exclusive powers to supervise and enforce Section 5 of Chapter III. 3. The Commission shall have powers to supervise and enforce this Regulation, other than those laid down in Section 5 of Chapter III thereof, against providers of very large online platforms and of very large online search engines. 4. Where the Commission has not initiated proceedings for the same infringement, the Member State in which the main establishment of the provider of very large online platform or of very large online search engine is located shall have powers to supervise and enforce the obligations under this Regulation, other than those laid down in Section 5 of Chapter III, with respect to those providers. 5. Member States and the Commission shall supervise and enforce the provisions of this Regulation in close cooperation. 6. Where a provider of intermediary services does not have an establishment in the Union, the Member State where its legal representative resides or is established or the Commission shall have powers, as applicable, in accordance with paragraphs 1 and 4 of this Article, to supervise and enforce the relevant obligations under this Regulation. 7. Where a provider of intermediary services fails to appoint a legal representative in accordance with Article 13, all Member States and, in case of a provider of a very large online platform or very large online search engine, the Commission shall have powers to supervise and enforce in accordance with this Article. Where a Digital Services Coordinator intends to exercise its powers under this paragraph, it shall notify all other Digital Services Coordinators and the Commission, and ensure that the applicable safeguards afforded by the Charter are respected, in particular to avoid that the same conduct is sanctioned more than once for the infringement of the obligations laid down in this Regulation. Where the Commission intends to exercise its powers under this paragraph, it shall notify all other Digital Services Coordinators of that intention. Following the notification pursuant to this paragraph, other Member States shall not initiate proceedings for the same infringement as that referred to in the notification.", "provision_code": "Article 56", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Mutual assistance", "provision_body": "1. Digital Services Coordinators and the Commission shall cooperate closely and provide each other with mutual assistance in order to apply this Regulation in a consistent and efficient manner. Mutual assistance shall include, in particular, exchange of information in accordance with this Article and the duty of the Digital Services Coordinator of establishment to inform all Digital Services Coordinators of destination, the Board and the Commission about the opening of an investigation and the intention to take a final decision, including its assessment, in respect of a specific provider of intermediary services. 2. For the purpose of an investigation, the Digital Services Coordinator of establishment may request other Digital Services Coordinators to provide specific information in their possession as regards a specific provider of intermediary services or to exercise their investigative powers referred to in Article 51(1) with regard to specific information located in their Member State. Where appropriate, the Digital Services Coordinator receiving the request may involve other competent authorities or other public authorities of the Member State in question. 3. The Digital Services Coordinator receiving the request pursuant to paragraph 2 shall comply with such request and inform the Digital Services Coordinator of establishment about the action taken, without undue delay and no later than two months after its receipt, unless: (a) the scope or the subject matter of the request is not sufficiently specified, justified or proportionate in view of the investigative purposes; or (b) neither the requested Digital Service Coordinator nor other competent authority or other public authority of that Member State is in possession of the requested information nor can have access to it; or (c) the request cannot be complied with without infringing Union or national law. The Digital Services Coordinator receiving the request shall justify its refusal by submitting a reasoned reply, within the period set out in the first subparagraph.", "provision_code": "Article 57", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Cross-border cooperation among Digital Services Coordinators", "provision_body": "1. Unless the Commission has initiated an investigation for the same alleged infringement, where a Digital Services Coordinator of destination has reason to suspect that a provider of an intermediary service has infringed this Regulation in a manner negatively affecting the recipients of the service in the Member State of that Digital Services Coordinator, it may request the Digital Services Coordinator of establishment to assess the matter and to take the necessary investigatory and enforcement measures to ensure compliance with this Regulation. 2. Unless the Commission has initiated an investigation for the same alleged infringement, and at the request of at least three Digital Services Coordinators of destination that have reason to suspect that a specific provider of intermediary services infringed this Regulation in a manner negatively affecting recipients of the service in their Member States, the Board may request the Digital Services Coordinator of establishment to assess the matter and take the necessary investigatory and enforcement measures to ensure compliance with this Regulation. 3. A request pursuant to paragraph 1 or 2 shall be duly reasoned, and shall at least indicate: (a) the point of contact of the provider of the intermediary services concerned as provided for in Article 11; (b) a description of the relevant facts, the provisions of this Regulation concerned and the reasons why the Digital Services Coordinator that sent the request, or the Board, suspects that the provider infringed this Regulation, including the description of the negative effects of the alleged infringement; (c) any other information that the Digital Services Coordinator that sent the request, or the Board, considers relevant, including, where appropriate, information gathered on its own initiative or suggestions for specific investigatory or enforcement measures to be taken, including interim measures. 4. The Digital Services Coordinator of establishment shall take utmost account of the request pursuant to paragraphs 1 or 2 of this Article. Where it considers that it has insufficient information to act upon the request and has reasons to consider that the Digital Services Coordinator that sent the request, or the Board, could provide additional information, the Digital Services Coordinator of establishment may either request such information in accordance with Article 57 or, alternatively, may launch a joint investigation pursuant to Article 60(1) involving at least the requesting Digital Services Coordinator. The period laid down in paragraph 5 of this Article shall be suspended until that additional information is provided or until the invitation to participate in the joint investigation is refused. 5. The Digital Services Coordinator of establishment shall, without undue delay and in any event not later than two months following receipt of the request pursuant to paragraph 1 or 2, communicate to the Digital Services Coordinator that sent the request, and the Board, the assessment of the suspected infringement and an explanation of any investigatory or enforcement measures taken or envisaged in relation thereto to ensure compliance with this Regulation.", "provision_code": "Article 58", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Referral to the Commission", "provision_body": "1. In the absence of a communication within the period laid down in Article 58(5), in the case of a disagreement of the Board with the assessment or the measures taken or envisaged pursuant to Article 58(5) or in the cases referred to in Article 60(3), the Board may refer the matter to the Commission, providing all relevant information. That information shall include at least the request or recommendation sent to the Digital Services Coordinator of establishment, the assessment by that Digital Services Coordinator, the reasons for the disagreement and any additional information supporting the referral. 2. The Commission shall assess the matter within two months following the referral of the matter pursuant to paragraph 1, after having consulted the Digital Services Coordinator of establishment. 3. Where, pursuant to paragraph 2 of this Article, the Commission considers that the assessment or the investigatory or enforcement measures taken or envisaged pursuant to Article 58(5) are insufficient to ensure effective enforcement or otherwise incompatible with this Regulation, it shall communicate its views to the Digital Services Coordinator of establishment and the Board and request the Digital Services Coordinator of establishment to review the matter. The Digital Services Coordinator of establishment shall take the necessary investigatory or enforcement measures to ensure compliance with this Regulation, taking utmost account of the views and request for review by the Commission. The Digital Services Coordinator of establishment shall inform the Commission, as well as the requesting Digital Services Coordinator or the Board that took action pursuant to Article 58(1) or (2), about the measures taken within two months from that request for review.", "provision_code": "Article 59", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Joint investigations", "provision_body": "1. The Digital Services Coordinator of establishment may launch and lead joint investigations with the participation of one or more other Digital Services Coordinators concerned: (a) at its own initiative, to investigate an alleged infringement of this Regulation by a given provider of intermediary services in several Member States; or (b) upon recommendation of the Board, acting on the request of at least three Digital Services Coordinators alleging, based on a reasonable suspicion, an infringement by a given provider of intermediary services affecting recipients of the service in their Member States. 2. Any Digital Services Coordinator that proves that it has a legitimate interest in participating in a joint investigation pursuant to paragraph 1 may request to do so. The joint investigation shall be concluded within three months from its launch, unless otherwise agreed amongst the participants. The Digital Services Coordinator of establishment shall communicate its preliminary position on the alleged infringement no later than one month after the end of the deadline referred to in the first subparagraph to all Digital Services Coordinators, the Commission and the Board. The preliminary position shall take into account the views of all other Digital Services Coordinators participating in the joint investigation. Where applicable, this preliminary position shall also set out the enforcement measures envisaged. 3. The Board may refer the matter to the Commission pursuant to Article 59, where: (a) the Digital Services Coordinator of establishment failed to communicate its preliminary position within the deadline set out in paragraph 2; (b) the Board substantially disagrees with the preliminary position communicated by the Digital Services Coordinator of establishment; or (c) the Digital Services Coordinator of establishment failed to initiate the joint investigation promptly following the recommendation by the Board pursuant to paragraph 1, point (b). 4. In carrying out the joint investigation, the participating Digital Services Coordinators shall cooperate in good faith, taking into account, where applicable, the indications of the Digital Services Coordinator of establishment and the Board\u2019s recommendation. The Digital Services Coordinators of destination participating in the joint investigation shall be entitled, at the request of or after having consulted the Digital Services Coordinator of establishment, to exercise their investigative powers referred to in Article 51(1) in respect of the providers of intermediary services concerned by the alleged infringement, with regard to information and premises located within their territory.", "provision_code": "Article 60", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "European Board for Digital Services", "provision_body": "1. An independent advisory group of Digital Services Coordinators on the supervision of providers of intermediary services named \u2018European Board for Digital Services\u2019 (the \u2018Board\u2019) is established. 2. The Board shall advise the Digital Services Coordinators and the Commission in accordance with this Regulation to achieve the following objectives: (a) contributing to the consistent application of this Regulation and effective cooperation of the Digital Services Coordinators and the Commission with regard to matters covered by this Regulation; (b) coordinating and contributing to guidelines and analysis of the Commission and Digital Services Coordinators and other competent authorities on emerging issues across the internal market with regard to matters covered by this Regulation; (c) assisting the Digital Services Coordinators and the Commission in the supervision of very large online platforms.", "provision_code": "Article 61", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Structure of the Board", "provision_body": "1. The Board shall be composed of Digital Services Coordinators who shall be represented by high-level officials. The failure by one or more Member States to designate a Digital Services Coordinator shall not prevent the Board from performing its tasks under this Regulation. Where provided for by national law, other competent authorities entrusted with specific operational responsibilities for the application and enforcement of this Regulation alongside the Digital Services Coordinator may participate in the Board. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them. 2. The Board shall be chaired by the Commission. The Commission shall convene the meetings and prepare the agenda in accordance with the tasks of the Board pursuant to this Regulation and in line with its rules of procedure. When the Board is requested to adopt a recommendation pursuant to this Regulation, it shall immediately make the request available to other Digital Services Coordinators through the information sharing system set out in Article 85. 3. Each Member State shall have one vote. The Commission shall not have voting rights. The Board shall adopt its acts by simple majority. When adopting a recommendation to the Commission referred to in Article 36(1), first subparagraph, the Board shall vote within 48 hours after the request of the Chair of the Board. 4. The Commission shall provide administrative and analytical support for the activities of the Board pursuant to this Regulation. 5. The Board may invite experts and observers to attend its meetings, and may cooperate with other Union bodies, offices, agencies and advisory groups, as well as external experts as appropriate. The Board shall make the results of this cooperation publicly available. 6. The Board may consult interested parties, and shall make the results of such consultation publicly available. 7. The Board shall adopt its rules of procedure, following the consent of the Commission.", "provision_code": "Article 62", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Tasks of the Board", "provision_body": "1. Where necessary to meet the objectives set out in Article 61(2), the Board shall in particular: (a) support the coordination of joint investigations; (b) support the competent authorities in the analysis of reports and results of audits of very large online platforms or of very large online search engines to be transmitted pursuant to this Regulation; (c) issue opinions, recommendations or advice to Digital Services Coordinators in accordance with this Regulation, taking into account, in particular, the freedom to provide services of the providers of intermediary service; (d) advise the Commission on the measures referred to in Article 66 and, adopt opinions concerning very large online platforms or very large online search engines in accordance with this Regulation; (e) support and promote the development and implementation of European standards, guidelines, reports, templates and code of conducts in cooperation with relevant stakeholders as provided for in this Regulation, including by issuing opinions or recommendations on matters related to Article 44, as well as the identification of emerging issues, with regard to matters covered by this Regulation. 2. Digital Services Coordinators and, where applicable, other competent authorities that do not follow the opinions, requests or recommendations addressed to them adopted by the Board shall provide the reasons for this choice, including an explanation on the investigations, actions and the measures that they have implemented, when reporting pursuant to this Regulation or when adopting their relevant decisions, as appropriate.", "provision_code": "Article 63", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Development of expertise and capabilities", "provision_body": "1. The Commission, in cooperation with the Digital Services Coordinators and the Board, shall develop Union expertise and capabilities, including, where appropriate, through the secondment of Member States\u2019 personnel. 2. In addition, the Commission, in cooperation with the Digital Services Coordinators and the Board, shall coordinate the assessment of systemic and emerging issues across the Union in relation to very large online platforms or very large online search engines with regard to matters covered by this Regulation. 3. The Commission may ask the Digital Services Coordinators, the Board and other Union bodies, offices and agencies with relevant expertise to support the assessment of systemic and emerging issues across the Union under this Regulation. 4. Member States shall cooperate with the Commission, in particular through their respective Digital Services Coordinators and other competent authorities, where applicable, including by making available their expertise and capabilities.", "provision_code": "Article 64", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Enforcement of obligations of providers of very large online platforms and of very large online search engines", "provision_body": "1. For the purposes of investigating compliance of providers of very large online platforms and of very large online search engines with the obligations laid down in this Regulation, the Commission may exercise the investigatory powers laid down in this Section even before initiating proceedings pursuant to Article 66(2). It may exercise those powers on its own initiative or following a request pursuant to paragraph 2 of this Article. 2. Where a Digital Services Coordinator has reason to suspect that a provider of a very large online platform or of a very large online search engine has infringed the provisions of Section 5 of Chapter III or has systemically infringed any of the provisions of this Regulation in a manner that seriously affects recipients of the service in its Member State, it may send, through the information sharing system referred to in Article 85, a request to the Commission to assess the matter. 3. A request pursuant to paragraph 2 shall be duly reasoned and at least indicate: (a) the point of contact of the provider of the very large online platform or of the very large online search engine concerned as provided for in Article 11; (b) a description of the relevant facts, the provisions of this Regulation concerned and the reasons why the Digital Services Coordinator that sent the request suspects that the provider of the very large online platforms or of the very large online search engine concerned infringed this Regulation, including a description of the facts that show that the suspected infringement is of a systemic nature; (c) any other information that the Digital Services Coordinator that sent the request considers relevant, including, where appropriate, information gathered on its own initiative.", "provision_code": "Article 65", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Initiation of proceedings by the Commission and cooperation in investigation", "provision_body": "1. The Commission may initiate proceedings in view of the possible adoption of decisions pursuant to Articles 73 and 74 in respect of the relevant conduct by the provider of the very large online platform or of the very large online search engine that the Commission suspect of having infringed any of the provisions of this Regulation. 2. Where the Commission decides to initiate proceedings pursuant to paragraph 1 of this Article, it shall notify all Digital Services Coordinators and the Board through the information sharing system referred to in Article 85, as well as the provider of the very large online platform or of the very large online search engine concerned. The Digital Services Coordinators shall, without undue delay after being informed of initiation of the proceedings, transmit to the Commission any information they hold about the infringement at stake. The initiation of proceedings pursuant to paragraph 1 of this Article by the Commission shall relieve the Digital Services Coordinator, or any competent authority where applicable, of its powers to supervise and enforce provided for in this Regulation pursuant to Article 56(4). 3. In the exercise of its powers of investigation under this Regulation the Commission may request the individual or joint support of any Digital Services Coordinators concerned by the suspected infringement, including the Digital Services Coordinator of establishment. The Digital Services Coordinators that have received such a request, and, where involved by the Digital Services Coordinator, any other competent authority, shall cooperate sincerely and in a timely manner with the Commission and shall be entitled to exercise their investigative powers referred to in Article 51(1) in respect of the provider of the very large online platform or of the very large online search engine at stake, with regard to information, persons and premises located within the territory of their Member State and in accordance with the request. 4. The Commission shall provide the Digital Services Coordinator of establishment and the Board with all relevant information about the exercise of the powers referred to in Articles 67 to 72 and its preliminary findings referred to in Article 79(1). The Board shall submit its views on those preliminary findings to the Commission within the period set pursuant to Article 79(2). The Commission shall take utmost account of any views of the Board in its decision.", "provision_code": "Article 66", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Requests for information", "provision_body": "1. In order to carry out the tasks assigned to it under this Section, the Commission may, by simple request or by decision, require the provider of the very large online platform or of the very large online search engine concerned, as well as any other natural or legal person acting for purposes related to their trade, business, craft or profession that may be reasonably aware of information relating to the suspected infringement, including organisations performing the audits referred to in Article 37 and Article 75(2), to provide such information within a reasonable period. 2. When sending a simple request for information to the provider of the very large online platform or of the very large online search engine concerned or other person referred to in paragraph 1 of this Article, the Commission shall state the legal basis and the purpose of the request, specify what information is required and set the period within which the information is to be provided, and the fines provided for in Article 74 for supplying incorrect, incomplete or misleading information. 3. Where the Commission requires the provider of the very large online platform or of the very large online search engine concerned or other person referred to in paragraph 1 of this Article to supply information by decision, it shall state the legal basis and the purpose of the request, specify what information is required and set the period within which it is to be provided. It shall also indicate the fines provided for in Article 74 and indicate or impose the periodic penalty payments provided for in Article 76. It shall further indicate the right to have the decision reviewed by the Court of Justice of the European Union. 4. The providers of the very large online platform or of the very large online search engine concerned or other person referred to in paragraph 1 or their representatives and, in the case of legal persons, companies or firms, or where they have no legal personality, the persons authorised to represent them by law or by their constitution shall supply the information requested on behalf of the provider of the very large online platform or of the very large online search engine concerned or other person referred to in paragraph 1. Lawyers duly authorised to act may supply the information on behalf of their clients. The latter shall remain fully responsible if the information supplied is incomplete, incorrect or misleading. 5. At the request of the Commission, the Digital Services Coordinators and other competent authorities shall provide the Commission with all necessary information to carry out the tasks assigned to it under this Section. 6. The Commission shall, without undue delay after sending the simple request or the decision referred to in paragraph 1 of this Article, send a copy thereof to the Digital Services Coordinators, through the information sharing system referred to in Article 85.", "provision_code": "Article 67", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Power to take interviews and statements", "provision_body": "1. In order to carry out the tasks assigned to it under this Section, the Commission may interview any natural or legal person who consents to being interviewed for the purpose of collecting information, relating to the subject-matter of an investigation, in relation to the suspected infringement. The Commission shall be entitled to record such interview by appropriate technical means. 2. If the interview referred to in paragraph 1 is conducted on other premises than those of the Commission, the Commission shall inform the Digital Services Coordinator of the Member State in the territory of which the interview takes place. If so requested by that Digital Services Coordinator, its officials may assist the officials and other accompanying persons authorised by the Commission to conduct the interview.", "provision_code": "Article 68", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Power to conduct inspections", "provision_body": "1. In order to carry out the tasks assigned to it under this Section, the Commission may conduct all necessary inspections at the premises of the provider of the very large online platform or of the very large online search engine concerned or of another person referred to in Article 67(1). 2. The officials and other accompanying persons authorised by the Commission to conduct an inspection shall be empowered to: (a) enter any premises, land and means of transport of the provider of the very large online platform or of the very large online search engine concerned or of the other person concerned; (b) examine the books and other records related to the provision of the service concerned, irrespective of the medium on which they are stored; (c) take or obtain in any form copies of or extracts from such books or other records; (d) require the provider of the very large online platform or of the very large online search engine or the other person concerned to provide access to and explanations on its organisation, functioning, IT system, algorithms, data-handling and business practices and to record or document the explanations given; (e) seal any premises used for purposes related to the trade, business, craft or profession of the provider of the very large online platform or of the very large online search engine or of the other person concerned, as well as books or other records, for the period and to the extent necessary for the inspection; (f) ask any representative or member of staff of the provider of the very large online platform or of the very large online search engine or the other person concerned for explanations on facts or documents relating to the subject-matter and purpose of the inspection and to record the answers; (g) address questions to any such representative or member of staff relating to the subject-matter and purpose of the inspection and to record the answers. 3. Inspections may be carried out with the assistance of auditors or experts appointed by the Commission pursuant to Article 72(2), and of Digital Services Coordinator or other competent national authorities of the Member State in the territory of which the inspection is conducted. 4. Where the production of required books or other records related to the provision of the service concerned is incomplete or where the answers to questions asked under paragraph 2 of this Article are incorrect, incomplete or misleading, the officials and other accompanying persons authorised by the Commission to conduct an inspection shall exercise their powers upon production of a written authorisation specifying the subject matter and purpose of the inspection and the penalties provided for in Articles 74 and 76. In good time before the inspection, the Commission shall inform the Digital Services Coordinator of the Member State in the territory in which the inspection is to be conducted thereof. 5. During inspections, the officials and other accompanying persons authorised by the Commission, the auditors and experts appointed by the Commission, the Digital Services Coordinator or the other competent authorities of the Member State in the territory of which the inspection is conducted may require the provider of the very large online platform or of the very large online search engine or other person concerned to provide explanations on its organisation, functioning, IT system, algorithms, data-handling and business conducts, and may address questions to its key personnel. 6. The provider of the very large online platform or of the very large online search engine or other natural or legal person concerned shall be required to submit to an inspection ordered by decision of the Commission. The decision shall specify the subject matter and purpose of the inspection, set the date on which it is to begin and indicate the penalties provided for in Articles 74 and 76 and the right to have the decision reviewed by the Court of Justice of the European Union. The Commission shall consult the Digital Services Coordinator of the Member State on territory of which the inspection is to be conducted prior to taking that decision. 7. Officials of, and other persons authorised or appointed by, the Digital Services Coordinator of the Member State on the territory of which the inspection is to be conducted shall, at the request of that Digital Services Coordinator or of the Commission, actively assist the officials and other accompanying persons authorised by the Commission in relation to the inspection. To this end, they shall have the powers listed in paragraph 2. 8. Where the officials and other accompanying persons authorised by the Commission find that the provider of the very large online platform or of the very large online search engine or the other person concerned opposes an inspection ordered pursuant to this Article, the Member State in the territory of which the inspection is to be conducted shall, at the request of those officials or other accompanying persons and in accordance with the national law of the Member State, afford them necessary assistance, including, where appropriate under that national law, in the form of coercive measures taken by a competent law enforcement authority, so as to enable them to conduct the inspection. 9. If the assistance provided for in paragraph 8 requires authorisation from a national judicial authority in accordance with the national law of the Member State concerned, such authorisation shall be applied for by the Digital Services Coordinator of that Member State at the request of the officials and other accompanying persons authorised by the Commission. Such authorisation may also be applied for as a precautionary measure. 10. Where the authorisation referred to in paragraph 9 is applied for, the national judicial authority before which a case has been brought shall verify that the Commission decision ordering the inspection is authentic and that the coercive measures envisaged are neither arbitrary nor excessive having regard to the subject matter of the inspection. When conducting such verification, the national judicial authority may ask the Commission, directly or through the Digital Services Coordinators of the Member State concerned, for detailed explanations, in particular those concerning the grounds on which the Commission suspects an infringement of this Regulation, concerning the seriousness of the suspected infringement and concerning the nature of the involvement of the provider of the very large online platform or of the very large online search engine or of the other person concerned. However, the national judicial authority shall not call into question the necessity for the inspection nor demand information from the case file of the Commission. The lawfulness of the Commission decision shall be subject to review only by the Court of Justice of the European Union.", "provision_code": "Article 69", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Interim measures", "provision_body": "1. In the context of proceedings which may lead to the adoption of a decision of non-compliance pursuant to Article 73(1), where there is an urgency due to the risk of serious damage for the recipients of the service, the Commission may, by decision, order interim measures against the provider of the very large online platform or of the very large online search engine concerned on the basis of a prima facie finding of an infringement. 2. A decision under paragraph 1 shall apply for a specified period of time and may be renewed in so far this is necessary and appropriate.", "provision_code": "Article 70", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Commitments", "provision_body": "1. If, during proceedings under this Section, the provider of the very large online platform or of the very large online search engine concerned offers commitments to ensure compliance with the relevant provisions of this Regulation, the Commission may by decision make those commitments binding on the provider of the very large online platform or of the very large online search engine concerned and declare that there are no further grounds for action. 2. The Commission may, upon request or on its own initiative, reopen the proceedings: (a) where there has been a material change in any of the facts on which the decision was based; (b) where the provider of the very large online platform or of the very large online search engine concerned acts contrary to its commitments; or (c) where the decision was based on incomplete, incorrect or misleading information provided by the provider of the very large online platform or of the very large online search engine concerned or other person referred to in Article 67(1). 3. Where the Commission considers that the commitments offered by the provider of the very large online platform or of the very large online search engine concerned are unable to ensure effective compliance with the relevant provisions of this Regulation, it shall reject those commitments in a reasoned decision when concluding the proceedings.", "provision_code": "Article 71", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Monitoring actions", "provision_body": "1. For the purposes of carrying out the tasks assigned to it under this Section, the Commission may take the necessary actions to monitor the effective implementation and compliance with this Regulation by providers of the very large online platform and of the very large online search engines. The Commission may order them to provide access to, and explanations relating to, its databases and algorithms. Such actions may include, imposing an obligation on the provider of the very large online platform or of the very large online search engine to retain all documents deemed to be necessary to assess the implementation of and compliance with the obligations under this Regulation. 2. The actions pursuant to paragraph 1 may include the appointment of independent external experts and auditors, as well as experts and auditors from competent national authorities with the agreement of the authority concerned, to assist the Commission in monitoring the effective implementation and compliance with the relevant provisions of this Regulation and to provide specific expertise or knowledge to the Commission.", "provision_code": "Article 72", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Non-compliance", "provision_body": "1. The Commission shall adopt a non-compliance decision where it finds that the provider of the very large online platform or of the very large online search engine concerned does not comply with one or more of the following: (a) the relevant provisions of this Regulation; (b) interim measures ordered pursuant to Article 70; (c) commitments made binding pursuant to Article 71.", "provision_code": "Article 73", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Fines", "provision_body": "1. In the decision referred to in Article 73, the Commission may impose on the provider of the very large online platform or of the very large online search engine concerned fines not exceeding 6 % of its total worldwide annual turnover in the preceding financial year where it finds that the provider, intentionally or negligently: (a) infringes the relevant provisions of this Regulation; (b) fails to comply with a decision ordering interim measures under Article 70; or (c) fails to comply with a commitment made binding by a decision pursuant to Article 71. 2. The Commission may adopt a decision imposing on the provider of the very large online platform or of the very large online search engine concerned or on another natural or legal person referred to in Article 67(1) fines not exceeding 1 % of the total annual income or worldwide turnover in the preceding financial year, where they intentionally or negligently: (a) supply incorrect, incomplete or misleading information in response to a simple request or request by a decision pursuant to Article 67; (b) fail to reply to the request for information by decision within the set period; (c) fail to rectify within the period set by the Commission, incorrect, incomplete or misleading information given by a member of staff, or fail or refuse to provide complete information; (d) refuse to submit to an inspection pursuant to Article 69; (e) fail to comply with the measures adopted by the Commission pursuant to Article 72; or (f) fail to comply with the conditions for access to the Commission\u2019s file pursuant to Article 79(4). 3. Before adopting the decision pursuant to paragraph 2 of this Article, the Commission shall communicate its preliminary findings to the provider of the very large online platform or of the very large online search engine concerned or to another person referred to in Article 67(1). 4. In fixing the amount of the fine, the Commission shall have regard to the nature, gravity, duration and recurrence of the infringement and, for fines imposed pursuant to paragraph 2, the delay caused to the proceedings.", "provision_code": "Article 74", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Enhanced supervision of remedies to address infringements of obligations laid down in Section 5 of Chapter III", "provision_body": "1. When adopting a decision pursuant to Article 73 in relation to an infringement by a provider of a very large online platform or of a very large online search engine of any of the provisions of Section 5 of Chapter III, the Commission shall make use of the enhanced supervision system laid down in this Article. When doing so, it shall take utmost account of any opinion of the Board pursuant to this Article. 2. In the decision referred to in Article 73, the Commission shall require the provider of a very large online platform or of a very large online search engine concerned to draw up and communicate, within a reasonable period specified in the decision, to the Digital Services Coordinators, the Commission and the Board an action plan setting out the necessary measures which are sufficient to terminate or remedy the infringement. Those measures shall include a commitment to perform an independent audit in accordance with Article 37(3) and (4) on the implementation of the other measures, and shall specify the identity of the auditors, as well as the methodology, timing and follow-up of the audit. The measures may also include, where appropriate, a commitment to participate in a relevant code of conduct, as provided for in Article 45. 3. Within one month following receipt of the action plan, the Board shall communicate its opinion on the action plan to the Commission. Within one month following receipt of that opinion, the Commission shall decide whether the measures set out in the action plan are sufficient to terminate or remedy the infringement, and shall set a reasonable period for its implementation. The possible commitment to adhere to relevant codes of conduct shall be taken into account in that decision. The Commission shall subsequently monitor the implementation of the action plan. To that end, the provider of a very large online platform or of a very large online search engine concerned shall communicate the audit report to the Commission without undue delay after it becomes available, and shall keep the Commission up to date on steps taken to implement the action plan. The Commission may, where necessary for such monitoring, require the provider of a very large online platform or of a very large online search engine concerned to provide additional information within a reasonable period set by the Commission. The Commission shall keep the Board and the Digital Services Coordinators informed about the implementation of the action plan, and about its monitoring thereof. 4. The Commission may take necessary measures in accordance with this Regulation, in particular Article 76(1), point (e), and Article 82(1), where: (a) the provider of the very large online platform or of the very large online search engine concerned fails to provide any action plan, the audit report, the necessary updates or any additional information required, within the applicable period; (b) the Commission rejects the proposed action plan because it considers that the measures set out therein are insufficient to terminate or remedy the infringement; or (c) the Commission considers, on the basis of the audit report, any updates or additional information provided or any other relevant information available to it, that the implementation of the action plan is insufficient to terminate or remedy the infringement.", "provision_code": "Article 75", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Periodic penalty payments", "provision_body": "1. The Commission may adopt a decision, imposing on the provider of the very large online platform or of the very large online search engine concerned or other person referred to in Article 67(1), as applicable, periodic penalty payments not exceeding 5 % of the average daily income or worldwide annual turnover in the preceding financial year per day, calculated from the date appointed by the decision, in order to compel them to: (a) supply correct and complete information in response to a decision requiring information pursuant to Article 67; (b) submit to an inspection which it has ordered by decision pursuant to Article 69; (c) comply with a decision ordering interim measures pursuant to Article 70(1); (d) comply with commitments made legally binding by a decision pursuant to Article 71(1); (e) comply with a decision pursuant to Article 73(1), including where applicable the requirements it contains relating to the action plan referred to in Article 75. 2. Where the provider of the very large online platform or of the very large online search engine concerned or other person referred to in Article 67(1) has satisfied the obligation which the periodic penalty payment was intended to enforce, the Commission may fix the definitive amount of the periodic penalty payment at a figure lower than that under the original decision.", "provision_code": "Article 76", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Limitation period for the imposition of penalties", "provision_body": "1. The powers conferred on the Commission by Articles 74 and 76 shall be subject to a limitation period of five years. 2. Time shall begin to run on the day on which the infringement is committed. However, in the case of continuing or repeated infringements, time shall begin to run on the day on which the infringement ceases. 3. Any action taken by the Commission or by the Digital Services Coordinator for the purpose of the investigation or proceedings in respect of an infringement shall interrupt the limitation period for the imposition of fines or periodic penalty payments. Actions which interrupt the limitation period shall include, in particular, the following: (a) requests for information by the Commission or by a Digital Services Coordinator; (b) inspection; (c) the opening of a proceeding by the Commission pursuant to Article 66(1). 4. Each interruption shall start time running afresh. However, the limitation period for the imposition of fines or periodic penalty payments shall expire at the latest on the day on which a period equal to twice the limitation period has elapsed without the Commission having imposed a fine or a periodic penalty payment. That period shall be extended by the time during which the limitation period has been suspended pursuant to paragraph 5. 5. The limitation period for the imposition of fines or periodic penalty payments shall be suspended for as long as the decision of the Commission is the subject of proceedings pending before the Court of Justice of the European Union.", "provision_code": "Article 77", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Limitation period for the enforcement of penalties", "provision_body": "1. The power of the Commission to enforce decisions taken pursuant to Articles 74 and 76 shall be subject to a limitation period of five years. 2. Time shall begin to run on the day on which the decision becomes final. 3. The limitation period for the enforcement of penalties shall be interrupted: (a) by notification of a decision varying the original amount of the fine or periodic penalty payment or refusing an application for variation; (b) by any action of the Commission, or of a Member State acting at the request of the Commission, designed to enforce payment of the fine or periodic penalty payment. 4. Each interruption shall start time running afresh. 5. The limitation period for the enforcement of penalties shall be suspended for so long as: (a) time to pay is allowed; (b) enforcement of payment is suspended pursuant to a decision of the Court of Justice of the European Union or to a decision of a national court.", "provision_code": "Article 78", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Right to be heard and access to the file", "provision_body": "1. Before adopting a decision pursuant to Article 73(1), Article 74 or 76, the Commission shall give the provider of the very large online platform or of the very large online search engine concerned or other person referred to in Article 67(1) the opportunity of being heard on: (a) preliminary findings of the Commission, including any matter to which the Commission has taken objections; and (b) measures that the Commission may intend to take in view of the preliminary findings referred to point (a). 2. The provider of the very large online platform or of the very large online search engine concerned or other person referred to in Article 67(1) may submit its observations on the Commission\u2019s preliminary findings within a reasonable period set by the Commission in its preliminary findings, which may not be less than 14 days. 3. The Commission shall base its decisions only on objections on which the parties concerned have been able to comment. 4. The rights of defence of the parties concerned shall be fully respected in the proceedings. They shall be entitled to have access to the Commission's file under the terms of a negotiated disclosure, subject to the legitimate interest of the provider of the very large online platform or of the very large online search engine or other person concerned in the protection of their business secrets. The Commission shall have the power to adopt decisions setting out such terms of disclosure in case of disagreement between the parties. The right of access to the file of the Commission shall not extend to confidential information and internal documents of the Commission, the Board, Digital Service Coordinators, other competent authorities or other public authorities of the Member States. In particular, the right of access shall not extend to correspondence between the Commission and those authorities. Nothing in this paragraph shall prevent the Commission from disclosing and using information necessary to prove an infringement. 5. The information collected pursuant to Articles 67, 68 and 69 shall be used only for the purpose of this Regulation.", "provision_code": "Article 79", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Publication of decisions", "provision_body": "1. The Commission shall publish the decisions it adopts pursuant to Article 70(1), Article 71(1) and Articles 73 to 76. Such publication shall state the names of the parties and the main content of the decision, including any penalties imposed. 2. The publication shall have regard to the rights and legitimate interests of the provider of the very large online platform or of the very large online search engine concerned, any other person referred to in Article 67(1) and any third parties in the protection of their confidential information.", "provision_code": "Article 80", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Review by the Court of Justice of the European Union", "provision_body": "In accordance with Article 261 TFEU, the Court of Justice of the European Union has unlimited jurisdiction to review decisions by which the Commission has imposed fines or periodic penalty payments. It may cancel, reduce or increase the fine or periodic penalty payment imposed.", "provision_code": "Article 81", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Requests for access restrictions and cooperation with national courts", "provision_body": "1. Where all powers pursuant to this Section to bring about the cessation of an infringement of this Regulation have been exhausted, the infringement persists and causes serious harm which cannot be avoided through the exercise of other powers available under Union or national law, the Commission may request the Digital Services Coordinator of establishment of the provider of the very large online platform or of the very large online search engine concerned to act pursuant to Article 51(3). Prior to making such request to the Digital Services Coordinator, the Commission shall invite interested parties to submit written observations within a period that shall not be less than 14 working days, describing the measures it intends to request and identifying the intended addressee or addressees thereof. 2. Where the coherent application of this Regulation so requires, the Commission, acting on its own initiative, may submit written observations to the competent judicial authority referred to Article 51(3). With the permission of the judicial authority in question, it may also make oral observations. For the purpose of the preparation of its observations only, the Commission may request that judicial authority to transmit or ensure the transmission to it of any documents necessary for the assessment of the case. 3. When a national court rules on a matter which is already the subject matter of a decision adopted by the Commission under this Regulation, that national court shall not take any decision which runs counter to that Commission decision. National courts shall also avoid taking decisions which could conflict with a decision contemplated by the Commission in proceedings it has initiated under this Regulation. To that effect, a national court may assess whether it is necessary to stay its proceedings. This is without prejudice to Article 267 TFEU.", "provision_code": "Article 82", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Implementing acts relating to Commission intervention", "provision_body": "In relation to the Commission intervention covered by this Section, the Commission may adopt implementing acts concerning the practical arrangements for: (a) the proceedings pursuant to Articles 69 and 72; (b) the hearings provided for in Article 79; (c) the negotiated disclosure of information provided for in Article 79. Before the adoption of any measures pursuant to the first paragraph of this Article, the Commission shall publish a draft thereof and invite all interested parties to submit their comments within the period set out therein, which shall not be less than one month. Those implementing acts shall be adopted in accordance with the advisory procedure referred to in Article 88.", "provision_code": "Article 83", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Professional secrecy", "provision_body": "Without prejudice to the exchange and to the use of information referred to in this Chapter, the Commission, the Board, Member States\u2019 competent authorities and their respective officials, servants and other persons working under their supervision, and any other natural or legal person involved, including auditors and experts appointed pursuant to Article 72(2), shall not disclose information acquired or exchanged by them pursuant to this Regulation and of the kind covered by the obligation of professional secrecy.", "provision_code": "Article 84", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Information sharing system", "provision_body": "1. The Commission shall establish and maintain a reliable and secure information sharing system supporting communications between Digital Services Coordinators, the Commission and the Board. Other competent authorities may be granted access to this system where necessary for them to carry out the tasks conferred to them in accordance with this Regulation. 2. The Digital Services Coordinators, the Commission and the Board shall use the information sharing system for all communications pursuant to this Regulation. 3. The Commission shall adopt implementing acts laying down the practical and operational arrangements for the functioning of the information sharing system and its interoperability with other relevant systems. Those implementing acts shall be adopted in accordance with the advisory procedure referred to in Article 88.", "provision_code": "Article 85", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Representation", "provision_body": "1. Without prejudice to Directive (EU) 2020/1828 or to any other type of representation under national law, recipients of intermediary services shall at least have the right to mandate a body, organisation or association to exercise the rights conferred by this Regulation on their behalf, provided the body, organisation or association meets all of the following conditions: (a) it operates on a not-for-profit basis; (b) it has been properly constituted in accordance with the law of a Member State; (c) its statutory objectives include a legitimate interest in ensuring that this Regulation is complied with. 2. Providers of online platforms shall take the necessary technical and organisational measures to ensure that complaints submitted by bodies, organisations or associations referred to in paragraph 1 of this Article on behalf of recipients of the service through the mechanisms referred to in Article 20(1) are processed and decided upon with priority and without undue delay.", "provision_code": "Article 86", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Exercise of the delegation", "provision_body": "1. The power to adopt delegated acts is conferred on the Commission subject to the conditions laid down in this Article. 2. The delegation of power referred to in Articles 24, 33, 37, 40 and 43 shall be conferred on the Commission for five years starting from 16 November 2022. The Commission shall draw up a report in respect of the delegation of power not later than nine months before the end of the five-year period. The delegation of power shall be tacitly extended for periods of an identical duration, unless the European Parliament or the Council opposes such extension not later than three months before the end of each period. 3. The delegation of power referred to in Articles 24, 33, 37, 40 and 43 may be revoked at any time by the European Parliament or by the Council. A decision of revocation shall put an end to the delegation of power specified in that decision. It shall take effect the day following that of its publication in the Official Journal of the European Union or at a later date specified therein. It shall not affect the validity of any delegated acts already in force. 4. Before adopting a delegated act, the Commission shall consult experts designated by each Member State in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making. 5. As soon as it adopts a delegated act, the Commission shall notify it simultaneously to the European Parliament and to the Council. 6. A delegated act adopted pursuant to Articles 24, 33, 37, 40 and 43 shall enter into force only if no objection has been expressed by either the European Parliament or the Council within a period of three months of notification of that act to the European Parliament and the Council or if, before the expiry of that period, the European Parliament and the Council have both informed the Commission that they will not object. That period shall be extended by three months at the initiative of the European Parliament or of the Council.", "provision_code": "Article 87", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Committee procedure", "provision_body": "1. The Commission shall be assisted by a committee (\u2018the Digital Services Committee\u2019). That Committee shall be a Committee within the meaning of Regulation (EU) No 182/2011. 2. Where reference is made to this paragraph, Article 4 of Regulation (EU) No 182/2011 shall apply.", "provision_code": "Article 88", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Amendments to Directive 2000/31/EC", "provision_body": "1. Articles 12 to 15 of Directive 2000/31/EC are deleted. 2. References to Articles 12 to 15 of Directive 2000/31/EC shall be construed as references to Articles 4, 5, 6 and 8 of this Regulation, respectively.", "provision_code": "Article 89", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Amendment to Directive (EU) 2020/1828", "provision_body": "In Annex I to Directive (EU) 2020/1828, the following point is added: \u2018(68) Regulation (EU) 2022/2065 of the European Parliament and of the Council of 19 October 2022 on a Single Market for Digital Services and amending Directive 2000/31/EC (Digital Services Act) (OJ L 277, 27.10.2022, p. 1).\u2019.", "provision_code": "Article 90", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Review", "provision_body": "1. By 18 February 2027, the Commission shall evaluate and report to the European Parliament, the Council and the European Economic and Social Committee on the potential effect of this Regulation on the development and economic growth of small and medium-sized enterprises. By 17 November 2025, the Commission shall evaluate and report to the European Parliament, the Council and the European Economic and Social Committee on: (a) the application of Article 33, including the scope of providers of intermediary services covered by the obligations set out in Section 5 of Chapter III of this Regulation; (b) the way that this Regulation interacts with other legal acts, in particular the acts referred to in Article 2(3) and (4). 2. By 17 November 2027, and every five years thereafter, the Commission shall evaluate this Regulation, and report to the European Parliament, the Council and the European Economic and Social Committee. This report shall address in particular: (a) the application of paragraph 1, second subparagraph, points (a) and (b); (b) the contribution of this Regulation to the deepening and efficient functioning of the internal market for intermediary services, in particular as regards the cross-border provision of digital services; (c) the application of Articles 13, 16, 20, 21, 45 and 46; (d) the scope of the obligations on small and micro enterprises; (e) the effectiveness of the supervision and enforcement mechanisms; (f) the impact on the respect for the right to freedom of expression and information. 3. Where appropriate, the report referred to in paragraphs 1 and 2 shall be accompanied by a proposal for amendment of this Regulation. 4. The Commission shall, in the report referred to in paragraph 2 of this Article, also evaluate and report on the annual reports on their activities by the Digital Services Coordinators provided to the Commission and the Board pursuant to Article 55(1). 5. For the purpose of paragraph 2, Member States and the Board shall send information on the request of the Commission. 6. In carrying out the evaluations referred to in paragraph 2, the Commission shall take into account the positions and findings of the European Parliament, the Council, and other relevant bodies or sources, and shall pay specific attention to small and medium-sized enterprises and the position of new competitors. 7. By 18 February 2027, the Commission, after consulting the Board, shall carry out an assessment of the functioning of the Board and of the application of Article 43, and shall report it to the European Parliament, the Council and the European Economic and Social Committee, taking into account the first years of application of the Regulation. On the basis of the findings and taking utmost account of the opinion of the Board, that report shall, where appropriate, be accompanied by a proposal for amendment of this Regulation with regard to the structure of the Board.", "provision_code": "Article 91", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Anticipated application to providers of very large online platforms and of very large online search engines", "provision_body": "This Regulation shall apply to providers of very large online platforms and of very large online search engines designated pursuant to Article 33(4) from four months after the notification to the provider concerned referred to in Article 33(6) where that date is earlier than 17 February 2024.", "provision_code": "Article 92", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
{"provision_title": "Entry into force and application", "provision_body": "1. This Regulation shall enter into force on the twentieth day following that of its publication in the Official Journal of the European Union. 2. This Regulation shall apply from 17 February 2024. However, Article 24(2), (3) and (6), Article 33(3) to (6), Article 37(7), Article 40(13), Article 43 and Sections 4, 5 and 6 of Chapter IV shall apply from 16 November 2022. This Regulation shall be binding in its entirety and directly applicable in all Member States. Done at Strasbourg, 19 October 2022. For the European Parliament The President R. METSOLA For the Council The President M. BEK", "provision_code": "Article 93", "country": "European Union", "region": "n/a", "relevant_labels": "Digital Services Act, Single Market For Digital Services, intermediary services, illegal content, online platforms, consumer protection, fundamental rights, data protection, online advertising, recommender systems, minors protection, crisis response, audits, enforcement, cooperation", "law_code": "REGULATION (EU) 2022/2065", "reference_file": "./law_dataset\\CELEX_32022R2065_EN_TXT.pdf"}
