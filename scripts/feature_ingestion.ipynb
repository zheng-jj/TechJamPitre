{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfcba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings # Using Ollama as an example\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e85d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (good practice, even if not used by Ollama)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eab4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "FEATURE_DATABASE_FILE = \"data/sample-feature-data.json\" \n",
    "VECTOR_STORE_PATH = \"feature_vector_store\"  # Save to a separate directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feature_record(feature_item, source_file):\n",
    "    \"\"\"Transforms a single feature dictionary into a LangChain Document.\"\"\"\n",
    "    \n",
    "    # Create a descriptive text string from the feature's JSON object\n",
    "    content = (\n",
    "        f\"Feature Name: {feature_item.get('feature_name', 'N/A')}. \"\n",
    "        f\"Type: {feature_item.get('feature_type', 'N/A')}. \"\n",
    "        f\"Description: {feature_item.get('feature_description', 'N/A')}. \"\n",
    "        f\"Relevant labels include: {', '.join(feature_item.get('relevant_labels', []))}.\"\n",
    "    )\n",
    "    \n",
    "    # Create specific metadata for the feature\n",
    "    metadata = {\n",
    "        \"feature_id\": feature_item.get('feature_id'),\n",
    "        \"source_type\": \"feature\",  # Critical for identifying this data type later\n",
    "        \"source_file\": source_file,\n",
    "        \"feature_name\": feature_item.get('feature_name')\n",
    "    }\n",
    "    return Document(page_content=content, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff3cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to ingest feature data and create a dedicated vector store.\"\"\"\n",
    "    print(f\"Starting feature ingestion from '{FEATURE_DATABASE_FILE}'...\")\n",
    "    \n",
    "    all_docs = []\n",
    "\n",
    "    # Check if the feature database file exists\n",
    "    if not os.path.exists(FEATURE_DATABASE_FILE):\n",
    "        print(f\"Error: Feature database file not found at '{FEATURE_DATABASE_FILE}'\")\n",
    "        return\n",
    "\n",
    "    # Load the list of features from the JSON file\n",
    "    with open(FEATURE_DATABASE_FILE, 'r', encoding='utf-8') as f:\n",
    "        feature_data_list = json.load(f)\n",
    "\n",
    "    # Process each feature record in the list\n",
    "    for feature_record in feature_data_list:\n",
    "        doc = process_feature_record(feature_record, FEATURE_DATABASE_FILE)\n",
    "        all_docs.append(doc)\n",
    "\n",
    "    if not all_docs:\n",
    "        print(\"No feature documents found in the file.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loaded {len(all_docs)} feature documents.\")\n",
    "\n",
    "    # Split the documents into smaller chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150) # Adjust chunk size as needed, IMPORTANT\n",
    "    split_docs = text_splitter.split_documents(all_docs)\n",
    "    print(f\"Split feature documents into {len(split_docs)} chunks.\")\n",
    "\n",
    "    # Initialize the embedding model (e.g., Ollama)\n",
    "    # IMPORTANT: Use the same embedding model as your law ingestion script!\n",
    "    embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "    print(\"Initialized embedding model.\")\n",
    "\n",
    "    # Create the vector store from the feature chunks\n",
    "    print(f\"Creating feature vector store with FAISS at '{VECTOR_STORE_PATH}'...\")\n",
    "    vector_store = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "    # Save the dedicated feature vector store\n",
    "    vector_store.save_local(VECTOR_STORE_PATH)\n",
    "    print(\"Feature vector store created and saved successfully.\")\n",
    "    print(\"Feature ingestion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da050ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
